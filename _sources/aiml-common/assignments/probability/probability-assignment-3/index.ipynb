{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get full credit in this assignment you need to use only `numpy` or `numba` libraries  and include adequate explanation of the code in either markdown cells or code comments. Sometimes you need to type equations - type equations in latex math notation. \n",
    "\n",
    "# Question 1 (30 points)\n",
    "\n",
    "![](points-on-line.png)\n",
    "\n",
    "1. We monitor server faults in a data center over a period of T units of time and represents each occurring fault as a point on the line. What is the probability that k faults take place between $t_1$ and $t_2$ if $n$ total points were recorded ?  (10 points)\n",
    "\n",
    "2. We collected a very large set of faults $n \\rightarrow \\infty$ over a long measurement interval $T \\rightarrow \\infty$  and we observed that on average faults occur with a rate of $\\lambda = \\frac{n}{T}$.   This [allows us](https://en.wikipedia.org/wiki/Poisson_limit_theorem) to model the probability of $k_a$ points in an interval $t_a$ as [Poisson](https://en.wikipedia.org/wiki/Poisson_distribution).  \n",
    "    Suppose that we measure $k_a$ and $k_b$ faults in two consecutive intervals of durations $t_a=(t_1, t_2)$ and $t_b=(t_2, t_3)$ respectively where $t_a+t_b < T$, write the expression of the joint probability $p(k_a \\in t_a, k_b \\in t_b)$. (10 points)\n",
    "\n",
    "3. Suppose now that we need to schedule personnel to replace these servers and we are interested to use the fault data to estimate the probability of $p(k_a \\in t_a | k_c \\in t_c)$ where $t_c=t_a + t_b$. Write the expression of this conditional probability.  (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Write your answer here and use Latex math notation for math. If you prefer write the math with pencil and scan the writeup in a png image that you can insert here using` \n",
    "\n",
    "```\n",
    "![](your-png-file.png)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (10 points)\n",
    "\n",
    "Generate N uniform distributed over the interval [0,1] random variables $\\{x_1, \\dots x_N\\}$. \n",
    "\n",
    "Compute their mean and after repeating such computation $m$ times, plot the  histogram as $N$ takes values ${1, 5, 10, 20}$. \n",
    "\n",
    "Provide a justification of the resultant histogram by reading about the [Cenral Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type the Python code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (10 points) \n",
    "\n",
    "The exercise refers to Example 6.6 of the  [Math for ML book](https://mml-book.github.io/book/mml-book.pdf). \n",
    "\n",
    "Simulate and plot the bivariate normal distribution with the shown parameters. \n",
    "\n",
    "You need to use the [Cholesky factorization](https://numpy.org/doc/stable/reference/generated/numpy.linalg.cholesky.html) for the simulation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (25 points)\n",
    "\n",
    "The exercise refers to Example 6.6 of the  [Math for ML book](https://mml-book.github.io/book/mml-book.pdf). \n",
    "\n",
    "1. Simulate for $m=10, 100, 1000$ samples and plot the conditional distribution as given by the analytical expressions of the conditional mean and covariance matrix in Python. (5 points)\n",
    "   \n",
    "2. Use maximum likelihood estimation (MLE) with Stochastic Gradient Descent (SGD) to estimate the parameters of resultant distribution. (15 points)\n",
    "\n",
    "3. Plot the estimates as a function of $m$ - include the analytical mean and variance in the plots for comparison.  (5 points)\n",
    "\n",
    "You may use [these](http://jrmeyer.github.io/machinelearning/2017/08/18/mle.html) derivatives for implementing the SGD-based estimator. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type the Python code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (25 points)\n",
    "\n",
    "![](mic-array.png)\n",
    "\n",
    "You smartphone has an microphone array i.e. a number of sensors that are spatially separated in the circumference of the device. The array is used to do interference suppression and it does so by beaming to the direction of your voice suppressing background noises. To do so it needs to measure the spatial correlation matrix. \n",
    "\n",
    "The data (sound in this case) are assumed to arrive sequentially one at a time (the co-called **online** learning setting). Introduce the index $i$ to represent the ith arriving data sample $\\mathbf x_i$. \n",
    "\n",
    "1. Write the expression of the *sample* correlation matrix (5 points)\n",
    "2. Write the expression of the sample correlation matrix that can be estimated recursively (15 points). \n",
    "3. Simulate $m=50$ samples assuming a correlation matrix of your choice. Plot the elements of the estimated correlation elements (row, column) of the correlation matrix as they estimated recursively over time assuming $n=2, 4 and 8$ sensors (mics). Comment if and if so how the estimated element variance is affected by the ratio $n/m$. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type the python code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
