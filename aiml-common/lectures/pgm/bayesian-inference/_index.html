
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Bayesian Inference &#8212; Data Mining</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://pantelis.github.io/data-mining/aiml-common/lectures/pgm/bayesian-inference/_index.html" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Bayesian Coin Flipping" href="../bayesian-coin/_index.html" />
    <link rel="prev" title="Boosting workshop" href="../../ensemble/boosting-workshop/_index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Mining</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Syllabus
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../syllabus/_index.html">
   Syllabus
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Data Mining
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ai-intro/course-introduction/_index.html">
   Course Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ai-intro/data-science-360/_index.html">
   Data Science 360
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ai-intro/pipelines/_index.html">
   ML Pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../uber-ml-arch-case-study/_index.html">
   A Case Study of an ML Architecture - Uber
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The Learning Problem
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../learning-problem/_index.html">
   The Learning Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../regression/linear-regression/_index.html">
   Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../optimization/maximum-likelihood/_index.html">
   Maximum Likelihood (ML) Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../entropy/_index.html">
   Entropy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../optimization/sgd/_index.html">
   Stochastic Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/classification-intro/_index.html">
   Introduction to Classification
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Classical Learning Methods
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/logistic-regression/_index.html">
   Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../decision-trees/_index.html">
   Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../regression-trees/regression_trees.html">
   Regression tree stumps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ensemble/_index.html">
   Ensemble Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ensemble/random-forests/_index.html">
   Random Forests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ensemble/boosting/_index.html">
   Boosting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ensemble/boosting-workshop/_index.html">
   Boosting workshop
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Bayesian Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bayesian-coin/_index.html">
   Bayesian Coin Flipping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/covid19-antibody-test/_index.html">
   COVID-19 Antibody Test
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deep Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/perceptron/_index.html">
   The Neuron (Perceptron)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../dnn/dnn-intro/_index.html">
   Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../dnn/backprop-intro/_index.html">
   Introduction to Backpropagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../dnn/backprop-dnn/_index.html">
   Backpropagation in Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../dnn/backprop-dnn-exercises/_index.html">
   Backpropagation DNN exercises
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../optimization/regularization/_index.html">
   Regularization in Deep Neural Networks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Convolutional Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-intro/_index.html">
   Introduction to Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-layers/_index.html">
   CNN Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-example-architectures/_index.html">
   CNN Example Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">
   Using convnets with small datasets
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Scene Understanding
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/scene-understanding-intro/_index.html">
   Introduction to Scene Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/feature-extraction-resnet/_index.html">
   Feature Extraction via Residual Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/object-detection/_index.html">
   Object Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/object-detection/detection-segmentation-workshop/_index.html">
   Object Detection and Semantic Segmentation Workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../cnn/cnn-explainers/_index.html">
   CNN Explainers
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Sequences and RNNs
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../rnn/introduction/_index.html">
   Introduction to Recurrent Neural Networks (RNN)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../rnn/simple-rnn/_index.html">
   Simple RNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../rnn/lstm/_index.html">
   The Long Short-Term Memory (LSTM) Cell Architecture
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Embeddings and NLP
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/nlp-intro/_index.html">
   Introduction to NLP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/word2vec/_index.html">
   Word2Vec Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/rnn-language-models/_index.html">
   RNN Language Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/nmt/_index.html">
   Neural Machine Translation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Non-Parametric Methods
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../unsupervised/k-means/_index.html">
   K-means Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../density-estimation/knn/_index.html">
   k-Nearest Neighbors (kNN) Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../density-estimation/knn-workshop/_index.html">
   kNN Workshop
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dimensionality Reduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../pca/_index.html">
   Principal Component Analysis (PCA)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Math Background
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-math/_index.html">
   Math for ML
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-math/probability/_index.html">
     Probability Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../linear-algebra/_index.html">
     Linear Algebra for Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-math/calculus/_index.html">
     Calculus
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../python/_index.html">
   Learn Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Assignments &amp; Projects
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../assignments/probability/probability-assignment-2/probability-assignment-2.html">
   Probability Assigmment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../assignments/mle/mle_exponential_linear_regression.html">
   Maximum Likelihood Parameter Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../projects/reported-ai/_index.html">
   Reported.ai - News Aggregation with AI Agents
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://pantelis.github.io/data-mining"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://pantelis.github.io/data-mining/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/pgm/bayesian-inference/_index.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../../_sources/aiml-common/lectures/pgm/bayesian-inference/_index.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-bayes-rule">
   The Bayes Rule
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probabilistic-graphical-models">
   Probabilistic Graphical Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-approach-vs-maximum-likelihood">
     Bayesian approach vs Maximum Likelihood
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#online-bayesian-regression">
   Online Bayesian Regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bayesian-regression-implementation">
   Bayesian Regression implementation
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Bayesian Inference</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-bayes-rule">
   The Bayes Rule
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probabilistic-graphical-models">
   Probabilistic Graphical Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-approach-vs-maximum-likelihood">
     Bayesian approach vs Maximum Likelihood
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#online-bayesian-regression">
   Online Bayesian Regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bayesian-regression-implementation">
   Bayesian Regression implementation
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="bayesian-inference">
<h1>Bayesian Inference<a class="headerlink" href="#bayesian-inference" title="Permalink to this headline">#</a></h1>
<section id="the-bayes-rule">
<h2>The Bayes Rule<a class="headerlink" href="#the-bayes-rule" title="Permalink to this headline">#</a></h2>
<p><img alt="Bayes" src="../../../../_images/bayes.jpg" />
<em>Thomas Bayes (1701-1761)</em></p>
<p>The Bayesian theorem is the cornerstone of probabilistic modeling and ultimately governs what models we can construct inside the <em>learning algorithm</em>. If <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> denotes the unknown parameters, <span class="math notranslate nohighlight">\(\mathtt{data}\)</span> denotes the dataset and <span class="math notranslate nohighlight">\(\mathcal{H}\)</span> denotes the hypothesis set that we met in the learning problem chapter.</p>
<div class="math notranslate nohighlight">
\[ p(\mathbf{w} | \mathtt{data}, \mathcal{H}) =  \frac{P(  \mathtt{data} | \mathbf{w}, \mathcal{H}) P(\mathbf{w} | \mathcal{H}) }{ P(  \mathtt{data} | \mathcal{H})} \]</div>
<p>The Bayesian framework allows the introduction of priors <span class="math notranslate nohighlight">\(p(\mathbf w | \mathcal{H})\)</span> from a wide variety of sources: experts, other data, past posteriors, etc. It allows us to calculate the posterior distribution from the likelihood function and this prior subject to a normalizing constant.</p>
<p><strong>We will call <em>belief</em> the internal to the agent posterior probability estimate of a random variable as calculated via the Bayes rule.</strong></p>
<p>For example,a medical patient is exhibiting symptoms x, y and z. There are a number of diseases that could be causing all of them, but only a single disease is present. A doctor (the expert) has a <em>belief</em> about the underlying disease, but a second doctor may have a slightly different <em>belief</em>.</p>
</section>
<section id="probabilistic-graphical-models">
<h2>Probabilistic Graphical Models<a class="headerlink" href="#probabilistic-graphical-models" title="Permalink to this headline">#</a></h2>
<p>Let us now look at a representation, <em>the probabilistic graphical model (pgm)</em> (also called Bayesian network when the priors are captured) that can be used to capture the <em>structure</em> of such beliefs and in general capture dependencies between the random variables involved in the modeling of a problem. We can use such representations to efficiently compute such beliefs and, in general, compute conditional probabilities. For now we will limit the modeling horizon to just one snapshot in time - later we will expand to capture problems that include time <span class="math notranslate nohighlight">\(t\)</span> as a variable.</p>
<p>By convention we represent in PGMs as directed graphs, with nodes being the random variables involved in the model and directed edges indicating a parent child relationship, with the arrow pointing to a child, representing that the child nodes are <em>probabilistically conditioned on the parent(s)</em>.</p>
<p>In a hypothetical example of a joint distribution with <span class="math notranslate nohighlight">\(K=7\)</span> random variables,</p>
<a class="reference internal image-reference" href="../../../../_images/Figure8.2.png"><img alt="../../../../_images/Figure8.2.png" class="align-center" src="../../../../_images/Figure8.2.png" style="width: 250px;" /></a>
<p>The PGM above represents the joint distribution <span class="math notranslate nohighlight">\(p(x_1, x_2, ..., x_7)=p(x_1)p(x_2)p(x_3)p(x_4|x_1, x_2, x_3)p(x_5|x_1, x_3) p(x_6|x_4)p(x_7|x_4, x_5)\)</span>. In general,</p>
<div class="math notranslate nohighlight">
\[p(\mathbf x)= \prod_{k=1}^K p(x_k | \mathtt{pa}_k)\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathtt{pa}_k\)</span> is the set of parents of node <span class="math notranslate nohighlight">\(x_k\)</span>.</p>
<p>Note that we have assumed that our model does <em>not</em> have variables involved in directed cycles and therefore we call such graphs Directed Acyclic Graphs (DAGs).</p>
<section id="bayesian-approach-vs-maximum-likelihood">
<h3>Bayesian approach vs Maximum Likelihood<a class="headerlink" href="#bayesian-approach-vs-maximum-likelihood" title="Permalink to this headline">#</a></h3>
<p>In the Maximum Likelihood Estimation section we have seen a simple supervised learning problem that is specified via a joint distribution <span class="math notranslate nohighlight">\(\hat{p}_{data}(\mathbf x, y)\)</span> and are asked to fit the model parameterized by the weights <span class="math notranslate nohighlight">\(\mathbf w\)</span> using maximum likelihood. Its important to view pictorially perhaps the most important effect of Bayesian thinking in the regression setting:</p>
<ul class="simple">
<li><p>The <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> in MLE is a point estimate <span class="math notranslate nohighlight">\(\mathbf{w}_{MLE}\)</span> and we are plugging this estimate in the predictive distribution to make predictions <span class="math notranslate nohighlight">\(\hat y\)</span> for data we havent seen before.</p></li>
<li><p>In the Bayesian setting on the other hand we use a full distribution over <span class="math notranslate nohighlight">\(\mathbf w\)</span>. We predict by integrating over the posterior of <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> (i.e. given the data) and therefore considering organically the uncertainty of the posterior of <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> in our predictions.  As such it can capture the effects of sparse data producing more uncertainty via its covariance in areas where there are no data as shown in the following example which is exactly the same sinusoidal dataset fit with Bayesian updates and Gaussian basis functions.</p></li>
</ul>
<p><a class="reference internal" href="../../../../_images/Figure3.8a.png"><img alt="../../../../_images/Figure3.8a.png" src="../../../../_images/Figure3.8a.png" style="width: 40%;" /></a> <a class="reference internal" href="../../../../_images/Figure3.8a.png"><img alt="../../../../_images/Figure3.8a.png" src="../../../../_images/Figure3.8a.png" style="width: 40%;" /></a>
<a class="reference internal" href="../../../../_images/Figure3.8c.png"><img alt="../../../../_images/Figure3.8c.png" src="../../../../_images/Figure3.8c.png" style="width: 40%;" /></a> <a class="reference internal" href="../../../../_images/Figure3.8d.png"><img alt="../../../../_images/Figure3.8d.png" src="../../../../_images/Figure3.8d.png" style="width: 40%;" /></a></p>
<p>ML frameworks have been enhanced recently to deal with Bayesian approaches and approximations that make such approaches feasible for both classical and deep learning. <strong>TF.Probability</strong> and <strong>PyTorch Pyro</strong> are examples of such enhancements.</p>
<p>Before diving into the posterior update in regression problems its instructive to go over the Bayesian coin tossing notebook that shows a simpler experiment.</p>
<!-- ## Bayesian Linear Regression

The Probabilistic Graphical Model is a representation that is extensively used in probabilistic reasoning. Lets consider the simplest possible example of a graphical model and see how it connects to concepts we have seen before. Any joint distribution $p(\mathbf x, y)$ can be decomposed using the product rule (we drop the data qualifier) 

$$p(\mathbf x, y) = p(\mathbf x) p(y|\mathbf x)$$

and such distribution can be represented via the simple PGM graph (a) below. 

<img src="images/Figure8.37.png" width="250" align="center">

*Simplest possible PGM example*

We introduce now a graphical notation where we shade, nodes that we consider observed. Let us know assume that we observe $y$ as shown in (b). We can view the marginal $p(\mathbf x)$  as a prior over $x$ and and we can _infer_ the posterior distribution using the Bayes rule

$$p(x|y) = \frac{p(y|x)p(x)}{p(y)}$$

where using the sum rule we know $p(y) = \sum_{x'} p(y|x') p(x')$. This is a very innocent but very powerful concept.  -->
</section>
</section>
<section id="online-bayesian-regression">
<h2>Online Bayesian Regression<a class="headerlink" href="#online-bayesian-regression" title="Permalink to this headline">#</a></h2>
<p>Lets us consider an instructive example of applying the Bayesian approach in an online learning setting (streaming data arriving over the wire). In this example where the underlying target function is <span class="math notranslate nohighlight">\(p_{data}(x, \mathbf w) = w_0 + w_1 x + n\)</span> This is the equation of a line. In this example its parametrized with <span class="math notranslate nohighlight">\(a_0=-0.3, a_1=0.5\)</span> and <span class="math notranslate nohighlight">\(n \in \mathcal N(0, \sigma=0.2)\)</span>. To match the simple inference exercise that we just saw, we draw the equivalent PGM</p>
<a class="reference internal image-reference" href="../../../../_images/Figure8.3.png"><img alt="../../../../_images/Figure8.3.png" class="align-center" src="../../../../_images/Figure8.3.png" style="width: 250px;" /></a>
<p><em>Bayesian Linear Regression example - please replace <span class="math notranslate nohighlight">\(t\)</span> with <span class="math notranslate nohighlight">\(y\)</span> to match earlier notation in these notes</em></p>
<p>The Bayesian update of the posterior can be intuitively understood using a graphical example of our model of the form:</p>
<div class="math notranslate nohighlight">
\[g(x,\mathbf{w})= w_0 + w_1 x\]</div>
<p>The reason why we pick this example is illustrative as the model has just two parameters and is amendable to visualization. The update needs a prior <em>distribution</em> over <span class="math notranslate nohighlight">\(\mathbf w\)</span> and a likelihood function. As prior we assume a spherical Gaussian</p>
<div class="math notranslate nohighlight">
\[p(\mathbf w | \alpha) = \mathcal N(\mathbf w | \mathbf 0, \alpha^{-1} \mathbf I)\]</div>
<p>with <span class="math notranslate nohighlight">\(\alpha = 0.2\)</span>. We starts in row 1 with this prior and at this point there are no data and the likelihood is undefined while every possible linear (line) hypothesis is feasible as represented by the red lines. In row 2, a data point arrives and the the Bayesian update takes place: the previous row posterior becomes the prior and is multiplied by the current likelihood function. The likelihood function and the form of the math behind the update are as shown in <a class="reference external" href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">Bishop’s book in section 3.3</a>. Here we focus on a pictorial view of what is the update is all about and how the estimate of the posterior distribution <span class="math notranslate nohighlight">\(p(\mathbf w | \mathbf y)\)</span> ultimately (as the iterations increase) it will be ideally centered to the ground truth (<span class="math notranslate nohighlight">\(\mathbf a\)</span>).</p>
<p><img alt="Figure3.7-bishop" src="../../../../_images/Figure3.7.png" />
<em>Instructive example of Bayesian learning as data points are streamed into the learner. Notice the dramatic improvement in the posterior the moment the 2nd data point arrives. Why is that?</em></p>
</section>
<section id="bayesian-regression-implementation">
<h2>Bayesian Regression implementation<a class="headerlink" href="#bayesian-regression-implementation" title="Permalink to this headline">#</a></h2>
<p>Notice in the notebook the two of the three broad benefits of the Bayesian approach:</p>
<ul class="simple">
<li><p>Compatibility with online learning - online learning does not mean necessarily that the data arrive over the ‘wire’ but it means that we can consider few data at a time.</p></li>
<li><p>Adjustment of the predictive uncertainty (cov) to the sparsity of the data.</p></li>
<li><p>Incorporation of external beliefs / opinions that can be naturally expressed probabilistically.</p></li>
</ul>
<iframe src="https://nbviewer.jupyter.org/github/pantelis/PRML/blob/master/notebooks/ch03b_Bayesian_Regression.ipynb" width="900" height="1200"></iframe></section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./aiml-common/lectures/pgm/bayesian-inference"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../../ensemble/boosting-workshop/_index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Boosting workshop</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../bayesian-coin/_index.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bayesian Coin Flipping</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Pantelis Monogioudis, Ph.D<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>