

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Linear Algebra for Machine Learning &#8212; Data Mining</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/sphinx-examples.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"mathjax_path": "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js", "tex": {"macros": {"floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'aiml-common/lectures/ml-math/linear-algebra/index';</script>
    <link rel="canonical" href="https://pantelis.github.io/data-mining/aiml-common/lectures/ml-math/linear-algebra/index.html" />
    <link rel="shortcut icon" href="../../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Calculus" href="../calculus/index.html" />
    <link rel="prev" title="Probability Basics" href="../probability/index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/logo.png" class="logo__image only-light" alt="Data Mining - Home"/>
    <script>document.write(`<img src="../../../../_static/logo.png" class="logo__image only-dark" alt="Data Mining - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Syllabus</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../syllabus/index.html">Syllabus</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to Data Mining</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../data-premise/index.html">The new premise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/data-science-360/_index.html">Data Science 360</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../pipelines/_index.html">Pipelines</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../pipelines/uber-ml-arch-case-study/index.html">A Case Study of an ML Architecture - Uber</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../pipelines/01_the_machine_learning_landscape.html">The Machine Learning landscape</a></li>



</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">The Learning Problem</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../learning-problem/_index.html">The Learning Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipelines/02_end_to_end_machine_learning_project.html">End-to-end Machine Learning project</a></li>






<li class="toctree-l1"><a class="reference internal" href="../../model-selection/bias_variance.html">Empirical Risk Minimization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Predictors for Structured Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../trees/decision-trees/index.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../trees/decision-trees/decision_tree.html">Decision tree from scratch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../trees/decision-trees/decision_tree_visualisations.html">Visualizing tree-based classifiers</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../trees/regression-trees/regression_tree_visualisations.html">Visualizing tree-based regressors</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../ensemble/index.html">Ensemble Methods</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ensemble/random-forests/index.html">Random Forests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ensemble/adaboost/index.html">Adaptive Boosting (AdaBoost)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ensemble/adaboost/adaboost_example.html">Adaboost from scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ensemble/gradient-boosting/index.html">Gradient Boosting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ensemble/boosting-workshop/index.html">Boosting Workshop</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Learning without Labels or Without Parameters</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../unsupervised/k-means/_index.html">K-means Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../density-estimation/knn/_index.html">k-Nearest Neighbors (kNN) Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../density-estimation/knn-workshop/_index.html">kNN Workshop</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Representation Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../optimization/maximum-likelihood/marginal_maximum_likelihood.html">Maximum Likelihood Estimation of a marginal model</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../generative-modeling/index.html">Generative Modeling and Probabilistic Graphical Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../generative-modeling/em-algorithm/index.html">The Expectation - Maximization (EM) Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../generative-modeling/em-gaussian-mixture/em_example_mog.html">Expectation Maximization for Gaussian Mixture Model</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Dimensionality Reduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../pca/introduction/index.html">Principal Component Analysis (PCA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pca/introduction/principal_component_analysis.html">PCA Workshop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recommenders/recommenders-intro/_index.html">Introduction to Recommender Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recommenders/netflix/_index.html">The Netflix Prize and Singular Value Decomposition</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Regression and Classification</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../regression/linear-regression/linear_regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/sgd/_index.html">Stochastic Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../classification/classification-intro/_index.html">Introduction to Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../classification/logistic-regression/_index.html">Logistic Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../classification/perceptron/_index.html">The Neuron (Perceptron)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/fashion-mnist-case-study.html">Fashion MNIST Case Study</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Image Data and Convolutional Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-intro/_index.html">Introduction to Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-layers/_index.html">CNN Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/_index.html">CNN Example Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">Using convnets with small datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../scene-understanding/feature-extraction-resnet/index.html">Feature Extraction via Residual Networks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Time-series data and Recurrent Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../rnn/introduction/_index.html">Introduction to Recurrent Neural Networks (RNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/simple-rnn/_index.html">Simple RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/lstm/_index.html">The Long Short-Term Memory (LSTM) Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/time_series_using_simple_rnn_lstm.html">Time Series Prediction using RNNs</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Neural Autoencoders</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../vae/introduction/index.html">Variational Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../vae/vae-architecture/index.html">VAE Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../vae/elbo-optimization/vae.html">Variational AutoEncoder</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Math Background</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Math for ML Textbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../probability/index.html">Probability Basics</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Linear Algebra for Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../calculus/index.html">Calculus</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/index.html">Your Programming Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/assignment-submission.html">Submitting Your Assignment / Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python/index.html">Learn Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/notebook-status.html">Notebook execution status</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/cutting-edge-dev-environments/index.html">Cutting Edge Development Environment for Data Science</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/nyc-taxi-streaming-data-prediction/index.html">Online Ensemble Learning from NYC Taxi Ride Event Streams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/logistic-regression-1/index.html">Logistic Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/nlp/news-recommendation/index.html">News Time Machine</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pantelis/data-mining" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pantelis/data-mining/edit/main/aiml-common/lectures/ml-math/linear-algebra/index.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pantelis/data-mining/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/ml-math/linear-algebra/index.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/aiml-common/lectures/ml-math/linear-algebra/index.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Linear Algebra for Machine Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-points">Key Points</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#projections">Projections</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-four-fundamental-subspaces">The Four Fundamental Subspaces</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eigenvalues-and-eigenvectors">Eigenvalues and Eigenvectors</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="linear-algebra-for-machine-learning">
<h1>Linear Algebra for Machine Learning<a class="headerlink" href="#linear-algebra-for-machine-learning" title="Permalink to this heading">#</a></h1>
<p>Let me introduce you MIT prof G Strang - probably the best educator in America. He has published this playlist of <a class="reference external" href="https://www.youtube.com/watch?v=Cx5Z-OslNWE&amp;list=PLUl4u3cNGP63oMNUHXqIUcrkS2PivhN3k">youtube videos on Linear Algebra</a>.</p>
<p>Also, watch <a class="reference external" href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">these videos</a> for a more elementary treatment of the topic.</p>
<div class="video_wrapper" style="">
<iframe allowfullscreen="true" src="https://www.youtube.com/embed/wu3E38nguG4" style="border: 0; height: 345px; width: 560px">
</iframe></div><p><em>Linear Algebra recitation for my classes. Recitation was delivered by my TA Shweta Selvaraj Achary.</em></p>
<p>The corresponding chapter of Ian Goodfellow’s Deep Learning book is what you partially need to know as data scientists at a graduate level but arguably if you are just starting you ought to know 2.1-2.5.</p>
<iframe src="https://www.deeplearningbook.org/contents/linear_algebra.html" width="800" height="1200"></iframe>
<section id="key-points">
<h2>Key Points<a class="headerlink" href="#key-points" title="Permalink to this heading">#</a></h2>
<p>We can now summarize the points to pay attention to, for ML applications.  In the following we assume a data matrix <span class="math notranslate nohighlight">\(A\)</span> with <span class="math notranslate nohighlight">\(m\)</span> rows and <span class="math notranslate nohighlight">\(n\)</span> columns. We also assume that the matrix is such that it has <span class="math notranslate nohighlight">\(r\)</span> independent rows or columns, called <em>the matrix rank</em>.</p>
<section id="projections">
<h3>Projections<a class="headerlink" href="#projections" title="Permalink to this heading">#</a></h3>
<p>Its important to understand this basic operator and its geometric interpretation as it is met in problems like Ordinary Least Squares but also all over ML and other fields such as compressed sensing. In the following we assume that the reader is familiar with the concept of vector spaces and subspaces.</p>
<p>Let <span class="math notranslate nohighlight">\(S\)</span> be a vector subspace of <span class="math notranslate nohighlight">\(R^n\)</span>. For example in <span class="math notranslate nohighlight">\(R^3\)</span>, <span class="math notranslate nohighlight">\(S\)</span> are the lines and planes going through the origin. The projection operator onto <span class="math notranslate nohighlight">\(S\)</span> implements a linear transformation: <span class="math notranslate nohighlight">\(\Pi_S: R^3 →S\)</span>. We will stick to <span class="math notranslate nohighlight">\(R^3\)</span> to maintain the ability to plot the operations involved. We also define the orthogonal subspace,</p>
<div class="math notranslate nohighlight">
\[S^\perp  ≡  \{ \mathbf w \in R^3 | \mathbf w ^T \mathbf s = 0, ∀ \mathbf s \in S \} \]</div>
<p>The transformation <span class="math notranslate nohighlight">\(\Pi_S\)</span> projects onto space <span class="math notranslate nohighlight">\(S\)</span> in the sense that when you apply this operator, every vector <span class="math notranslate nohighlight">\(\mathbf u\)</span> in any other space results in the subspace <span class="math notranslate nohighlight">\(S\)</span>. In our example above,</p>
<div class="math notranslate nohighlight">
\[\Pi_S(\mathbf u) \in S, \forall \mathbf u \in R^3\]</div>
<p>This means that any components of the vector <span class="math notranslate nohighlight">\(\mathbf u\)</span> that belonged to <span class="math notranslate nohighlight">\(S^\perp\)</span> are gone when applying the projection operator. Effectively, the original space is decomposed into</p>
<div class="math notranslate nohighlight">
\[ R^3 = S \oplus S^\perp \]</div>
<p>Now we can treat projections onto specific subspaces such as lines and planes passing through the origin.</p>
<p>For a line defined by a direction vector <span class="math notranslate nohighlight">\(\mathbf u\)</span></p>
<div class="math notranslate nohighlight">
\[l = \{  (x,y,z) \in \R^3 | (x,y,z) = \mathbf 0 + t \mathbf u \} \]</div>
<p>we can define the projection onto the line</p>
<p><img alt="line-projection" src="../../../../_images/line-projection.png" />
<em>Projection of <span class="math notranslate nohighlight">\(\mathbf u\)</span> onto the line <span class="math notranslate nohighlight">\(l\)</span></em></p>
<p>The space <span class="math notranslate nohighlight">\(S^\perp ≡ l^\perp\)</span> is a plane since it consists of all the vectors that are perpendicular to the line. What is shown in the figure as a dashed line is simply the projection of <span class="math notranslate nohighlight">\(\mathbf u\)</span> on the <span class="math notranslate nohighlight">\(l^\perp\)</span> subspace,</p>
<div class="math notranslate nohighlight">
\[\begin{split}l^\perp = \{  (x,y,z) \in \R^3 | \begin{bmatrix} x \\ y \\ z \end{bmatrix}^T  \mathbf v = 0\} \end{split}\]</div>
<p>The orthogonal space of a line with direction vector <span class="math notranslate nohighlight">\(\mathbf v\)</span> is a <em>plane</em> with a normal vector <span class="math notranslate nohighlight">\(\mathbf v\)</span>. So when we project the <span class="math notranslate nohighlight">\(\mathbf v\)</span> on the line we get two components one is lying on the line and is the <span class="math notranslate nohighlight">\(\Pi_l \mathbf u\)</span> and the other is the vector <span class="math notranslate nohighlight">\(\mathbf w\)</span> = <span class="math notranslate nohighlight">\(\Pi_{l^\perp} \mathbf u = \mathbf u - \mathbf v = \mathbf u - \Pi_{\mathbf v} \mathbf u \)</span>. The vector <span class="math notranslate nohighlight">\(\mathbf w\)</span> is what remains when we remove the projected on <span class="math notranslate nohighlight">\(\mathbf v\)</span> part from the <span class="math notranslate nohighlight">\(\mathbf u\)</span>.</p>
</section>
<section id="the-four-fundamental-subspaces">
<h3>The Four Fundamental Subspaces<a class="headerlink" href="#the-four-fundamental-subspaces" title="Permalink to this heading">#</a></h3>
<p><img alt="Four fundamental spaces" src="../../../../_images/four-fundamental-spaces-linear-alg.png" /></p>
<p>The <em>fundamental theorem of Linear Algebra</em> specifies the effect of the multiplication operation of the matrix and a vector (<span class="math notranslate nohighlight">\(A\mathbf{x}\)</span>). The matrix gives raise to 4 subspaces:</p>
<ol class="arabic simple">
<li><p><strong>The column space of <span class="math notranslate nohighlight">\(A\)</span></strong>, denoted by <span class="math notranslate nohighlight">\(\mathcal{R}(A)\)</span>, with dimension <span class="math notranslate nohighlight">\(r\)</span>.</p></li>
<li><p><strong>The nullspace of <span class="math notranslate nohighlight">\(A\)</span></strong>, denoted by <span class="math notranslate nohighlight">\(\mathcal{N}(A)\)</span>, with dimension <span class="math notranslate nohighlight">\(n-r\)</span>.</p></li>
<li><p><strong>The row space of <span class="math notranslate nohighlight">\(A\)</span></strong> which is the column space of <span class="math notranslate nohighlight">\(A^T\)</span>, with dimension <span class="math notranslate nohighlight">\(r\)</span></p></li>
<li><p><strong>The left nullspace of <span class="math notranslate nohighlight">\(A\)</span></strong>, which is the nullspace of <span class="math notranslate nohighlight">\(A^T\)</span>, denoted by <span class="math notranslate nohighlight">\(\mathcal{N}(A^T)\)</span>, with dimension <span class="math notranslate nohighlight">\(m-r\)</span>.</p></li>
</ol>
<p>The real action that the matrix performs is to <strong>transform</strong> its row space to its column space.</p>
<p>The type of matrices that are common in ML are those that the number of rows <span class="math notranslate nohighlight">\(m\)</span> representing observations is much larger than the number of columns <span class="math notranslate nohighlight">\(n\)</span> that represent features. We will call these matrices “tall” for obvious reasons. Let us consider one trivial but instructive example of the smallest possible “tall” matrix:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix} a_{11} &amp; a_{12} \\ a_{21}  &amp; a_{22} \\ a_{31} &amp; a_{32} \end{bmatrix} = \begin{bmatrix} 1       &amp; 0 \\ 5       &amp; 4 \\ 2       &amp; 4 \end{bmatrix}\end{split}\]</div>
<p>In ML we are usually concerned with the problem of learning the weights <span class="math notranslate nohighlight">\(x_1, x_2\)</span> that will combine the features and result into the given target variables <span class="math notranslate nohighlight">\(\mathbf{b}\)</span>. The notation here is different and we have adopted the notation of many linear algebra textbooks.</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{bmatrix} 1       &amp; 0 \\ 5       &amp; 4 \\ 2       &amp; 4 \end{bmatrix}  \begin{bmatrix} x_1 \\ x_2  \end{bmatrix} =
\begin{bmatrix} b_1 \\ b_2 \\  b_3  \end{bmatrix}\end{split}\]</div>
<p>To make more explicit the combination of features we can write,</p>
<div class="math notranslate nohighlight">
\[\begin{split} x_1 \begin{bmatrix} 1 \\ 5 \\ 2 \end{bmatrix} + x_2 \begin{bmatrix} 0 \\ 4 \\  4  \end{bmatrix} = \begin{bmatrix} b_1 \\ b_2 \\  b_3  \end{bmatrix}\end{split}\]</div>
<p>Since <span class="math notranslate nohighlight">\(m=3 &gt; n=2\)</span>, we have more equations than unknowns we in general we have no solutions - a system with <span class="math notranslate nohighlight">\(m &gt; n\)</span> will be solvable only for certain right hand sides <span class="math notranslate nohighlight">\(\mathbf{b}\)</span>. Those are all the vectors <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> that lie in the column space of <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p><img alt="column-space" src="../../../../_images/column-space.png" /></p>
<p>In this example, as shown in the picture <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> must lie in the plane spanned by the two columns of <span class="math notranslate nohighlight">\(A\)</span>. The plane is a subspace of <span class="math notranslate nohighlight">\(\mathbb{R}^m=\mathbb{R}^3\)</span> in this case.</p>
<p>Now instead of looking at what properties <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> must have for the system to have a solution, lets look at the <em>dual</em> problem i.e. what weights <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> can attain those <span class="math notranslate nohighlight">\(\mathbf{b}\)</span>. The right-hand side <span class="math notranslate nohighlight">\(\mathbf{b}=0\)</span> always allows the solution <span class="math notranslate nohighlight">\(\mathbf{x}=0\)</span>
The solutions to <span class="math notranslate nohighlight">\(A \mathbf{x} = \mathbf{0}\)</span> form a vector space - <strong>the nullspace</strong> <span class="math notranslate nohighlight">\(\mathcal{N}(A)\)</span>. The nullspace is also called the <em>kernel</em> of matrix <span class="math notranslate nohighlight">\(A\)</span> and the its dimension <span class="math notranslate nohighlight">\(n-r\)</span> is called the nullity.</p>
<p><span class="math notranslate nohighlight">\(\mathcal{N}(A)\)</span> is a subspace of <span class="math notranslate nohighlight">\(\mathbb{R}^n=\mathbb{R}^2\)</span> in this case. For our specific example,</p>
<div class="math notranslate nohighlight">
\[\begin{split} x_1 \begin{bmatrix} 1 \\ 5 \\ 2 \end{bmatrix} + x_2 \begin{bmatrix} 0 \\ 4 \\  4  \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \\  0  \end{bmatrix}\end{split}\]</div>
<p>the only solution that can satisfy this set of homogenous equations is: <span class="math notranslate nohighlight">\(\mathbf{x}=\mathbf{0}\)</span> and this means that the null space contains only the zero vector and this</p>
<p>Two vectors are independent when their linear combination cannot be zero, unless both <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span> are zero.  The columns of <span class="math notranslate nohighlight">\(A\)</span> are therefore linearly independent and they span the column space. They have therefore all the properties needed for them to constitute a set called the <em>basis</em> for that space and we have two basis vectors (the rank is <span class="math notranslate nohighlight">\(r=2\)</span> in this case). The dimension of the column space is in fact the same as the dimension of the row space (<span class="math notranslate nohighlight">\(r\)</span>) and the mapping from row space to column space is in fact invertible. Every vector <span class="math notranslate nohighlight">\(\mathbf{b}\)</span> comes from one and only one vector <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> of the row space (<span class="math notranslate nohighlight">\(\mathbf{x}_r\)</span>). And this vector can be found by the inverse operation - noting that only the inverse <span class="math notranslate nohighlight">\(A^{-1}\)</span> is the operation that moves the vector correctly from the column space to the row space. The inverse exists only if <span class="math notranslate nohighlight">\(r=m=n\)</span> - this is important as in most ML problems we are dealing with “tall” matrices with the number of equations much larger than the number of unknowns which makes the system <em>inconsistent</em> (or <em>degenerate</em>).</p>
<p><img alt="projection-column-space" src="../../../../_images/projection-column-space.png" />
<em>Projection onto the column space</em></p>
<p>Geometrically you can think about the basis vectors as the axes of the space. However, if the axes are not orthogonal, calculations will tend to be complicated not to mention that we usually attribute to each vector of the basis to have length one (1.0).</p>
</section>
<section id="eigenvalues-and-eigenvectors">
<h3>Eigenvalues and Eigenvectors<a class="headerlink" href="#eigenvalues-and-eigenvectors" title="Permalink to this heading">#</a></h3>
<p>The following video gives an intuitive explanation of eigenvalues and eigenvectors and its included here due to its visualizations that it offers.  The video must be viewed in conjunction with <a class="reference external" href="http://math.mit.edu/~gs/linearalgebra/linearalgebra5_6-1.pdf">Strang’s introduction</a></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/PFDu9oVAE-g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>A geometric interpretation of the eigenvectors and eigenvalues is given in the following figure:</p>
<p><img alt="eigenvectors" src="../../../../_images/eigenvectors.png" /></p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./aiml-common/lectures/ml-math/linear-algebra"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../probability/index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Probability Basics</p>
      </div>
    </a>
    <a class="right-next"
       href="../calculus/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Calculus</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-points">Key Points</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#projections">Projections</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-four-fundamental-subspaces">The Four Fundamental Subspaces</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eigenvalues-and-eigenvectors">Eigenvalues and Eigenvectors</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pantelis Monogioudis, Ph.D
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>