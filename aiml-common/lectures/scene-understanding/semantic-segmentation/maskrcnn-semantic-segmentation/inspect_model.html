
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>3.4. Mask R-CNN - Inspect Trained Model &#8212; Data Mining</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
    <script src="../../../../../_static/jquery.js"></script>
    <script src="../../../../../_static/underscore.js"></script>
    <script src="../../../../../_static/doctools.js"></script>
    <script src="../../../../../_static/clipboard.min.js"></script>
    <script src="../../../../../_static/copybutton.js"></script>
    <script src="../../../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://pantelis.github.io/data-mining/aiml-common/lectures/scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_model.html" />
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
    <link rel="next" title="3.15. Mask R-CNN - Inspect Weights of a Trained Model" href="inspect_weights.html" />
    <link rel="prev" title="3.3. Mask R-CNN - Inspect Training Data" href="inspect_data.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Mining</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Syllabus
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../../syllabus/_index.html">
   Syllabus
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Data Mining
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ai-intro/course-introduction/_index.html">
   1. Course Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ai-intro/data-science-360/_index.html">
   2. Data Science 360
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ai-intro/pipelines/_index.html">
   3. ML Pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../uber-ml-arch-case-study/_index.html">
   4. A Case Study of an ML Architecture - Uber
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The Learning Problem
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../learning-problem/_index.html">
   1. The Learning Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../regression/linear-regression/_index.html">
   2. Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../regression/linear-regression/regression-notebooks.html">
   3. Regression Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../optimization/maximum-likelihood/_index.html">
   4. Maximum Likelihood (ML) Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../entropy/_index.html">
   5. Entropy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../optimization/sgd/_index.html">
   6. Stochastic Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../classification/classification-intro/_index.html">
   7. Introduction to Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../classification/logistic-regression/_index.html">
   8. Logistic Regression
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deep Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../classification/perceptron/_index.html">
   1. The Neuron (Perceptron)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../dnn/dnn-intro/_index.html">
   2. Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../dnn/backprop-intro/_index.html">
   3. Introduction to Backpropagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../dnn/backprop-dnn/_index.html">
   4. Backpropagation in Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../dnn/backprop-dnn-exercises/_index.html">
   5. Backpropagation DNN exercises
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../dnn/fashion-mnist-case-study.html">
   6. Fashion MNIST Case Study
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../optimization/regularization/_index.html">
   7. Regularization in Deep Neural Networks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Convolutional Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cnn/cnn-intro/_index.html">
   1. Introduction to Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cnn/cnn-layers/_index.html">
   2. CNN Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cnn/cnn-example-architectures/_index.html">
   3. CNN Example Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">
   4. Using convnets with small datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../feature-extraction-resnet/index.html">
   5. Feature Extraction via Residual Networks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Transfer Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../transfer-learning/transfer-learning-introduction.html">
   1. Introduction to Transfer Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../transfer-learning/transfer_learning_tutorial.html">
   2. Transfer Learning for Computer Vision Tutorial
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Scene Understanding
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding-intro/index.html">
   1. Introduction to Scene Understanding
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../object-detection/object-detection-intro/index.html">
   2. Object Detection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../object-detection/detection-metrics/index.html">
     2.1. Object Detection and Semantic Segmentation Metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../object-detection/rcnn-object-detection/index.html">
     2.2. Region-CNN (RCNN) Object Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../object-detection/faster-rcnn-object-detection/index.html">
     2.3. Fast and Faster RCNN Object Detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   3. Semantic Segmentation
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="index.html">
     3.1. Mask R-CNN Semantic Segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="demo.html">
     3.2. Mask R-CNN Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="inspect_data.html">
     3.3. Mask R-CNN - Inspect Training Data
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     3.4. Mask R-CNN - Inspect Trained Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="inspect_weights.html">
     3.15. Mask R-CNN - Inspect Weights of a Trained Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="detectron2_tutorial.html">
     3.21. Detectron2 Beginner’s Tutorial
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Sequences and RNNs
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rnn/introduction/_index.html">
   1. Introduction to Recurrent Neural Networks (RNN)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rnn/simple-rnn/_index.html">
   2. Simple RNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rnn/lstm/_index.html">
   3. The Long Short-Term Memory (LSTM) Cell Architecture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../rnn/15_processing_sequences_using_rnns_and_cnns.html">
   4. Processing Sequences Using RNN
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Embeddings and NLP
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/nlp-intro/_index.html">
   1. Introduction to NLP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/word2vec/_index.html">
   2. Word2Vec Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/word2vec/word2vec-workshop.html">
   3. Word2Vec Workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/language-models/_index.html">
   4. RNN Language Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/language-models/simple-rnn-language-model.html">
   5. Simple RNN Language Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/language-models/cnn-language-model.html">
   6. CNN Language Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../nlp/nmt/_index.html">
   7. Neural Machine Translation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Classical Learning Methods
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../decision-trees/_index.html">
   1. Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../regression-trees/regression_trees.html">
   2. Regression tree stumps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ensemble/_index.html">
   4. Ensemble Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ensemble/random-forests/_index.html">
   5. Random Forests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ensemble/adaboost/index.html">
   6. Adaptive Boosting (AdaBoost)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ensemble/gradient-boosting/index.html">
   7. Gradient Boosting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../ensemble/boosting-workshop/_index.html">
   8. Boosting workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../pgm/bayesian-inference/_index.html">
   9. Bayesian Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../pgm/bayesian-coin/_index.html">
   10. Bayesian Coin Flipping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../classification/covid19-antibody-test/_index.html">
   11. COVID-19 Antibody Test
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Non-Parametric Methods
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../unsupervised/k-means/_index.html">
   1. K-means Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../density-estimation/knn/_index.html">
   2. k-Nearest Neighbors (kNN) Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../density-estimation/knn-workshop/_index.html">
   3. kNN Workshop
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dimensionality Reduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../pca/_index.html">
   1. Principal Component Analysis (PCA)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Math Background
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../ml-math/_index.html">
   1. Math for ML
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-math/probability/_index.html">
     1.1. Probability Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../linear-algebra/_index.html">
     1.2. Linear Algebra for Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../ml-math/calculus/_index.html">
     1.3. Calculus
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../python/_index.html">
   1. Learn Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Assignments &amp; Projects
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../assignments/probability/probability-assignment-3/index.html">
   1. Probability Assignment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../assignments/poisson-regression/index.html">
   3. Bike Rides and the Poisson Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../projects/visual-search-coco/index.html">
   4. Reverse Visual Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../projects/transfer-learning-home-depot/index.html">
   5. Transfer Learning for Custom Datasets in the Small-Data Regime
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/pantelis/data-mining"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/pantelis/data-mining/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_model.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../../../_sources/aiml-common/lectures/scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_model.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   3.4. Mask R-CNN - Inspect Trained Model
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#configurations">
   3.5. Configurations
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notebook-preferences">
   3.6. Notebook Preferences
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-validation-dataset">
   3.7. Load Validation Dataset
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-model">
   3.8. Load Model
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-detection">
   3.9. Run Detection
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#precision-recall">
     3.9.1. Precision-Recall
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compute-map-iou-50-on-batch-of-images">
     3.9.2. Compute mAP @ IoU=50 on Batch of Images
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-by-step-prediction">
   3.10. Step by Step Prediction
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stage-1-region-proposal-network">
   3.11. Stage 1: Region Proposal Network
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-rpn-targets">
     3.11.1. 1.a RPN Targets
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-rpn-predictions">
     3.11.2. 1.b RPN Predictions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stage-2-proposal-classification">
   3.12. Stage 2: Proposal Classification
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-proposal-classification">
     3.12.1. 2.a Proposal Classification
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#c-step-by-step-detection">
     3.12.2. 2.c Step by Step Detection
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#apply-bounding-box-refinement">
       Apply Bounding Box Refinement
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#filter-low-confidence-detections">
       Filter Low Confidence Detections
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#per-class-non-max-suppression">
       Per-Class Non-Max Suppression
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stage-3-generating-masks">
   3.13. Stage 3: Generating Masks
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-mask-targets">
     3.13.1. 3.a Mask Targets
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-predicted-masks">
     3.13.2. 3.b Predicted Masks
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualize-activations">
   3.14. Visualize Activations
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Mask R-CNN - Inspect Trained Model</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   3.4. Mask R-CNN - Inspect Trained Model
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#configurations">
   3.5. Configurations
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notebook-preferences">
   3.6. Notebook Preferences
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-validation-dataset">
   3.7. Load Validation Dataset
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-model">
   3.8. Load Model
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#run-detection">
   3.9. Run Detection
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#precision-recall">
     3.9.1. Precision-Recall
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compute-map-iou-50-on-batch-of-images">
     3.9.2. Compute mAP @ IoU=50 on Batch of Images
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-by-step-prediction">
   3.10. Step by Step Prediction
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stage-1-region-proposal-network">
   3.11. Stage 1: Region Proposal Network
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-rpn-targets">
     3.11.1. 1.a RPN Targets
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-rpn-predictions">
     3.11.2. 1.b RPN Predictions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stage-2-proposal-classification">
   3.12. Stage 2: Proposal Classification
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-proposal-classification">
     3.12.1. 2.a Proposal Classification
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#c-step-by-step-detection">
     3.12.2. 2.c Step by Step Detection
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#apply-bounding-box-refinement">
       Apply Bounding Box Refinement
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#filter-low-confidence-detections">
       Filter Low Confidence Detections
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#per-class-non-max-suppression">
       Per-Class Non-Max Suppression
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#stage-3-generating-masks">
   3.13. Stage 3: Generating Masks
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-mask-targets">
     3.13.1. 3.a Mask Targets
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#b-predicted-masks">
     3.13.2. 3.b Predicted Masks
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#visualize-activations">
   3.14. Visualize Activations
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section id="mask-r-cnn-inspect-trained-model">
<h1><span class="section-number">3.4. </span>Mask R-CNN - Inspect Trained Model<a class="headerlink" href="#mask-r-cnn-inspect-trained-model" title="Permalink to this headline">#</a></h1>
<p>Code and visualizations to test, debug, and evaluate the Mask R-CNN model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
import sys
import random
import math
import re
import time
import numpy as np
import tensorflow as tf
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.patches as patches

# Root directory of the project
ROOT_DIR = os.path.abspath(&quot;../../&quot;)

# Import Mask RCNN
sys.path.append(ROOT_DIR)  # To find local version of the library
from mrcnn import utils
from mrcnn import visualize
from mrcnn.visualize import display_images
import mrcnn.model as modellib
from mrcnn.model import log

%matplotlib inline 

# Directory to save logs and trained model
MODEL_DIR = os.path.join(ROOT_DIR, &quot;logs&quot;)

# Local path to trained weights file
COCO_MODEL_PATH = os.path.join(ROOT_DIR, &quot;mask_rcnn_coco.h5&quot;)
# Download COCO trained weights from Releases if needed
if not os.path.exists(COCO_MODEL_PATH):
    utils.download_trained_weights(COCO_MODEL_PATH)

# Path to Shapes trained weights
SHAPES_MODEL_PATH = os.path.join(ROOT_DIR, &quot;mask_rcnn_shapes.h5&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using TensorFlow backend.
</pre></div>
</div>
</div>
</div>
</section>
<section id="configurations">
<h1><span class="section-number">3.5. </span>Configurations<a class="headerlink" href="#configurations" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Run one of the code blocks

# Shapes toy dataset
# import shapes
# config = shapes.ShapesConfig()

# MS COCO Dataset
import coco
config = coco.CocoConfig()
COCO_DIR = &quot;path to COCO dataset&quot;  # TODO: enter value here
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Override the training configurations with a few
# changes for inferencing.
class InferenceConfig(config.__class__):
    # Run detection on one image at a time
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1

config = InferenceConfig()
config.display()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Configurations:
BACKBONE_SHAPES                [[256 256]
 [128 128]
 [ 64  64]
 [ 32  32]
 [ 16  16]]
BACKBONE_STRIDES               [4, 8, 16, 32, 64]
BATCH_SIZE                     1
BBOX_STD_DEV                   [ 0.1  0.1  0.2  0.2]
DETECTION_MAX_INSTANCES        100
DETECTION_MIN_CONFIDENCE       0.5
DETECTION_NMS_THRESHOLD        0.3
GPU_COUNT                      1
IMAGES_PER_GPU                 1
IMAGE_MAX_DIM                  1024
IMAGE_MIN_DIM                  800
IMAGE_PADDING                  True
IMAGE_SHAPE                    [1024 1024    3]
LEARNING_MOMENTUM              0.9
LEARNING_RATE                  0.002
MASK_POOL_SIZE                 14
MASK_SHAPE                     [28, 28]
MAX_GT_INSTANCES               100
MEAN_PIXEL                     [ 123.7  116.8  103.9]
MINI_MASK_SHAPE                (56, 56)
NAME                           coco
NUM_CLASSES                    81
POOL_SIZE                      7
POST_NMS_ROIS_INFERENCE        1000
POST_NMS_ROIS_TRAINING         2000
ROI_POSITIVE_RATIO             0.33
RPN_ANCHOR_RATIOS              [0.5, 1, 2]
RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)
RPN_ANCHOR_STRIDE              2
RPN_BBOX_STD_DEV               [ 0.1  0.1  0.2  0.2]
RPN_TRAIN_ANCHORS_PER_IMAGE    256
STEPS_PER_EPOCH                1000
TRAIN_ROIS_PER_IMAGE           128
USE_MINI_MASK                  True
USE_RPN_ROIS                   True
VALIDATION_STEPS               50
WEIGHT_DECAY                   0.0001
</pre></div>
</div>
</div>
</div>
</section>
<section id="notebook-preferences">
<h1><span class="section-number">3.6. </span>Notebook Preferences<a class="headerlink" href="#notebook-preferences" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Device to load the neural network on.
# Useful if you&#39;re training a model on the same 
# machine, in which case use CPU and leave the
# GPU for training.
DEVICE = &quot;/cpu:0&quot;  # /cpu:0 or /gpu:0

# Inspect the model in training or inference modes
# values: &#39;inference&#39; or &#39;training&#39;
# TODO: code for &#39;training&#39; test mode not ready yet
TEST_MODE = &quot;inference&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def get_ax(rows=1, cols=1, size=16):
    &quot;&quot;&quot;Return a Matplotlib Axes array to be used in
    all visualizations in the notebook. Provide a
    central point to control graph sizes.
    
    Adjust the size attribute to control how big to render images
    &quot;&quot;&quot;
    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))
    return ax
</pre></div>
</div>
</div>
</div>
</section>
<section id="load-validation-dataset">
<h1><span class="section-number">3.7. </span>Load Validation Dataset<a class="headerlink" href="#load-validation-dataset" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Build validation dataset
if config.NAME == &#39;shapes&#39;:
    dataset = shapes.ShapesDataset()
    dataset.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])
elif config.NAME == &quot;coco&quot;:
    dataset = coco.CocoDataset()
    dataset.load_coco(COCO_DIR, &quot;minival&quot;)

# Must call before using the dataset
dataset.prepare()

print(&quot;Images: {}\nClasses: {}&quot;.format(len(dataset.image_ids), dataset.class_names))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loading annotations into memory...
Done (t=4.86s)
creating index...
index created!
Images: 35185
Classes: [&#39;BG&#39;, &#39;person&#39;, &#39;bicycle&#39;, &#39;car&#39;, &#39;motorcycle&#39;, &#39;airplane&#39;, &#39;bus&#39;, &#39;train&#39;, &#39;truck&#39;, &#39;boat&#39;, &#39;traffic light&#39;, &#39;fire hydrant&#39;, &#39;stop sign&#39;, &#39;parking meter&#39;, &#39;bench&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;horse&#39;, &#39;sheep&#39;, &#39;cow&#39;, &#39;elephant&#39;, &#39;bear&#39;, &#39;zebra&#39;, &#39;giraffe&#39;, &#39;backpack&#39;, &#39;umbrella&#39;, &#39;handbag&#39;, &#39;tie&#39;, &#39;suitcase&#39;, &#39;frisbee&#39;, &#39;skis&#39;, &#39;snowboard&#39;, &#39;sports ball&#39;, &#39;kite&#39;, &#39;baseball bat&#39;, &#39;baseball glove&#39;, &#39;skateboard&#39;, &#39;surfboard&#39;, &#39;tennis racket&#39;, &#39;bottle&#39;, &#39;wine glass&#39;, &#39;cup&#39;, &#39;fork&#39;, &#39;knife&#39;, &#39;spoon&#39;, &#39;bowl&#39;, &#39;banana&#39;, &#39;apple&#39;, &#39;sandwich&#39;, &#39;orange&#39;, &#39;broccoli&#39;, &#39;carrot&#39;, &#39;hot dog&#39;, &#39;pizza&#39;, &#39;donut&#39;, &#39;cake&#39;, &#39;chair&#39;, &#39;couch&#39;, &#39;potted plant&#39;, &#39;bed&#39;, &#39;dining table&#39;, &#39;toilet&#39;, &#39;tv&#39;, &#39;laptop&#39;, &#39;mouse&#39;, &#39;remote&#39;, &#39;keyboard&#39;, &#39;cell phone&#39;, &#39;microwave&#39;, &#39;oven&#39;, &#39;toaster&#39;, &#39;sink&#39;, &#39;refrigerator&#39;, &#39;book&#39;, &#39;clock&#39;, &#39;vase&#39;, &#39;scissors&#39;, &#39;teddy bear&#39;, &#39;hair drier&#39;, &#39;toothbrush&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="load-model">
<h1><span class="section-number">3.8. </span>Load Model<a class="headerlink" href="#load-model" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Create model in inference mode
with tf.device(DEVICE):
    model = modellib.MaskRCNN(mode=&quot;inference&quot;, model_dir=MODEL_DIR,
                              config=config)

# Set weights file path
if config.NAME == &quot;shapes&quot;:
    weights_path = SHAPES_MODEL_PATH
elif config.NAME == &quot;coco&quot;:
    weights_path = COCO_MODEL_PATH
# Or, uncomment to load the last model you trained
# weights_path = model.find_last()

# Load weights
print(&quot;Loading weights &quot;, weights_path)
model.load_weights(weights_path, by_name=True)
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-detection">
<h1><span class="section-number">3.9. </span>Run Detection<a class="headerlink" href="#run-detection" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>image_id = random.choice(dataset.image_ids)
image, image_meta, gt_class_id, gt_bbox, gt_mask =\
    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)
info = dataset.image_info[image_id]
print(&quot;image ID: {}.{} ({}) {}&quot;.format(info[&quot;source&quot;], info[&quot;id&quot;], image_id, 
                                       dataset.image_reference(image_id)))
# Run object detection
results = model.detect([image], verbose=1)

# Display results
ax = get_ax(1)
r = results[0]
visualize.display_instances(image, r[&#39;rois&#39;], r[&#39;masks&#39;], r[&#39;class_ids&#39;], 
                            dataset.class_names, r[&#39;scores&#39;], ax=ax,
                            title=&quot;Predictions&quot;)
log(&quot;gt_class_id&quot;, gt_class_id)
log(&quot;gt_bbox&quot;, gt_bbox)
log(&quot;gt_mask&quot;, gt_mask)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>image ID: coco.392144 (34940) http://cocodataset.org/#explore?id=392144
Processing 1 images
image                    shape: (1024, 1024, 3)       min:    0.00000  max:  255.00000
molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000
image_metas              shape: (1, 89)               min:    0.00000  max: 1024.00000
gt_class_id              shape: (10,)                 min:    1.00000  max:   40.00000
gt_bbox                  shape: (10, 5)               min:    0.00000  max: 1024.00000
gt_mask                  shape: (1024, 1024, 10)      min:    0.00000  max:    1.00000
</pre></div>
</div>
<img alt="../../../../../_images/inspect_model_13_1.png" src="../../../../../_images/inspect_model_13_1.png" />
</div>
</div>
<section id="precision-recall">
<h2><span class="section-number">3.9.1. </span>Precision-Recall<a class="headerlink" href="#precision-recall" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Draw precision-recall curve
AP, precisions, recalls, overlaps = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,
                                          r[&#39;rois&#39;], r[&#39;class_ids&#39;], r[&#39;scores&#39;], r[&#39;masks&#39;])
visualize.plot_precision_recall(AP, precisions, recalls)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_15_0.png" src="../../../../../_images/inspect_model_15_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Grid of ground truth objects and their predictions
visualize.plot_overlaps(gt_class_id, r[&#39;class_ids&#39;], r[&#39;scores&#39;],
                        overlaps, dataset.class_names)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_16_0.png" src="../../../../../_images/inspect_model_16_0.png" />
</div>
</div>
</section>
<section id="compute-map-iou-50-on-batch-of-images">
<h2><span class="section-number">3.9.2. </span>Compute mAP &#64; IoU=50 on Batch of Images<a class="headerlink" href="#compute-map-iou-50-on-batch-of-images" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Compute VOC-style Average Precision
def compute_batch_ap(image_ids):
    APs = []
    for image_id in image_ids:
        # Load image
        image, image_meta, gt_class_id, gt_bbox, gt_mask =\
            modellib.load_image_gt(dataset, config,
                                   image_id, use_mini_mask=False)
        # Run object detection
        results = model.detect([image], verbose=0)
        # Compute AP
        r = results[0]
        AP, precisions, recalls, overlaps =\
            utils.compute_ap(gt_bbox, gt_class_id, gt_mask,
                              r[&#39;rois&#39;], r[&#39;class_ids&#39;], r[&#39;scores&#39;], r[&#39;masks&#39;])
        APs.append(AP)
    return APs

# Pick a set of random images
image_ids = np.random.choice(dataset.image_ids, 10)
APs = compute_batch_ap(image_ids)
print(&quot;mAP @ IoU=50: &quot;, np.mean(APs))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.5/dist-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.
  &quot;the returned array has changed.&quot;, UserWarning)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mAP @ IoU=50:  0.656323084916
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="step-by-step-prediction">
<h1><span class="section-number">3.10. </span>Step by Step Prediction<a class="headerlink" href="#step-by-step-prediction" title="Permalink to this headline">#</a></h1>
</section>
<section id="stage-1-region-proposal-network">
<h1><span class="section-number">3.11. </span>Stage 1: Region Proposal Network<a class="headerlink" href="#stage-1-region-proposal-network" title="Permalink to this headline">#</a></h1>
<p>The Region Proposal Network (RPN) runs a lightweight binary classifier on a lot of boxes (anchors) over the image and returns object/no-object scores. Anchors with high <em>objectness</em> score (positive anchors) are passed to the stage two to be classified.</p>
<p>Often, even positive anchors don’t cover objects fully. So the RPN also regresses a refinement (a delta in location and size) to be applied to the anchors to shift it and resize it a bit to the correct boundaries of the object.</p>
<section id="a-rpn-targets">
<h2><span class="section-number">3.11.1. </span>1.a RPN Targets<a class="headerlink" href="#a-rpn-targets" title="Permalink to this headline">#</a></h2>
<p>The RPN targets are the training values for the RPN. To generate the targets, we start with a grid of anchors that cover the full image at different scales, and then we compute the IoU of the anchors with ground truth object. Positive anchors are those that have an IoU &gt;= 0.7 with any ground truth object, and negative anchors are those that don’t cover any object by more than 0.3 IoU. Anchors in between (i.e. cover an object by IoU &gt;= 0.3 but &lt; 0.7) are considered neutral and excluded from training.</p>
<p>To train the RPN regressor, we also compute the shift and resizing needed to make the anchor cover the ground truth object completely.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Generate RPN trainig targets
# target_rpn_match is 1 for positive anchors, -1 for negative anchors
# and 0 for neutral anchors.
target_rpn_match, target_rpn_bbox = modellib.build_rpn_targets(
    image.shape, model.anchors, gt_class_id, gt_bbox, model.config)
log(&quot;target_rpn_match&quot;, target_rpn_match)
log(&quot;target_rpn_bbox&quot;, target_rpn_bbox)

positive_anchor_ix = np.where(target_rpn_match[:] == 1)[0]
negative_anchor_ix = np.where(target_rpn_match[:] == -1)[0]
neutral_anchor_ix = np.where(target_rpn_match[:] == 0)[0]
positive_anchors = model.anchors[positive_anchor_ix]
negative_anchors = model.anchors[negative_anchor_ix]
neutral_anchors = model.anchors[neutral_anchor_ix]
log(&quot;positive_anchors&quot;, positive_anchors)
log(&quot;negative_anchors&quot;, negative_anchors)
log(&quot;neutral anchors&quot;, neutral_anchors)

# Apply refinement deltas to positive anchors
refined_anchors = utils.apply_box_deltas(
    positive_anchors,
    target_rpn_bbox[:positive_anchors.shape[0]] * model.config.RPN_BBOX_STD_DEV)
log(&quot;refined_anchors&quot;, refined_anchors, )
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>target_rpn_match         shape: (65472,)              min:   -1.00000  max:    1.00000
target_rpn_bbox          shape: (256, 4)              min:   -5.19860  max:    2.59641
positive_anchors         shape: (14, 4)               min:    5.49033  max:  973.25483
negative_anchors         shape: (242, 4)              min:  -22.62742  max: 1038.62742
neutral anchors          shape: (65216, 4)            min: -362.03867  max: 1258.03867
refined_anchors          shape: (14, 4)               min:    0.00000  max: 1023.99994
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Display positive anchors before refinement (dotted) and
# after refinement (solid).
visualize.draw_boxes(image, boxes=positive_anchors, refined_boxes=refined_anchors, ax=get_ax())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_23_0.png" src="../../../../../_images/inspect_model_23_0.png" />
</div>
</div>
</section>
<section id="b-rpn-predictions">
<h2><span class="section-number">3.11.2. </span>1.b RPN Predictions<a class="headerlink" href="#b-rpn-predictions" title="Permalink to this headline">#</a></h2>
<p>Here we run the RPN graph and display its predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Run RPN sub-graph
pillar = model.keras_model.get_layer(&quot;ROI&quot;).output  # node to start searching from

# TF 1.4 and 1.9 introduce new versions of NMS. Search for all names to support TF 1.3~1.10
nms_node = model.ancestor(pillar, &quot;ROI/rpn_non_max_suppression:0&quot;)
if nms_node is None:
    nms_node = model.ancestor(pillar, &quot;ROI/rpn_non_max_suppression/NonMaxSuppressionV2:0&quot;)
if nms_node is None: #TF 1.9-1.10
    nms_node = model.ancestor(pillar, &quot;ROI/rpn_non_max_suppression/NonMaxSuppressionV3:0&quot;)

rpn = model.run_graph([image], [
    (&quot;rpn_class&quot;, model.keras_model.get_layer(&quot;rpn_class&quot;).output),
    (&quot;pre_nms_anchors&quot;, model.ancestor(pillar, &quot;ROI/pre_nms_anchors:0&quot;)),
    (&quot;refined_anchors&quot;, model.ancestor(pillar, &quot;ROI/refined_anchors:0&quot;)),
    (&quot;refined_anchors_clipped&quot;, model.ancestor(pillar, &quot;ROI/refined_anchors_clipped:0&quot;)),
    (&quot;post_nms_anchor_ix&quot;, nms_node),
    (&quot;proposals&quot;, model.keras_model.get_layer(&quot;ROI&quot;).output),
])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>rpn_class                shape: (1, 65472, 2)         min:    0.00000  max:    1.00000
pre_nms_anchors          shape: (1, 10000, 4)         min: -362.03867  max: 1258.03870
refined_anchors          shape: (1, 10000, 4)         min: -1385.67920  max: 2212.44043
refined_anchors_clipped  shape: (1, 10000, 4)         min:    0.00000  max: 1024.00000
post_nms_anchor_ix       shape: (1000,)               min:    0.00000  max: 1477.00000
proposals                shape: (1, 1000, 4)          min:    0.00000  max:    1.00000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Show top anchors by score (before refinement)
limit = 100
sorted_anchor_ids = np.argsort(rpn[&#39;rpn_class&#39;][:,:,1].flatten())[::-1]
visualize.draw_boxes(image, boxes=model.anchors[sorted_anchor_ids[:limit]], ax=get_ax())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_26_0.png" src="../../../../../_images/inspect_model_26_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Show top anchors with refinement. Then with clipping to image boundaries
limit = 50
ax = get_ax(1, 2)
pre_nms_anchors = utils.denorm_boxes(rpn[&quot;pre_nms_anchors&quot;][0], image.shape[:2])
refined_anchors = utils.denorm_boxes(rpn[&quot;refined_anchors&quot;][0], image.shape[:2])
refined_anchors_clipped = utils.denorm_boxes(rpn[&quot;refined_anchors_clipped&quot;][0], image.shape[:2])
visualize.draw_boxes(image, boxes=pre_nms_anchors[:limit],
                     refined_boxes=refined_anchors[:limit], ax=ax[0])
visualize.draw_boxes(image, refined_boxes=refined_anchors_clipped[:limit], ax=ax[1])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_27_0.png" src="../../../../../_images/inspect_model_27_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Show refined anchors after non-max suppression
limit = 50
ixs = rpn[&quot;post_nms_anchor_ix&quot;][:limit]
visualize.draw_boxes(image, refined_boxes=refined_anchors_clipped[ixs], ax=get_ax())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_28_0.png" src="../../../../../_images/inspect_model_28_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Show final proposals
# These are the same as the previous step (refined anchors 
# after NMS) but with coordinates normalized to [0, 1] range.
limit = 50
# Convert back to image coordinates for display
h, w = config.IMAGE_SHAPE[:2]
proposals = rpn[&#39;proposals&#39;][0, :limit] * np.array([h, w, h, w])
visualize.draw_boxes(image, refined_boxes=proposals, ax=get_ax())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_29_0.png" src="../../../../../_images/inspect_model_29_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Measure the RPN recall (percent of objects covered by anchors)
# Here we measure recall for 3 different methods:
# - All anchors
# - All refined anchors
# - Refined anchors after NMS
iou_threshold = 0.7

recall, positive_anchor_ids = utils.compute_recall(model.anchors, gt_bbox, iou_threshold)
print(&quot;All Anchors ({:5})       Recall: {:.3f}  Positive anchors: {}&quot;.format(
    model.anchors.shape[0], recall, len(positive_anchor_ids)))

recall, positive_anchor_ids = utils.compute_recall(rpn[&#39;refined_anchors&#39;][0], gt_bbox, iou_threshold)
print(&quot;Refined Anchors ({:5})   Recall: {:.3f}  Positive anchors: {}&quot;.format(
    rpn[&#39;refined_anchors&#39;].shape[1], recall, len(positive_anchor_ids)))

recall, positive_anchor_ids = utils.compute_recall(proposals, gt_bbox, iou_threshold)
print(&quot;Post NMS Anchors ({:5})  Recall: {:.3f}  Positive anchors: {}&quot;.format(
    proposals.shape[0], recall, len(positive_anchor_ids)))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>All Anchors (65472)       Recall: 0.400  Positive anchors: 8
Refined Anchors (10000)   Recall: 0.900  Positive anchors: 65
Post NMS Anchors (   50)  Recall: 0.800  Positive anchors: 9
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="stage-2-proposal-classification">
<h1><span class="section-number">3.12. </span>Stage 2: Proposal Classification<a class="headerlink" href="#stage-2-proposal-classification" title="Permalink to this headline">#</a></h1>
<p>This stage takes the region proposals from the RPN and classifies them.</p>
<section id="a-proposal-classification">
<h2><span class="section-number">3.12.1. </span>2.a Proposal Classification<a class="headerlink" href="#a-proposal-classification" title="Permalink to this headline">#</a></h2>
<p>Run the classifier heads on proposals to generate class propbabilities and bounding box regressions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Get input and output to classifier and mask heads.
mrcnn = model.run_graph([image], [
    (&quot;proposals&quot;, model.keras_model.get_layer(&quot;ROI&quot;).output),
    (&quot;probs&quot;, model.keras_model.get_layer(&quot;mrcnn_class&quot;).output),
    (&quot;deltas&quot;, model.keras_model.get_layer(&quot;mrcnn_bbox&quot;).output),
    (&quot;masks&quot;, model.keras_model.get_layer(&quot;mrcnn_mask&quot;).output),
    (&quot;detections&quot;, model.keras_model.get_layer(&quot;mrcnn_detection&quot;).output),
])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>proposals                shape: (1, 1000, 4)          min:    0.00000  max:    1.00000
probs                    shape: (1, 1000, 81)         min:    0.00000  max:    0.99999
deltas                   shape: (1, 1000, 81, 4)      min:   -3.26400  max:    3.83929
masks                    shape: (1, 100, 28, 28, 81)  min:    0.00000  max:    0.99984
detections               shape: (1, 100, 6)           min:    0.00000  max:  844.00000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Get detection class IDs. Trim zero padding.
det_class_ids = mrcnn[&#39;detections&#39;][0, :, 4].astype(np.int32)
det_count = np.where(det_class_ids == 0)[0][0]
det_class_ids = det_class_ids[:det_count]
detections = mrcnn[&#39;detections&#39;][0, :det_count]

print(&quot;{} detections: {}&quot;.format(
    det_count, np.array(dataset.class_names)[det_class_ids]))

captions = [&quot;{} {:.3f}&quot;.format(dataset.class_names[int(c)], s) if c &gt; 0 else &quot;&quot;
            for c, s in zip(detections[:, 4], detections[:, 5])]
visualize.draw_boxes(
    image, 
    refined_boxes=utils.denorm_boxes(detections[:, :4], image.shape[:2]),
    visibilities=[2] * len(detections),
    captions=captions, title=&quot;Detections&quot;,
    ax=get_ax())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>8 detections: [&#39;person&#39; &#39;person&#39; &#39;person&#39; &#39;person&#39; &#39;person&#39; &#39;airplane&#39; &#39;airplane&#39; &#39;car&#39;]
</pre></div>
</div>
<img alt="../../../../../_images/inspect_model_34_1.png" src="../../../../../_images/inspect_model_34_1.png" />
</div>
</div>
</section>
<section id="c-step-by-step-detection">
<h2><span class="section-number">3.12.2. </span>2.c Step by Step Detection<a class="headerlink" href="#c-step-by-step-detection" title="Permalink to this headline">#</a></h2>
<p>Here we dive deeper into the process of processing the detections.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Proposals are in normalized coordinates. Scale them
# to image coordinates.
h, w = config.IMAGE_SHAPE[:2]
proposals = np.around(mrcnn[&quot;proposals&quot;][0] * np.array([h, w, h, w])).astype(np.int32)

# Class ID, score, and mask per proposal
roi_class_ids = np.argmax(mrcnn[&quot;probs&quot;][0], axis=1)
roi_scores = mrcnn[&quot;probs&quot;][0, np.arange(roi_class_ids.shape[0]), roi_class_ids]
roi_class_names = np.array(dataset.class_names)[roi_class_ids]
roi_positive_ixs = np.where(roi_class_ids &gt; 0)[0]

# How many ROIs vs empty rows?
print(&quot;{} Valid proposals out of {}&quot;.format(np.sum(np.any(proposals, axis=1)), proposals.shape[0]))
print(&quot;{} Positive ROIs&quot;.format(len(roi_positive_ixs)))

# Class counts
print(list(zip(*np.unique(roi_class_names, return_counts=True))))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1000 Valid proposals out of 1000
71 Positive ROIs
[(&#39;BG&#39;, 929), (&#39;airplane&#39;, 23), (&#39;car&#39;, 11), (&#39;person&#39;, 37)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Display a random sample of proposals.
# Proposals classified as background are dotted, and
# the rest show their class and confidence score.
limit = 200
ixs = np.random.randint(0, proposals.shape[0], limit)
captions = [&quot;{} {:.3f}&quot;.format(dataset.class_names[c], s) if c &gt; 0 else &quot;&quot;
            for c, s in zip(roi_class_ids[ixs], roi_scores[ixs])]
visualize.draw_boxes(image, boxes=proposals[ixs],
                     visibilities=np.where(roi_class_ids[ixs] &gt; 0, 2, 1),
                     captions=captions, title=&quot;ROIs Before Refinement&quot;,
                     ax=get_ax())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_37_0.png" src="../../../../../_images/inspect_model_37_0.png" />
</div>
</div>
<section id="apply-bounding-box-refinement">
<h3>Apply Bounding Box Refinement<a class="headerlink" href="#apply-bounding-box-refinement" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Class-specific bounding box shifts.
roi_bbox_specific = mrcnn[&quot;deltas&quot;][0, np.arange(proposals.shape[0]), roi_class_ids]
log(&quot;roi_bbox_specific&quot;, roi_bbox_specific)

# Apply bounding box transformations
# Shape: [N, (y1, x1, y2, x2)]
refined_proposals = utils.apply_box_deltas(
    proposals, roi_bbox_specific * config.BBOX_STD_DEV).astype(np.int32)
log(&quot;refined_proposals&quot;, refined_proposals)

# Show positive proposals
# ids = np.arange(roi_boxes.shape[0])  # Display all
limit = 5
ids = np.random.randint(0, len(roi_positive_ixs), limit)  # Display random sample
captions = [&quot;{} {:.3f}&quot;.format(dataset.class_names[c], s) if c &gt; 0 else &quot;&quot;
            for c, s in zip(roi_class_ids[roi_positive_ixs][ids], roi_scores[roi_positive_ixs][ids])]
visualize.draw_boxes(image, boxes=proposals[roi_positive_ixs][ids],
                     refined_boxes=refined_proposals[roi_positive_ixs][ids],
                     visibilities=np.where(roi_class_ids[roi_positive_ixs][ids] &gt; 0, 1, 0),
                     captions=captions, title=&quot;ROIs After Refinement&quot;,
                     ax=get_ax())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>roi_bbox_specific        shape: (1000, 4)             min:   -2.44748  max:    2.94838
refined_proposals        shape: (1000, 4)             min:   -8.00000  max: 1028.00000
</pre></div>
</div>
<img alt="../../../../../_images/inspect_model_39_1.png" src="../../../../../_images/inspect_model_39_1.png" />
</div>
</div>
</section>
<section id="filter-low-confidence-detections">
<h3>Filter Low Confidence Detections<a class="headerlink" href="#filter-low-confidence-detections" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Remove boxes classified as background
keep = np.where(roi_class_ids &gt; 0)[0]
print(&quot;Keep {} detections:\n{}&quot;.format(keep.shape[0], keep))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Keep 71 detections:
[  0   2   3   4   5   6   8   9  16  17  18  19  25  30  36  37  38  40
  42  50  51  67  68  74  78  79  92 158 162 177 187 191 209 225 261 284
 292 314 328 374 402 403 409 429 473 490 499 516 545 557 572 575 607 624
 638 639 671 703 719 744 753 754 778 790 813 815 848 862 865 876 911]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Remove low confidence detections
keep = np.intersect1d(keep, np.where(roi_scores &gt;= config.DETECTION_MIN_CONFIDENCE)[0])
print(&quot;Remove boxes below {} confidence. Keep {}:\n{}&quot;.format(
    config.DETECTION_MIN_CONFIDENCE, keep.shape[0], keep))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Remove boxes below 0.5 confidence. Keep 67:
[  0   2   4   5   6   8   9  16  17  18  19  25  30  36  37  38  40  42
  50  51  67  68  74  78  79 158 162 177 187 191 209 225 284 292 314 328
 374 402 403 409 429 473 490 499 516 545 557 575 607 624 638 639 671 703
 719 744 753 754 778 790 813 815 848 862 865 876 911]
</pre></div>
</div>
</div>
</div>
</section>
<section id="per-class-non-max-suppression">
<h3>Per-Class Non-Max Suppression<a class="headerlink" href="#per-class-non-max-suppression" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Apply per-class non-max suppression
pre_nms_boxes = refined_proposals[keep]
pre_nms_scores = roi_scores[keep]
pre_nms_class_ids = roi_class_ids[keep]

nms_keep = []
for class_id in np.unique(pre_nms_class_ids):
    # Pick detections of this class
    ixs = np.where(pre_nms_class_ids == class_id)[0]
    # Apply NMS
    class_keep = utils.non_max_suppression(pre_nms_boxes[ixs], 
                                            pre_nms_scores[ixs],
                                            config.DETECTION_NMS_THRESHOLD)
    # Map indicies
    class_keep = keep[ixs[class_keep]]
    nms_keep = np.union1d(nms_keep, class_keep)
    print(&quot;{:22}: {} -&gt; {}&quot;.format(dataset.class_names[class_id][:20], 
                                   keep[ixs], class_keep))

keep = np.intersect1d(keep, nms_keep).astype(np.int32)
print(&quot;\nKept after per-class NMS: {}\n{}&quot;.format(keep.shape[0], keep))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>person                : [  0   2   5   6   9  67  68  74  79 158 162 187 191 225 284 374 403 409
 429 490 545 557 575 607 638 671 703 744 753 754 778 790 813 848 862 876
 911] -&gt; [  0 162   9   2 671]
car                   : [ 16  18  30  36  51 177 314 328 499 624 815] -&gt; [30]
airplane              : [  4   8  17  19  25  37  38  40  42  50  78 209 292 402 473 516 639 719
 865] -&gt; [78 19]

Kept after per-class NMS: 8
[  0   2   9  19  30  78 162 671]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Show final detections
ixs = np.arange(len(keep))  # Display all
# ixs = np.random.randint(0, len(keep), 10)  # Display random sample
captions = [&quot;{} {:.3f}&quot;.format(dataset.class_names[c], s) if c &gt; 0 else &quot;&quot;
            for c, s in zip(roi_class_ids[keep][ixs], roi_scores[keep][ixs])]
visualize.draw_boxes(
    image, boxes=proposals[keep][ixs],
    refined_boxes=refined_proposals[keep][ixs],
    visibilities=np.where(roi_class_ids[keep][ixs] &gt; 0, 1, 0),
    captions=captions, title=&quot;Detections after NMS&quot;,
    ax=get_ax())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_45_0.png" src="../../../../../_images/inspect_model_45_0.png" />
</div>
</div>
</section>
</section>
</section>
<section id="stage-3-generating-masks">
<h1><span class="section-number">3.13. </span>Stage 3: Generating Masks<a class="headerlink" href="#stage-3-generating-masks" title="Permalink to this headline">#</a></h1>
<p>This stage takes the detections (refined bounding boxes and class IDs) from the previous layer and runs the mask head to generate segmentation masks for every instance.</p>
<section id="a-mask-targets">
<h2><span class="section-number">3.13.1. </span>3.a Mask Targets<a class="headerlink" href="#a-mask-targets" title="Permalink to this headline">#</a></h2>
<p>These are the training targets for the mask branch</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>display_images(np.transpose(gt_mask, [2, 0, 1]), cmap=&quot;Blues&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_48_0.png" src="../../../../../_images/inspect_model_48_0.png" />
</div>
</div>
</section>
<section id="b-predicted-masks">
<h2><span class="section-number">3.13.2. </span>3.b Predicted Masks<a class="headerlink" href="#b-predicted-masks" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Get predictions of mask head
mrcnn = model.run_graph([image], [
    (&quot;detections&quot;, model.keras_model.get_layer(&quot;mrcnn_detection&quot;).output),
    (&quot;masks&quot;, model.keras_model.get_layer(&quot;mrcnn_mask&quot;).output),
])

# Get detection class IDs. Trim zero padding.
det_class_ids = mrcnn[&#39;detections&#39;][0, :, 4].astype(np.int32)
det_count = np.where(det_class_ids == 0)[0][0]
det_class_ids = det_class_ids[:det_count]

print(&quot;{} detections: {}&quot;.format(
    det_count, np.array(dataset.class_names)[det_class_ids]))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>detections               shape: (1, 100, 6)           min:    0.00000  max:  844.00000
masks                    shape: (1, 100, 28, 28, 81)  min:    0.00000  max:    0.99984
8 detections: [&#39;person&#39; &#39;person&#39; &#39;person&#39; &#39;person&#39; &#39;person&#39; &#39;airplane&#39; &#39;airplane&#39; &#39;car&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Masks
det_boxes = utils.denorm_boxes(mrcnn[&quot;detections&quot;][0, :, :4], image.shape[:2])
det_mask_specific = np.array([mrcnn[&quot;masks&quot;][0, i, :, :, c] 
                              for i, c in enumerate(det_class_ids)])
det_masks = np.array([utils.unmold_mask(m, det_boxes[i], image.shape)
                      for i, m in enumerate(det_mask_specific)])
log(&quot;det_mask_specific&quot;, det_mask_specific)
log(&quot;det_masks&quot;, det_masks)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>det_mask_specific        shape: (8, 28, 28)           min:    0.00001  max:    0.99984
det_masks                shape: (8, 1024, 1024)       min:    0.00000  max:    1.00000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>display_images(det_mask_specific[:4] * 255, cmap=&quot;Blues&quot;, interpolation=&quot;none&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_52_0.png" src="../../../../../_images/inspect_model_52_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>display_images(det_masks[:4] * 255, cmap=&quot;Blues&quot;, interpolation=&quot;none&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_53_0.png" src="../../../../../_images/inspect_model_53_0.png" />
</div>
</div>
</section>
</section>
<section id="visualize-activations">
<h1><span class="section-number">3.14. </span>Visualize Activations<a class="headerlink" href="#visualize-activations" title="Permalink to this headline">#</a></h1>
<p>In some cases it helps to look at the output from different layers and visualize them to catch issues and odd patterns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Get activations of a few sample layers
activations = model.run_graph([image], [
    (&quot;input_image&quot;,        tf.identity(model.keras_model.get_layer(&quot;input_image&quot;).output)),
    (&quot;res4w_out&quot;,          model.keras_model.get_layer(&quot;res4w_out&quot;).output),  # for resnet100
    (&quot;rpn_bbox&quot;,           model.keras_model.get_layer(&quot;rpn_bbox&quot;).output),
    (&quot;roi&quot;,                model.keras_model.get_layer(&quot;ROI&quot;).output),
])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>input_image              shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10001
res4w_out                shape: (1, 64, 64, 1024)     min:    0.00000  max:   54.64681
rpn_bbox                 shape: (1, 65472, 4)         min:  -12.26412  max:   18.18265
roi                      shape: (1, 1000, 4)          min:    0.00000  max:    1.00000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Input image (normalized)
_ = plt.imshow(modellib.unmold_image(activations[&quot;input_image&quot;][0],config))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_56_0.png" src="../../../../../_images/inspect_model_56_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Backbone feature map
display_images(np.transpose(activations[&quot;res4w_out&quot;][0,:,:,:4], [2, 0, 1]))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_57_0.png" src="../../../../../_images/inspect_model_57_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Histograms of RPN bounding box deltas
plt.figure(figsize=(12, 3))
plt.subplot(1, 4, 1)
plt.title(&quot;dy&quot;)
_ = plt.hist(activations[&quot;rpn_bbox&quot;][0,:,0], 50)
plt.subplot(1, 4, 2)
plt.title(&quot;dx&quot;)
_ = plt.hist(activations[&quot;rpn_bbox&quot;][0,:,1], 50)
plt.subplot(1, 4, 3)
plt.title(&quot;dw&quot;)
_ = plt.hist(activations[&quot;rpn_bbox&quot;][0,:,2], 50)
plt.subplot(1, 4, 4)
plt.title(&quot;dh&quot;)
_ = plt.hist(activations[&quot;rpn_bbox&quot;][0,:,3], 50)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_58_0.png" src="../../../../../_images/inspect_model_58_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Distribution of y, x coordinates of generated proposals
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.title(&quot;y1, x1&quot;)
plt.scatter(activations[&quot;roi&quot;][0,:,0], activations[&quot;roi&quot;][0,:,1])
plt.subplot(1, 2, 2)
plt.title(&quot;y2, x2&quot;)
plt.scatter(activations[&quot;roi&quot;][0,:,2], activations[&quot;roi&quot;][0,:,3])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../../_images/inspect_model_59_0.png" src="../../../../../_images/inspect_model_59_0.png" />
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./aiml-common/lectures/scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="inspect_data.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">3.3. </span>Mask R-CNN - Inspect Training Data</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="inspect_weights.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3.15. </span>Mask R-CNN - Inspect Weights of a Trained Model</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Pantelis Monogioudis, Ph.D<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>