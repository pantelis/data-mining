
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>4. Processing Sequences Using RNN &#8212; Data Mining</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://pantelis.github.io/data-mining/aiml-common/lectures/rnn/15_processing_sequences_using_rnns_and_cnns.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="1. Introduction to NLP" href="../nlp/nlp-intro/_index.html" />
    <link rel="prev" title="3. The Long Short-Term Memory (LSTM) Cell Architecture" href="lstm/_index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Mining</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Syllabus
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../syllabus/_index.html">
   Syllabus
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Data Mining
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../ai-intro/course-introduction/_index.html">
   1. Course Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ai-intro/data-science-360/_index.html">
   2. Data Science 360
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ai-intro/pipelines/_index.html">
   3. ML Pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../uber-ml-arch-case-study/_index.html">
   4. A Case Study of an ML Architecture - Uber
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The Learning Problem
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../learning-problem/_index.html">
   1. The Learning Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../regression/linear-regression/_index.html">
   2. Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../regression/linear-regression/regression-notebooks.html">
   3. Regression Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../optimization/maximum-likelihood/_index.html">
   4. Maximum Likelihood (ML) Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../entropy/_index.html">
   5. Entropy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../optimization/sgd/_index.html">
   6. Stochastic Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../classification/classification-intro/_index.html">
   7. Introduction to Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../classification/logistic-regression/_index.html">
   8. Logistic Regression
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deep Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../classification/perceptron/_index.html">
   1. The Neuron (Perceptron)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dnn/dnn-intro/_index.html">
   2. Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dnn/backprop-intro/_index.html">
   3. Introduction to Backpropagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dnn/backprop-dnn/_index.html">
   4. Backpropagation in Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dnn/backprop-dnn-exercises/_index.html">
   5. Backpropagation DNN exercises
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../dnn/fashion-mnist-case-study.html">
   6. Fashion MNIST Case Study
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../optimization/regularization/_index.html">
   7. Regularization in Deep Neural Networks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Convolutional Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../cnn/cnn-intro/_index.html">
   1. Introduction to Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cnn/cnn-layers/_index.html">
   2. CNN Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cnn/cnn-example-architectures/_index.html">
   3. CNN Example Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">
   4. Using convnets with small datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../scene-understanding/feature-extraction-resnet/index.html">
   5. Feature Extraction via Residual Networks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Transfer Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../transfer-learning/transfer-learning-introduction.html">
   1. Introduction to Transfer Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../transfer-learning/transfer_learning_tutorial.html">
   2. Transfer Learning for Computer Vision Tutorial
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Scene Understanding
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../scene-understanding/scene-understanding-intro/index.html">
   1. Introduction to Scene Understanding
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../scene-understanding/object-detection/object-detection-intro/index.html">
   2. Object Detection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../scene-understanding/object-detection/detection-metrics/index.html">
     2.1. Object Detection and Semantic Segmentation Metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../scene-understanding/object-detection/rcnn-object-detection/index.html">
     2.2. Region-CNN (RCNN) Object Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../scene-understanding/object-detection/faster-rcnn-object-detection/index.html">
     2.3. Fast and Faster RCNN Object Detection
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../scene-understanding/semantic-segmentation/index.html">
   3. Semantic Segmentation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/index.html">
     3.1. Mask R-CNN Semantic Segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/demo.html">
     3.2. Mask R-CNN Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_data.html">
     3.3. Mask R-CNN - Inspect Training Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_model.html">
     3.4. Mask R-CNN - Inspect Trained Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_weights.html">
     3.15. Mask R-CNN - Inspect Weights of a Trained Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/detectron2_tutorial.html">
     3.21. Detectron2 Beginner’s Tutorial
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Sequences and RNNs
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="introduction/_index.html">
   1. Introduction to Recurrent Neural Networks (RNN)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="simple-rnn/_index.html">
   2. Simple RNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lstm/_index.html">
   3. The Long Short-Term Memory (LSTM) Cell Architecture
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4. Processing Sequences Using RNN
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Embeddings and NLP
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nlp-intro/_index.html">
   1. Introduction to NLP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/word2vec/_index.html">
   2. Word2Vec Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/word2vec/word2vec-workshop.html">
   3. Word2Vec Workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/language-models/_index.html">
   4. RNN Language Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/language-models/simple-rnn-language-model.html">
   5. Simple RNN Language Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/language-models/cnn-language-model.html">
   6. CNN Language Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/nmt/_index.html">
   7. Neural Machine Translation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Classical Learning Methods
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../decision-trees/_index.html">
   1. Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../regression-trees/regression_trees.html">
   2. Regression tree stumps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ensemble/_index.html">
   4. Ensemble Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ensemble/random-forests/_index.html">
   5. Random Forests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ensemble/adaboost/index.html">
   6. Adaptive Boosting (AdaBoost)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ensemble/gradient-boosting/index.html">
   7. Gradient Boosting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ensemble/boosting-workshop/_index.html">
   8. Boosting workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pgm/bayesian-inference/_index.html">
   9. Bayesian Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../pgm/bayesian-coin/_index.html">
   10. Bayesian Coin Flipping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../classification/covid19-antibody-test/_index.html">
   11. COVID-19 Antibody Test
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Non-Parametric Methods
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../unsupervised/k-means/_index.html">
   1. K-means Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../density-estimation/knn/_index.html">
   2. k-Nearest Neighbors (kNN) Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../density-estimation/knn-workshop/_index.html">
   3. kNN Workshop
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dimensionality Reduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../pca/_index.html">
   1. Principal Component Analysis (PCA)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Math Background
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../ml-math/_index.html">
   1. Math for ML
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-math/probability/_index.html">
     1.1. Probability Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../linear-algebra/_index.html">
     1.2. Linear Algebra for Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ml-math/calculus/_index.html">
     1.3. Calculus
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../python/_index.html">
   1. Learn Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Assignments &amp; Projects
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../assignments/probability/probability-assignment-3/index.html">
   1. Probability Assignment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../assignments/poisson-regression/index.html">
   3. Bike Rides and the Poisson Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../projects/visual-search-coco/index.html">
   4. Reverse Visual Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../projects/transfer-learning-home-depot/index.html">
   5. Transfer Learning for Custom Datasets in the Small-Data Regime
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/pantelis/data-mining"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/pantelis/data-mining/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/rnn/15_processing_sequences_using_rnns_and_cnns.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/aiml-common/lectures/rnn/15_processing_sequences_using_rnns_and_cnns.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   4. Processing Sequences Using RNN
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#basic-rnns">
   5. Basic RNNs
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-the-dataset">
     5.1. Generate the Dataset
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#computing-some-baselines">
     5.2. Computing Some Baselines
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-a-simple-rnn">
     5.3. Using a Simple RNN
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deep-rnns">
     5.4. Deep RNNs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#forecasting-several-steps-ahead">
     5.5. Forecasting Several Steps Ahead
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deep-rnn-with-batch-norm">
   6. Deep RNN with Batch Norm
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deep-rnns-with-layer-norm">
   7. Deep RNNs with Layer Norm
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-a-custom-rnn-class">
   8. Creating a Custom RNN Class
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lstms">
   9. LSTMs
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#grus">
   10. GRUs
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-one-dimensional-convolutional-layers-to-process-sequences">
     10.1. Using One-Dimensional Convolutional Layers to Process Sequences
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wavenet">
     10.2. WaveNet
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-solutions">
   11. Exercise solutions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#to-8">
     11.1. 1. to 8.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tackling-the-sketchrnn-dataset">
     11.2. 9. Tackling the SketchRNN Dataset
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bach-chorales">
     11.3. 10. Bach Chorales
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Processing Sequences Using RNN</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   4. Processing Sequences Using RNN
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#basic-rnns">
   5. Basic RNNs
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-the-dataset">
     5.1. Generate the Dataset
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#computing-some-baselines">
     5.2. Computing Some Baselines
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-a-simple-rnn">
     5.3. Using a Simple RNN
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deep-rnns">
     5.4. Deep RNNs
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#forecasting-several-steps-ahead">
     5.5. Forecasting Several Steps Ahead
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deep-rnn-with-batch-norm">
   6. Deep RNN with Batch Norm
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#deep-rnns-with-layer-norm">
   7. Deep RNNs with Layer Norm
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-a-custom-rnn-class">
   8. Creating a Custom RNN Class
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#lstms">
   9. LSTMs
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#grus">
   10. GRUs
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-one-dimensional-convolutional-layers-to-process-sequences">
     10.1. Using One-Dimensional Convolutional Layers to Process Sequences
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wavenet">
     10.2. WaveNet
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-solutions">
   11. Exercise solutions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#to-8">
     11.1. 1. to 8.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tackling-the-sketchrnn-dataset">
     11.2. 9. Tackling the SketchRNN Dataset
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bach-chorales">
     11.3. 10. Bach Chorales
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <p><strong>Chapter 15 – Processing Sequences Using RNNs and CNNs</strong></p>
<p><em>This notebook contains all the sample code in chapter 15.</em></p>
<table align="left">
  <td>
    <a href="https://colab.research.google.com/github/ageron/handson-ml2/blob/master/15_processing_sequences_using_rnns_and_cnns.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
  </td>
  <td>
    <a target="_blank" href="https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml2/blob/master/15_processing_sequences_using_rnns_and_cnns.ipynb"><img src="https://kaggle.com/static/images/open-in-kaggle.svg" /></a>
  </td>
</table><section class="tex2jax_ignore mathjax_ignore" id="processing-sequences-using-rnn">
<h1><span class="section-number">4. </span>Processing Sequences Using RNN<a class="headerlink" href="#processing-sequences-using-rnn" title="Permalink to this headline">#</a></h1>
<p>First, let’s import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Python ≥3.5 is required
import sys
assert sys.version_info &gt;= (3, 5)

# Is this notebook running on Colab or Kaggle?
IS_COLAB = &quot;google.colab&quot; in sys.modules
IS_KAGGLE = &quot;kaggle_secrets&quot; in sys.modules

# Scikit-Learn ≥0.20 is required
import sklearn
assert sklearn.__version__ &gt;= &quot;0.20&quot;

# TensorFlow ≥2.0 is required
import tensorflow as tf
from tensorflow import keras
assert tf.__version__ &gt;= &quot;2.0&quot;

if not tf.config.list_physical_devices(&#39;GPU&#39;):
    print(&quot;No GPU was detected. LSTMs and CNNs can be very slow without a GPU.&quot;)
    if IS_COLAB:
        print(&quot;Go to Runtime &gt; Change runtime and select a GPU hardware accelerator.&quot;)
    if IS_KAGGLE:
        print(&quot;Go to Settings &gt; Accelerator and select GPU.&quot;)

# Common imports
import numpy as np
import os
from pathlib import Path

# to make this notebook&#39;s output stable across runs
np.random.seed(42)
tf.random.set_seed(42)

# To plot pretty figures
%matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rc(&#39;axes&#39;, labelsize=14)
mpl.rc(&#39;xtick&#39;, labelsize=12)
mpl.rc(&#39;ytick&#39;, labelsize=12)

# Where to save the figures
PROJECT_ROOT_DIR = &quot;.&quot;
CHAPTER_ID = &quot;rnn&quot;
IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, &quot;images&quot;, CHAPTER_ID)
os.makedirs(IMAGES_PATH, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension=&quot;png&quot;, resolution=300):
    path = os.path.join(IMAGES_PATH, fig_id + &quot;.&quot; + fig_extension)
    print(&quot;Saving figure&quot;, fig_id)
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>No GPU was detected. LSTMs and CNNs can be very slow without a GPU.
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="basic-rnns">
<h1><span class="section-number">5. </span>Basic RNNs<a class="headerlink" href="#basic-rnns" title="Permalink to this headline">#</a></h1>
<section id="generate-the-dataset">
<h2><span class="section-number">5.1. </span>Generate the Dataset<a class="headerlink" href="#generate-the-dataset" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def generate_time_series(batch_size, n_steps):
    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)
    time = np.linspace(0, 1, n_steps)
    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  #   wave 1
    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2
    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # + noise
    return series[..., np.newaxis].astype(np.float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 1)
X_train, y_train = series[:7000, :n_steps], series[:7000, -1]
X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]
X_test, y_test = series[9000:, :n_steps], series[9000:, -1]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X_train.shape, y_train.shape
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((7000, 50, 1), (7000, 1))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plot_series(series, y=None, y_pred=None, x_label=&quot;$t$&quot;, y_label=&quot;$x(t)$&quot;, legend=True):
    plt.plot(series, &quot;.-&quot;)
    if y is not None:
        plt.plot(n_steps, y, &quot;bo&quot;, label=&quot;Target&quot;)
    if y_pred is not None:
        plt.plot(n_steps, y_pred, &quot;rx&quot;, markersize=10, label=&quot;Prediction&quot;)
    plt.grid(True)
    if x_label:
        plt.xlabel(x_label, fontsize=16)
    if y_label:
        plt.ylabel(y_label, fontsize=16, rotation=0)
    plt.hlines(0, 0, 100, linewidth=1)
    plt.axis([0, n_steps + 1, -1, 1])
    if legend and (y or y_pred):
        plt.legend(fontsize=14, loc=&quot;upper left&quot;)

fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(12, 4))
for col in range(3):
    plt.sca(axes[col])
    plot_series(X_valid[col, :, 0], y_valid[col, 0],
                y_label=(&quot;$x(t)$&quot; if col==0 else None),
                legend=(col == 0))
save_fig(&quot;time_series_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure time_series_plot
</pre></div>
</div>
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_11_1.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_11_1.png" />
</div>
</div>
<p><strong>Note</strong>: in this notebook, the blue dots represent targets, and red crosses represent predictions. In the book, I first used blue crosses for targets and red dots for predictions, then I reversed this later in the chapter. Sorry if this caused some confusion.</p>
</section>
<section id="computing-some-baselines">
<h2><span class="section-number">5.2. </span>Computing Some Baselines<a class="headerlink" href="#computing-some-baselines" title="Permalink to this headline">#</a></h2>
<p>Naive predictions (just predict the last observed value):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_pred = X_valid[:, -1]
np.mean(keras.losses.mean_squared_error(y_valid, y_pred))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.020211367
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_16_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_16_0.png" />
</div>
</div>
<p>Linear predictions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[50, 1]),
    keras.layers.Dense(1)
])

model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;)
history = model.fit(X_train, y_train, epochs=20,
                    validation_data=(X_valid, y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 1s 3ms/step - loss: 0.1398 - val_loss: 0.0545
Epoch 2/20
219/219 [==============================] - 0s 690us/step - loss: 0.0443 - val_loss: 0.0266
Epoch 3/20
219/219 [==============================] - 0s 631us/step - loss: 0.0237 - val_loss: 0.0157
Epoch 4/20
219/219 [==============================] - 0s 738us/step - loss: 0.0142 - val_loss: 0.0116
Epoch 5/20
219/219 [==============================] - 0s 740us/step - loss: 0.0110 - val_loss: 0.0098
Epoch 6/20
219/219 [==============================] - 0s 615us/step - loss: 0.0093 - val_loss: 0.0087
Epoch 7/20
219/219 [==============================] - 0s 590us/step - loss: 0.0083 - val_loss: 0.0079
Epoch 8/20
219/219 [==============================] - 0s 581us/step - loss: 0.0074 - val_loss: 0.0071
Epoch 9/20
219/219 [==============================] - 0s 562us/step - loss: 0.0064 - val_loss: 0.0066
Epoch 10/20
219/219 [==============================] - 0s 570us/step - loss: 0.0063 - val_loss: 0.0062
Epoch 11/20
219/219 [==============================] - 0s 576us/step - loss: 0.0059 - val_loss: 0.0057
Epoch 12/20
219/219 [==============================] - 0s 645us/step - loss: 0.0054 - val_loss: 0.0055
Epoch 13/20
219/219 [==============================] - 0s 578us/step - loss: 0.0052 - val_loss: 0.0052
Epoch 14/20
219/219 [==============================] - 0s 596us/step - loss: 0.0050 - val_loss: 0.0049
Epoch 15/20
219/219 [==============================] - 0s 707us/step - loss: 0.0048 - val_loss: 0.0048
Epoch 16/20
219/219 [==============================] - 0s 635us/step - loss: 0.0046 - val_loss: 0.0048
Epoch 17/20
219/219 [==============================] - 0s 604us/step - loss: 0.0046 - val_loss: 0.0045
Epoch 18/20
219/219 [==============================] - 0s 647us/step - loss: 0.0043 - val_loss: 0.0044
Epoch 19/20
219/219 [==============================] - 0s 659us/step - loss: 0.0042 - val_loss: 0.0043
Epoch 20/20
219/219 [==============================] - 0s 769us/step - loss: 0.0043 - val_loss: 0.0042
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.evaluate(X_valid, y_valid)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>63/63 [==============================] - 0s 414us/step - loss: 0.0042
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.004168087150901556
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plot_learning_curves(loss, val_loss):
    plt.plot(np.arange(len(loss)) + 0.5, loss, &quot;b.-&quot;, label=&quot;Training loss&quot;)
    plt.plot(np.arange(len(val_loss)) + 1, val_loss, &quot;r.-&quot;, label=&quot;Validation loss&quot;)
    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))
    plt.axis([1, 20, 0, 0.05])
    plt.legend(fontsize=14)
    plt.xlabel(&quot;Epochs&quot;)
    plt.ylabel(&quot;Loss&quot;)
    plt.grid(True)

plot_learning_curves(history.history[&quot;loss&quot;], history.history[&quot;val_loss&quot;])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_20_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_20_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_21_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_21_0.png" />
</div>
</div>
</section>
<section id="using-a-simple-rnn">
<h2><span class="section-number">5.3. </span>Using a Simple RNN<a class="headerlink" href="#using-a-simple-rnn" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(1, input_shape=[None, 1])
])

optimizer = keras.optimizers.Adam(learning_rate=0.005)
model.compile(loss=&quot;mse&quot;, optimizer=optimizer)
history = model.fit(X_train, y_train, epochs=20,
                    validation_data=(X_valid, y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 2s 5ms/step - loss: 0.1554 - val_loss: 0.0489
Epoch 2/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0409 - val_loss: 0.0296
Epoch 3/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0277 - val_loss: 0.0218
Epoch 4/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0208 - val_loss: 0.0177
Epoch 5/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0174 - val_loss: 0.0151
Epoch 6/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0146 - val_loss: 0.0134
Epoch 7/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0138 - val_loss: 0.0123
Epoch 8/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0128 - val_loss: 0.0116
Epoch 9/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0118 - val_loss: 0.0112
Epoch 10/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0117 - val_loss: 0.0110
Epoch 11/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0109
Epoch 12/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0109
Epoch 13/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0109
Epoch 14/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0109
Epoch 15/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0113 - val_loss: 0.0109
Epoch 16/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0109
Epoch 17/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0109
Epoch 18/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0115 - val_loss: 0.0109
Epoch 19/20
219/219 [==============================] - 1s 5ms/step - loss: 0.0115 - val_loss: 0.0109
Epoch 20/20
219/219 [==============================] - 1s 4ms/step - loss: 0.0116 - val_loss: 0.0109
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.evaluate(X_valid, y_valid)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>63/63 [==============================] - 0s 2ms/step - loss: 0.0109
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.010881561785936356
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plot_learning_curves(history.history[&quot;loss&quot;], history.history[&quot;val_loss&quot;])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_25_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_25_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_26_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_26_0.png" />
</div>
</div>
</section>
<section id="deep-rnns">
<h2><span class="section-number">5.4. </span>Deep RNNs<a class="headerlink" href="#deep-rnns" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.SimpleRNN(20, return_sequences=True),
    keras.layers.SimpleRNN(1)
])

model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;)
history = model.fit(X_train, y_train, epochs=20,
                    validation_data=(X_valid, y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 5s 17ms/step - loss: 0.1324 - val_loss: 0.0090
Epoch 2/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0078 - val_loss: 0.0065
Epoch 3/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0057 - val_loss: 0.0045
Epoch 4/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0045 - val_loss: 0.0040
Epoch 5/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0044 - val_loss: 0.0040
Epoch 6/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0038 - val_loss: 0.0036
Epoch 7/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0036 - val_loss: 0.0040
Epoch 8/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0038 - val_loss: 0.0033
Epoch 9/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0037 - val_loss: 0.0032
Epoch 10/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0035 - val_loss: 0.0031
Epoch 11/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0034 - val_loss: 0.0030
Epoch 12/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0033 - val_loss: 0.0031
Epoch 13/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0034 - val_loss: 0.0031
Epoch 14/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0034 - val_loss: 0.0032
Epoch 15/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0034 - val_loss: 0.0033
Epoch 16/20
219/219 [==============================] - 3s 15ms/step - loss: 0.0037 - val_loss: 0.0030
Epoch 17/20
219/219 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0029
Epoch 18/20
219/219 [==============================] - 3s 14ms/step - loss: 0.0031 - val_loss: 0.0030
Epoch 19/20
219/219 [==============================] - 3s 14ms/step - loss: 0.0032 - val_loss: 0.0029
Epoch 20/20
219/219 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0029
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.evaluate(X_valid, y_valid)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>63/63 [==============================] - 0s 3ms/step - loss: 0.0029
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.002910564187914133
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plot_learning_curves(history.history[&quot;loss&quot;], history.history[&quot;val_loss&quot;])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_30_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_30_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_31_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_31_0.png" />
</div>
</div>
<p>Make the second <code class="docutils literal notranslate"><span class="pre">SimpleRNN</span></code> layer return only the last output:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.SimpleRNN(20),
    keras.layers.Dense(1)
])

model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;)
history = model.fit(X_train, y_train, epochs=20,
                    validation_data=(X_valid, y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0566 - val_loss: 0.0052
Epoch 2/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0048 - val_loss: 0.0036
Epoch 3/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0036 - val_loss: 0.0031
Epoch 4/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0033 - val_loss: 0.0033
Epoch 5/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0033 - val_loss: 0.0034
Epoch 6/20
219/219 [==============================] - 3s 11ms/step - loss: 0.0031 - val_loss: 0.0029
Epoch 7/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0030 - val_loss: 0.0034
Epoch 8/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0033 - val_loss: 0.0028
Epoch 9/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0031 - val_loss: 0.0028
Epoch 10/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0029 - val_loss: 0.0029
Epoch 11/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0029 - val_loss: 0.0027
Epoch 12/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0029 - val_loss: 0.0031
Epoch 13/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0029 - val_loss: 0.0031
Epoch 14/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0031 - val_loss: 0.0030
Epoch 15/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0030 - val_loss: 0.0030
Epoch 16/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0030 - val_loss: 0.0027
Epoch 17/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0030 - val_loss: 0.0028
Epoch 18/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0029 - val_loss: 0.0027
Epoch 19/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0029 - val_loss: 0.0028
Epoch 20/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0030 - val_loss: 0.0026
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.evaluate(X_valid, y_valid)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>63/63 [==============================] - 0s 3ms/step - loss: 0.0026
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.002623623702675104
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plot_learning_curves(history.history[&quot;loss&quot;], history.history[&quot;val_loss&quot;])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_35_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_35_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_pred = model.predict(X_valid)
plot_series(X_valid[0, :, 0], y_valid[0, 0], y_pred[0, 0])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_36_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_36_0.png" />
</div>
</div>
</section>
<section id="forecasting-several-steps-ahead">
<h2><span class="section-number">5.5. </span>Forecasting Several Steps Ahead<a class="headerlink" href="#forecasting-several-steps-ahead" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(43) # not 42, as it would give the first series in the train set

series = generate_time_series(1, n_steps + 10)
X_new, Y_new = series[:, :n_steps], series[:, n_steps:]
X = X_new
for step_ahead in range(10):
    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>Y_pred.shape
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1, 10, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plot_multiple_forecasts(X, Y, Y_pred):
    n_steps = X.shape[1]
    ahead = Y.shape[1]
    plot_series(X[0, :, 0])
    plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :, 0], &quot;bo-&quot;, label=&quot;Actual&quot;)
    plt.plot(np.arange(n_steps, n_steps + ahead), Y_pred[0, :, 0], &quot;rx-&quot;, label=&quot;Forecast&quot;, markersize=10)
    plt.axis([0, n_steps + ahead, -1, 1])
    plt.legend(fontsize=14)

plot_multiple_forecasts(X_new, Y_new, Y_pred)
save_fig(&quot;forecast_ahead_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure forecast_ahead_plot
</pre></div>
</div>
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_40_1.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_40_1.png" />
</div>
</div>
<p>Now let’s use this model to predict the next 10 values. We first need to regenerate the sequences with 9 more time steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 10)
X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]
X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]
X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]
</pre></div>
</div>
</div>
</div>
<p>Now let’s predict the next 10 values one by one:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X = X_valid
for step_ahead in range(10):
    y_pred_one = model.predict(X)[:, np.newaxis, :]
    X = np.concatenate([X, y_pred_one], axis=1)

Y_pred = X[:, n_steps:, 0]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>Y_pred.shape
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2000, 10)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.mean(keras.metrics.mean_squared_error(Y_valid, Y_pred))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.027510857
</pre></div>
</div>
</div>
</div>
<p>Let’s compare this performance with some baselines: naive predictions and a simple linear model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>Y_naive_pred = np.tile(X_valid[:, -1], 10) # take the last time step value, and repeat it 10 times
np.mean(keras.metrics.mean_squared_error(Y_valid, Y_naive_pred))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.25697407
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[50, 1]),
    keras.layers.Dense(10)
])

model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;)
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 0s 1ms/step - loss: 0.2186 - val_loss: 0.0606
Epoch 2/20
219/219 [==============================] - 0s 743us/step - loss: 0.0535 - val_loss: 0.0425
Epoch 3/20
219/219 [==============================] - 0s 727us/step - loss: 0.0406 - val_loss: 0.0353
Epoch 4/20
219/219 [==============================] - 0s 731us/step - loss: 0.0343 - val_loss: 0.0311
Epoch 5/20
219/219 [==============================] - 0s 743us/step - loss: 0.0300 - val_loss: 0.0283
Epoch 6/20
219/219 [==============================] - 0s 721us/step - loss: 0.0278 - val_loss: 0.0264
Epoch 7/20
219/219 [==============================] - 0s 722us/step - loss: 0.0262 - val_loss: 0.0249
Epoch 8/20
219/219 [==============================] - 0s 731us/step - loss: 0.0246 - val_loss: 0.0237
Epoch 9/20
219/219 [==============================] - 0s 725us/step - loss: 0.0236 - val_loss: 0.0229
Epoch 10/20
219/219 [==============================] - 0s 735us/step - loss: 0.0228 - val_loss: 0.0222
Epoch 11/20
219/219 [==============================] - 0s 743us/step - loss: 0.0220 - val_loss: 0.0216
Epoch 12/20
219/219 [==============================] - 0s 733us/step - loss: 0.0214 - val_loss: 0.0212
Epoch 13/20
219/219 [==============================] - 0s 714us/step - loss: 0.0212 - val_loss: 0.0208
Epoch 14/20
219/219 [==============================] - 0s 739us/step - loss: 0.0207 - val_loss: 0.0207
Epoch 15/20
219/219 [==============================] - 0s 712us/step - loss: 0.0207 - val_loss: 0.0202
Epoch 16/20
219/219 [==============================] - 0s 723us/step - loss: 0.0199 - val_loss: 0.0199
Epoch 17/20
219/219 [==============================] - 0s 738us/step - loss: 0.0197 - val_loss: 0.0195
Epoch 18/20
219/219 [==============================] - 0s 715us/step - loss: 0.0190 - val_loss: 0.0192
Epoch 19/20
219/219 [==============================] - 0s 719us/step - loss: 0.0189 - val_loss: 0.0189
Epoch 20/20
219/219 [==============================] - 0s 726us/step - loss: 0.0188 - val_loss: 0.0187
</pre></div>
</div>
</div>
</div>
<p>Now let’s create an RNN that predicts all 10 next values at once:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.SimpleRNN(20),
    keras.layers.Dense(10)
])

model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;)
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 3s 12ms/step - loss: 0.1216 - val_loss: 0.0317
Epoch 2/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0294 - val_loss: 0.0200
Epoch 3/20
219/219 [==============================] - 3s 11ms/step - loss: 0.0198 - val_loss: 0.0160
Epoch 4/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0162 - val_loss: 0.0144
Epoch 5/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0144 - val_loss: 0.0118
Epoch 6/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0127 - val_loss: 0.0112
Epoch 7/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0119 - val_loss: 0.0110
Epoch 8/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0114 - val_loss: 0.0103
Epoch 9/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0110 - val_loss: 0.0112
Epoch 10/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0118 - val_loss: 0.0100
Epoch 11/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0109 - val_loss: 0.0103
Epoch 12/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0104 - val_loss: 0.0096
Epoch 13/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0103 - val_loss: 0.0100
Epoch 14/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0101 - val_loss: 0.0103
Epoch 15/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0107
Epoch 16/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0095 - val_loss: 0.0089
Epoch 17/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0111
Epoch 18/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0098 - val_loss: 0.0094
Epoch 19/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0090 - val_loss: 0.0083
Epoch 20/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0092 - val_loss: 0.0085
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, -10:, :]
Y_pred = model.predict(X_new)[..., np.newaxis]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_53_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_53_0.png" />
</div>
</div>
<p>Now let’s create an RNN that predicts the next 10 steps at each time step. That is, instead of just forecasting time steps 50 to 59 based on time steps 0 to 49, it will forecast time steps 1 to 10 at time step 0, then time steps 2 to 11 at time step 1, and so on, and finally it will forecast time steps 50 to 59 at the last time step. Notice that the model is causal: when it makes predictions at any time step, it can only see past time steps.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)

n_steps = 50
series = generate_time_series(10000, n_steps + 10)
X_train = series[:7000, :n_steps]
X_valid = series[7000:9000, :n_steps]
X_test = series[9000:, :n_steps]
Y = np.empty((10000, n_steps, 10))
for step_ahead in range(1, 10 + 1):
    Y[..., step_ahead - 1] = series[..., step_ahead:step_ahead + n_steps, 0]
Y_train = Y[:7000]
Y_valid = Y[7000:9000]
Y_test = Y[9000:]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X_train.shape, Y_train.shape
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((7000, 50, 1), (7000, 50, 10))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.SimpleRNN(20, return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

def last_time_step_mse(Y_true, Y_pred):
    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])

model.compile(loss=&quot;mse&quot;, optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 4s 12ms/step - loss: 0.0705 - last_time_step_mse: 0.0621 - val_loss: 0.0429 - val_last_time_step_mse: 0.0324
Epoch 2/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0413 - last_time_step_mse: 0.0301 - val_loss: 0.0366 - val_last_time_step_mse: 0.0264
Epoch 3/20
219/219 [==============================] - 3s 11ms/step - loss: 0.0333 - last_time_step_mse: 0.0223 - val_loss: 0.0343 - val_last_time_step_mse: 0.0244
Epoch 4/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0306 - last_time_step_mse: 0.0200 - val_loss: 0.0284 - val_last_time_step_mse: 0.0164
Epoch 5/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0281 - last_time_step_mse: 0.0167 - val_loss: 0.0282 - val_last_time_step_mse: 0.0196
Epoch 6/20
219/219 [==============================] - 3s 11ms/step - loss: 0.0259 - last_time_step_mse: 0.0137 - val_loss: 0.0215 - val_last_time_step_mse: 0.0081
Epoch 7/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0234 - last_time_step_mse: 0.0105 - val_loss: 0.0220 - val_last_time_step_mse: 0.0089
Epoch 8/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0216 - last_time_step_mse: 0.0085 - val_loss: 0.0217 - val_last_time_step_mse: 0.0091
Epoch 9/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0214 - last_time_step_mse: 0.0089 - val_loss: 0.0202 - val_last_time_step_mse: 0.0074
Epoch 10/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0210 - last_time_step_mse: 0.0085 - val_loss: 0.0211 - val_last_time_step_mse: 0.0086
Epoch 11/20
219/219 [==============================] - 3s 11ms/step - loss: 0.0203 - last_time_step_mse: 0.0078 - val_loss: 0.0201 - val_last_time_step_mse: 0.0078
Epoch 12/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0203 - last_time_step_mse: 0.0079 - val_loss: 0.0194 - val_last_time_step_mse: 0.0073
Epoch 13/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0198 - last_time_step_mse: 0.0074 - val_loss: 0.0209 - val_last_time_step_mse: 0.0085
Epoch 14/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0197 - last_time_step_mse: 0.0073 - val_loss: 0.0189 - val_last_time_step_mse: 0.0067
Epoch 15/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0192 - last_time_step_mse: 0.0072 - val_loss: 0.0182 - val_last_time_step_mse: 0.0066
Epoch 16/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0187 - last_time_step_mse: 0.0066 - val_loss: 0.0196 - val_last_time_step_mse: 0.0095
Epoch 17/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0187 - last_time_step_mse: 0.0067 - val_loss: 0.0185 - val_last_time_step_mse: 0.0072
Epoch 18/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0186 - last_time_step_mse: 0.0067 - val_loss: 0.0179 - val_last_time_step_mse: 0.0064
Epoch 19/20
219/219 [==============================] - 3s 11ms/step - loss: 0.0185 - last_time_step_mse: 0.0068 - val_loss: 0.0172 - val_last_time_step_mse: 0.0058
Epoch 20/20
219/219 [==============================] - 2s 11ms/step - loss: 0.0181 - last_time_step_mse: 0.0066 - val_loss: 0.0205 - val_last_time_step_mse: 0.0096
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_59_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_59_0.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="deep-rnn-with-batch-norm">
<h1><span class="section-number">6. </span>Deep RNN with Batch Norm<a class="headerlink" href="#deep-rnn-with-batch-norm" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.BatchNormalization(),
    keras.layers.SimpleRNN(20, return_sequences=True),
    keras.layers.BatchNormalization(),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;, metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 4s 13ms/step - loss: 0.4750 - last_time_step_mse: 0.5027 - val_loss: 0.0877 - val_last_time_step_mse: 0.0832
Epoch 2/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0561 - last_time_step_mse: 0.0468 - val_loss: 0.0549 - val_last_time_step_mse: 0.0462
Epoch 3/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0486 - last_time_step_mse: 0.0394 - val_loss: 0.0451 - val_last_time_step_mse: 0.0358
Epoch 4/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0443 - last_time_step_mse: 0.0344 - val_loss: 0.0418 - val_last_time_step_mse: 0.0314
Epoch 5/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0414 - last_time_step_mse: 0.0315 - val_loss: 0.0391 - val_last_time_step_mse: 0.0287
Epoch 6/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0391 - last_time_step_mse: 0.0281 - val_loss: 0.0379 - val_last_time_step_mse: 0.0273
Epoch 7/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0370 - last_time_step_mse: 0.0257 - val_loss: 0.0367 - val_last_time_step_mse: 0.0248
Epoch 8/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0352 - last_time_step_mse: 0.0236 - val_loss: 0.0363 - val_last_time_step_mse: 0.0249
Epoch 9/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0340 - last_time_step_mse: 0.0224 - val_loss: 0.0332 - val_last_time_step_mse: 0.0208
Epoch 10/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0332 - last_time_step_mse: 0.0213 - val_loss: 0.0335 - val_last_time_step_mse: 0.0214
Epoch 11/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0325 - last_time_step_mse: 0.0214 - val_loss: 0.0323 - val_last_time_step_mse: 0.0203
Epoch 12/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0316 - last_time_step_mse: 0.0196 - val_loss: 0.0333 - val_last_time_step_mse: 0.0210
Epoch 13/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0312 - last_time_step_mse: 0.0192 - val_loss: 0.0310 - val_last_time_step_mse: 0.0187
Epoch 14/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0308 - last_time_step_mse: 0.0187 - val_loss: 0.0310 - val_last_time_step_mse: 0.0189
Epoch 15/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0302 - last_time_step_mse: 0.0183 - val_loss: 0.0298 - val_last_time_step_mse: 0.0178
Epoch 16/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0298 - last_time_step_mse: 0.0177 - val_loss: 0.0293 - val_last_time_step_mse: 0.0174
Epoch 17/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0294 - last_time_step_mse: 0.0173 - val_loss: 0.0315 - val_last_time_step_mse: 0.0200
Epoch 18/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0289 - last_time_step_mse: 0.0167 - val_loss: 0.0295 - val_last_time_step_mse: 0.0174
Epoch 19/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0287 - last_time_step_mse: 0.0168 - val_loss: 0.0290 - val_last_time_step_mse: 0.0163
Epoch 20/20
219/219 [==============================] - 3s 12ms/step - loss: 0.0281 - last_time_step_mse: 0.0161 - val_loss: 0.0288 - val_last_time_step_mse: 0.0164
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="deep-rnns-with-layer-norm">
<h1><span class="section-number">7. </span>Deep RNNs with Layer Norm<a class="headerlink" href="#deep-rnns-with-layer-norm" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from tensorflow.keras.layers import LayerNormalization
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>class LNSimpleRNNCell(keras.layers.Layer):
    def __init__(self, units, activation=&quot;tanh&quot;, **kwargs):
        super().__init__(**kwargs)
        self.state_size = units
        self.output_size = units
        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units,
                                                          activation=None)
        self.layer_norm = LayerNormalization()
        self.activation = keras.activations.get(activation)
    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):
        if inputs is not None:
            batch_size = tf.shape(inputs)[0]
            dtype = inputs.dtype
        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]
    def call(self, inputs, states):
        outputs, new_states = self.simple_rnn_cell(inputs, states)
        norm_outputs = self.activation(self.layer_norm(outputs))
        return norm_outputs, [norm_outputs]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True,
                     input_shape=[None, 1]),
    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;, metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 7s 26ms/step - loss: 0.2860 - last_time_step_mse: 0.2822 - val_loss: 0.0734 - val_last_time_step_mse: 0.0624
Epoch 2/20
219/219 [==============================] - 5s 25ms/step - loss: 0.0679 - last_time_step_mse: 0.0546 - val_loss: 0.0566 - val_last_time_step_mse: 0.0423
Epoch 3/20
219/219 [==============================] - 5s 25ms/step - loss: 0.0553 - last_time_step_mse: 0.0406 - val_loss: 0.0509 - val_last_time_step_mse: 0.0342
Epoch 4/20
219/219 [==============================] - 5s 25ms/step - loss: 0.0485 - last_time_step_mse: 0.0328 - val_loss: 0.0442 - val_last_time_step_mse: 0.0286
Epoch 5/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0435 - last_time_step_mse: 0.0281 - val_loss: 0.0418 - val_last_time_step_mse: 0.0258
Epoch 6/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0404 - last_time_step_mse: 0.0249 - val_loss: 0.0382 - val_last_time_step_mse: 0.0229
Epoch 7/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0374 - last_time_step_mse: 0.0228 - val_loss: 0.0351 - val_last_time_step_mse: 0.0206
Epoch 8/20
219/219 [==============================] - 5s 25ms/step - loss: 0.0352 - last_time_step_mse: 0.0208 - val_loss: 0.0337 - val_last_time_step_mse: 0.0185
Epoch 9/20
219/219 [==============================] - 6s 26ms/step - loss: 0.0331 - last_time_step_mse: 0.0190 - val_loss: 0.0319 - val_last_time_step_mse: 0.0184
Epoch 10/20
219/219 [==============================] - 5s 25ms/step - loss: 0.0322 - last_time_step_mse: 0.0185 - val_loss: 0.0311 - val_last_time_step_mse: 0.0172
Epoch 11/20
219/219 [==============================] - 5s 25ms/step - loss: 0.0308 - last_time_step_mse: 0.0174 - val_loss: 0.0301 - val_last_time_step_mse: 0.0170
Epoch 12/20
219/219 [==============================] - 5s 25ms/step - loss: 0.0300 - last_time_step_mse: 0.0166 - val_loss: 0.0291 - val_last_time_step_mse: 0.0159
Epoch 13/20
219/219 [==============================] - 5s 25ms/step - loss: 0.0293 - last_time_step_mse: 0.0158 - val_loss: 0.0283 - val_last_time_step_mse: 0.0148
Epoch 14/20
219/219 [==============================] - 5s 25ms/step - loss: 0.0286 - last_time_step_mse: 0.0154 - val_loss: 0.0277 - val_last_time_step_mse: 0.0149
Epoch 15/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0278 - last_time_step_mse: 0.0147 - val_loss: 0.0273 - val_last_time_step_mse: 0.0145
Epoch 16/20
219/219 [==============================] - 5s 23ms/step - loss: 0.0275 - last_time_step_mse: 0.0142 - val_loss: 0.0272 - val_last_time_step_mse: 0.0149
Epoch 17/20
219/219 [==============================] - 5s 23ms/step - loss: 0.0267 - last_time_step_mse: 0.0139 - val_loss: 0.0259 - val_last_time_step_mse: 0.0128
Epoch 18/20
219/219 [==============================] - 5s 23ms/step - loss: 0.0264 - last_time_step_mse: 0.0135 - val_loss: 0.0258 - val_last_time_step_mse: 0.0130
Epoch 19/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0258 - last_time_step_mse: 0.0132 - val_loss: 0.0257 - val_last_time_step_mse: 0.0131
Epoch 20/20
219/219 [==============================] - 5s 23ms/step - loss: 0.0252 - last_time_step_mse: 0.0124 - val_loss: 0.0250 - val_last_time_step_mse: 0.0121
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="creating-a-custom-rnn-class">
<h1><span class="section-number">8. </span>Creating a Custom RNN Class<a class="headerlink" href="#creating-a-custom-rnn-class" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>class MyRNN(keras.layers.Layer):
    def __init__(self, cell, return_sequences=False, **kwargs):
        super().__init__(**kwargs)
        self.cell = cell
        self.return_sequences = return_sequences
        self.get_initial_state = getattr(
            self.cell, &quot;get_initial_state&quot;, self.fallback_initial_state)
    def fallback_initial_state(self, inputs):
        batch_size = tf.shape(inputs)[0]
        return [tf.zeros([batch_size, self.cell.state_size], dtype=inputs.dtype)]
    @tf.function
    def call(self, inputs):
        states = self.get_initial_state(inputs)
        shape = tf.shape(inputs)
        batch_size = shape[0]
        n_steps = shape[1]
        sequences = tf.TensorArray(
            inputs.dtype, size=(n_steps if self.return_sequences else 0))
        outputs = tf.zeros(shape=[batch_size, self.cell.output_size], dtype=inputs.dtype)
        for step in tf.range(n_steps):
            outputs, states = self.cell(inputs[:, step], states)
            if self.return_sequences:
                sequences = sequences.write(step, outputs)
        if self.return_sequences:
            return tf.transpose(sequences.stack(), [1, 0, 2])
        else:
            return outputs
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    MyRNN(LNSimpleRNNCell(20), return_sequences=True,
          input_shape=[None, 1]),
    MyRNN(LNSimpleRNNCell(20), return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;, metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 7s 27ms/step - loss: 0.2860 - last_time_step_mse: 0.2822 - val_loss: 0.0734 - val_last_time_step_mse: 0.0624
Epoch 2/20
219/219 [==============================] - 6s 26ms/step - loss: 0.0679 - last_time_step_mse: 0.0546 - val_loss: 0.0566 - val_last_time_step_mse: 0.0423
Epoch 3/20
219/219 [==============================] - 6s 26ms/step - loss: 0.0553 - last_time_step_mse: 0.0406 - val_loss: 0.0509 - val_last_time_step_mse: 0.0342
Epoch 4/20
219/219 [==============================] - 6s 26ms/step - loss: 0.0485 - last_time_step_mse: 0.0328 - val_loss: 0.0442 - val_last_time_step_mse: 0.0286
Epoch 5/20
219/219 [==============================] - 6s 25ms/step - loss: 0.0435 - last_time_step_mse: 0.0281 - val_loss: 0.0418 - val_last_time_step_mse: 0.0258
Epoch 6/20
219/219 [==============================] - 6s 26ms/step - loss: 0.0404 - last_time_step_mse: 0.0249 - val_loss: 0.0382 - val_last_time_step_mse: 0.0229
Epoch 7/20
219/219 [==============================] - 6s 26ms/step - loss: 0.0374 - last_time_step_mse: 0.0228 - val_loss: 0.0351 - val_last_time_step_mse: 0.0206
Epoch 8/20
219/219 [==============================] - 6s 25ms/step - loss: 0.0352 - last_time_step_mse: 0.0208 - val_loss: 0.0337 - val_last_time_step_mse: 0.0185
Epoch 9/20
219/219 [==============================] - 6s 25ms/step - loss: 0.0331 - last_time_step_mse: 0.0190 - val_loss: 0.0319 - val_last_time_step_mse: 0.0184
Epoch 10/20
219/219 [==============================] - 6s 25ms/step - loss: 0.0322 - last_time_step_mse: 0.0185 - val_loss: 0.0311 - val_last_time_step_mse: 0.0172
Epoch 11/20
219/219 [==============================] - 6s 26ms/step - loss: 0.0308 - last_time_step_mse: 0.0174 - val_loss: 0.0301 - val_last_time_step_mse: 0.0170
Epoch 12/20
219/219 [==============================] - 6s 26ms/step - loss: 0.0300 - last_time_step_mse: 0.0166 - val_loss: 0.0291 - val_last_time_step_mse: 0.0159
Epoch 13/20
219/219 [==============================] - 6s 27ms/step - loss: 0.0293 - last_time_step_mse: 0.0158 - val_loss: 0.0283 - val_last_time_step_mse: 0.0148
Epoch 14/20
219/219 [==============================] - 6s 27ms/step - loss: 0.0286 - last_time_step_mse: 0.0154 - val_loss: 0.0277 - val_last_time_step_mse: 0.0149
Epoch 15/20
219/219 [==============================] - 6s 26ms/step - loss: 0.0278 - last_time_step_mse: 0.0147 - val_loss: 0.0273 - val_last_time_step_mse: 0.0145
Epoch 16/20
219/219 [==============================] - 6s 26ms/step - loss: 0.0275 - last_time_step_mse: 0.0142 - val_loss: 0.0272 - val_last_time_step_mse: 0.0149
Epoch 17/20
219/219 [==============================] - 6s 26ms/step - loss: 0.0267 - last_time_step_mse: 0.0139 - val_loss: 0.0259 - val_last_time_step_mse: 0.0128
Epoch 18/20
219/219 [==============================] - 6s 26ms/step - loss: 0.0264 - last_time_step_mse: 0.0135 - val_loss: 0.0258 - val_last_time_step_mse: 0.0130
Epoch 19/20
219/219 [==============================] - 6s 27ms/step - loss: 0.0258 - last_time_step_mse: 0.0132 - val_loss: 0.0257 - val_last_time_step_mse: 0.0131
Epoch 20/20
219/219 [==============================] - 6s 27ms/step - loss: 0.0252 - last_time_step_mse: 0.0124 - val_loss: 0.0250 - val_last_time_step_mse: 0.0121
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="lstms">
<h1><span class="section-number">9. </span>LSTMs<a class="headerlink" href="#lstms" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.LSTM(20, return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;, metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 8s 23ms/step - loss: 0.0979 - last_time_step_mse: 0.0877 - val_loss: 0.0554 - val_last_time_step_mse: 0.0364
Epoch 2/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0515 - last_time_step_mse: 0.0326 - val_loss: 0.0427 - val_last_time_step_mse: 0.0222
Epoch 3/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0407 - last_time_step_mse: 0.0196 - val_loss: 0.0367 - val_last_time_step_mse: 0.0157
Epoch 4/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0356 - last_time_step_mse: 0.0156 - val_loss: 0.0334 - val_last_time_step_mse: 0.0132
Epoch 5/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0330 - last_time_step_mse: 0.0138 - val_loss: 0.0314 - val_last_time_step_mse: 0.0121
Epoch 6/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0313 - last_time_step_mse: 0.0124 - val_loss: 0.0298 - val_last_time_step_mse: 0.0112
Epoch 7/20
219/219 [==============================] - 5s 21ms/step - loss: 0.0297 - last_time_step_mse: 0.0118 - val_loss: 0.0291 - val_last_time_step_mse: 0.0120
Epoch 8/20
219/219 [==============================] - 4s 21ms/step - loss: 0.0289 - last_time_step_mse: 0.0109 - val_loss: 0.0278 - val_last_time_step_mse: 0.0099
Epoch 9/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0282 - last_time_step_mse: 0.0110 - val_loss: 0.0278 - val_last_time_step_mse: 0.0113
Epoch 10/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0276 - last_time_step_mse: 0.0107 - val_loss: 0.0268 - val_last_time_step_mse: 0.0101
Epoch 11/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0270 - last_time_step_mse: 0.0104 - val_loss: 0.0263 - val_last_time_step_mse: 0.0096
Epoch 12/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0265 - last_time_step_mse: 0.0100 - val_loss: 0.0263 - val_last_time_step_mse: 0.0105
Epoch 13/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0260 - last_time_step_mse: 0.0098 - val_loss: 0.0257 - val_last_time_step_mse: 0.0100
Epoch 14/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0258 - last_time_step_mse: 0.0097 - val_loss: 0.0252 - val_last_time_step_mse: 0.0091
Epoch 15/20
219/219 [==============================] - 4s 21ms/step - loss: 0.0255 - last_time_step_mse: 0.0100 - val_loss: 0.0251 - val_last_time_step_mse: 0.0092
Epoch 16/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0252 - last_time_step_mse: 0.0094 - val_loss: 0.0248 - val_last_time_step_mse: 0.0089
Epoch 17/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0248 - last_time_step_mse: 0.0093 - val_loss: 0.0248 - val_last_time_step_mse: 0.0098
Epoch 18/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0247 - last_time_step_mse: 0.0092 - val_loss: 0.0246 - val_last_time_step_mse: 0.0091
Epoch 19/20
219/219 [==============================] - 4s 21ms/step - loss: 0.0243 - last_time_step_mse: 0.0092 - val_loss: 0.0238 - val_last_time_step_mse: 0.0085
Epoch 20/20
219/219 [==============================] - 4s 20ms/step - loss: 0.0239 - last_time_step_mse: 0.0088 - val_loss: 0.0238 - val_last_time_step_mse: 0.0086
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.evaluate(X_valid, Y_valid)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>63/63 [==============================] - 0s 4ms/step - loss: 0.0238 - last_time_step_mse: 0.0086
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.023788681253790855, 0.00856079813092947]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plot_learning_curves(history.history[&quot;loss&quot;], history.history[&quot;val_loss&quot;])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_72_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_72_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_74_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_74_0.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="grus">
<h1><span class="section-number">10. </span>GRUs<a class="headerlink" href="#grus" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),
    keras.layers.GRU(20, return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;, metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 8s 26ms/step - loss: 0.0995 - last_time_step_mse: 0.0940 - val_loss: 0.0538 - val_last_time_step_mse: 0.0450
Epoch 2/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0495 - last_time_step_mse: 0.0383 - val_loss: 0.0441 - val_last_time_step_mse: 0.0326
Epoch 3/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0432 - last_time_step_mse: 0.0321 - val_loss: 0.0390 - val_last_time_step_mse: 0.0275
Epoch 4/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0379 - last_time_step_mse: 0.0261 - val_loss: 0.0339 - val_last_time_step_mse: 0.0202
Epoch 5/20
219/219 [==============================] - 5s 23ms/step - loss: 0.0333 - last_time_step_mse: 0.0192 - val_loss: 0.0312 - val_last_time_step_mse: 0.0164
Epoch 6/20
219/219 [==============================] - 5s 23ms/step - loss: 0.0310 - last_time_step_mse: 0.0158 - val_loss: 0.0294 - val_last_time_step_mse: 0.0143
Epoch 7/20
219/219 [==============================] - 5s 23ms/step - loss: 0.0295 - last_time_step_mse: 0.0146 - val_loss: 0.0300 - val_last_time_step_mse: 0.0162
Epoch 8/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0287 - last_time_step_mse: 0.0136 - val_loss: 0.0278 - val_last_time_step_mse: 0.0130
Epoch 9/20
219/219 [==============================] - 5s 23ms/step - loss: 0.0277 - last_time_step_mse: 0.0133 - val_loss: 0.0273 - val_last_time_step_mse: 0.0127
Epoch 10/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0273 - last_time_step_mse: 0.0128 - val_loss: 0.0264 - val_last_time_step_mse: 0.0121
Epoch 11/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0265 - last_time_step_mse: 0.0122 - val_loss: 0.0268 - val_last_time_step_mse: 0.0135
Epoch 12/20
219/219 [==============================] - 5s 23ms/step - loss: 0.0264 - last_time_step_mse: 0.0122 - val_loss: 0.0261 - val_last_time_step_mse: 0.0123
Epoch 13/20
219/219 [==============================] - 5s 23ms/step - loss: 0.0259 - last_time_step_mse: 0.0117 - val_loss: 0.0254 - val_last_time_step_mse: 0.0116
Epoch 14/20
219/219 [==============================] - 5s 23ms/step - loss: 0.0257 - last_time_step_mse: 0.0116 - val_loss: 0.0254 - val_last_time_step_mse: 0.0116
Epoch 15/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0254 - last_time_step_mse: 0.0118 - val_loss: 0.0250 - val_last_time_step_mse: 0.0112
Epoch 16/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0252 - last_time_step_mse: 0.0114 - val_loss: 0.0250 - val_last_time_step_mse: 0.0114
Epoch 17/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0248 - last_time_step_mse: 0.0113 - val_loss: 0.0249 - val_last_time_step_mse: 0.0118
Epoch 18/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0246 - last_time_step_mse: 0.0109 - val_loss: 0.0244 - val_last_time_step_mse: 0.0108
Epoch 19/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0243 - last_time_step_mse: 0.0107 - val_loss: 0.0240 - val_last_time_step_mse: 0.0105
Epoch 20/20
219/219 [==============================] - 5s 24ms/step - loss: 0.0239 - last_time_step_mse: 0.0105 - val_loss: 0.0238 - val_last_time_step_mse: 0.0103
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.evaluate(X_valid, Y_valid)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>63/63 [==============================] - 0s 4ms/step - loss: 0.0238 - last_time_step_mse: 0.0103
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.023785505443811417, 0.010262809693813324]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plot_learning_curves(history.history[&quot;loss&quot;], history.history[&quot;val_loss&quot;])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_78_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_78_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(43)

series = generate_time_series(1, 50 + 10)
X_new, Y_new = series[:, :50, :], series[:, 50:, :]
Y_pred = model.predict(X_new)[:, -1][..., np.newaxis]
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:5 out of the last 508 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x7febe272c290&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plot_multiple_forecasts(X_new, Y_new, Y_pred)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_80_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_80_0.png" />
</div>
</div>
<section id="using-one-dimensional-convolutional-layers-to-process-sequences">
<h2><span class="section-number">10.1. </span>Using One-Dimensional Convolutional Layers to Process Sequences<a class="headerlink" href="#using-one-dimensional-convolutional-layers-to-process-sequences" title="Permalink to this headline">#</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span><span class="n">D</span> <span class="n">conv</span> <span class="n">layer</span> <span class="k">with</span> <span class="n">kernel</span> <span class="n">size</span> <span class="mi">4</span><span class="p">,</span> <span class="n">stride</span> <span class="mi">2</span><span class="p">,</span> <span class="n">VALID</span> <span class="n">padding</span><span class="p">:</span>

              <span class="o">|-----</span><span class="mi">2</span><span class="o">-----|</span>     <span class="o">|-----</span><span class="mi">5</span><span class="o">---...------|</span>     <span class="o">|-----</span><span class="mi">23</span><span class="o">----|</span>
        <span class="o">|-----</span><span class="mi">1</span><span class="o">-----|</span>     <span class="o">|-----</span><span class="mi">4</span><span class="o">-----|</span>   <span class="o">...</span>      <span class="o">|-----</span><span class="mi">22</span><span class="o">----|</span>
  <span class="o">|-----</span><span class="mi">0</span><span class="o">----|</span>      <span class="o">|-----</span><span class="mi">3</span><span class="o">-----|</span>     <span class="o">|---...|-----</span><span class="mi">21</span><span class="o">----|</span>
<span class="n">X</span><span class="p">:</span> <span class="mi">0</span>  <span class="mi">1</span>  <span class="mi">2</span>  <span class="mi">3</span>  <span class="mi">4</span>  <span class="mi">5</span>  <span class="mi">6</span>  <span class="mi">7</span>  <span class="mi">8</span>  <span class="mi">9</span>  <span class="mi">10</span> <span class="mi">11</span> <span class="mi">12</span> <span class="o">...</span> <span class="mi">42</span> <span class="mi">43</span> <span class="mi">44</span> <span class="mi">45</span> <span class="mi">46</span> <span class="mi">47</span> <span class="mi">48</span> <span class="mi">49</span>
<span class="n">Y</span><span class="p">:</span> <span class="mi">1</span>  <span class="mi">2</span>  <span class="mi">3</span>  <span class="mi">4</span>  <span class="mi">5</span>  <span class="mi">6</span>  <span class="mi">7</span>  <span class="mi">8</span>  <span class="mi">9</span>  <span class="mi">10</span> <span class="mi">11</span> <span class="mi">12</span> <span class="mi">13</span> <span class="o">...</span> <span class="mi">43</span> <span class="mi">44</span> <span class="mi">45</span> <span class="mi">46</span> <span class="mi">47</span> <span class="mi">48</span> <span class="mi">49</span> <span class="mi">50</span>
  <span class="o">/</span><span class="mi">10</span> <span class="mi">11</span> <span class="mi">12</span> <span class="mi">13</span> <span class="mi">14</span> <span class="mi">15</span> <span class="mi">16</span> <span class="mi">17</span> <span class="mi">18</span> <span class="mi">19</span> <span class="mi">20</span> <span class="mi">21</span> <span class="mi">22</span> <span class="o">...</span> <span class="mi">52</span> <span class="mi">53</span> <span class="mi">54</span> <span class="mi">55</span> <span class="mi">56</span> <span class="mi">57</span> <span class="mi">58</span> <span class="mi">59</span>

<span class="n">Output</span><span class="p">:</span>

<span class="n">X</span><span class="p">:</span>     <span class="mi">0</span><span class="o">/</span><span class="mi">3</span>   <span class="mi">2</span><span class="o">/</span><span class="mi">5</span>   <span class="mi">4</span><span class="o">/</span><span class="mi">7</span>   <span class="mi">6</span><span class="o">/</span><span class="mi">9</span>   <span class="mi">8</span><span class="o">/</span><span class="mi">11</span> <span class="mi">10</span><span class="o">/</span><span class="mi">13</span> <span class="o">.../</span><span class="mi">43</span> <span class="mi">42</span><span class="o">/</span><span class="mi">45</span> <span class="mi">44</span><span class="o">/</span><span class="mi">47</span> <span class="mi">46</span><span class="o">/</span><span class="mi">49</span>
<span class="n">Y</span><span class="p">:</span>     <span class="mi">4</span><span class="o">/</span><span class="mi">13</span>  <span class="mi">6</span><span class="o">/</span><span class="mi">15</span>  <span class="mi">8</span><span class="o">/</span><span class="mi">17</span> <span class="mi">10</span><span class="o">/</span><span class="mi">19</span> <span class="mi">12</span><span class="o">/</span><span class="mi">21</span> <span class="mi">14</span><span class="o">/</span><span class="mi">23</span> <span class="o">.../</span><span class="mi">53</span> <span class="mi">46</span><span class="o">/</span><span class="mi">55</span> <span class="mi">48</span><span class="o">/</span><span class="mi">57</span> <span class="mi">50</span><span class="o">/</span><span class="mi">59</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=&quot;valid&quot;,
                        input_shape=[None, 1]),
    keras.layers.GRU(20, return_sequences=True),
    keras.layers.GRU(20, return_sequences=True),
    keras.layers.TimeDistributed(keras.layers.Dense(10))
])

model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;, metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train[:, 3::2], epochs=20,
                    validation_data=(X_valid, Y_valid[:, 3::2]))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 6s 16ms/step - loss: 0.0908 - last_time_step_mse: 0.0845 - val_loss: 0.0477 - val_last_time_step_mse: 0.0396
Epoch 2/20
219/219 [==============================] - 3s 14ms/step - loss: 0.0437 - last_time_step_mse: 0.0357 - val_loss: 0.0367 - val_last_time_step_mse: 0.0285
Epoch 3/20
219/219 [==============================] - 3s 14ms/step - loss: 0.0356 - last_time_step_mse: 0.0282 - val_loss: 0.0307 - val_last_time_step_mse: 0.0218
Epoch 4/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0293 - last_time_step_mse: 0.0201 - val_loss: 0.0259 - val_last_time_step_mse: 0.0152
Epoch 5/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0256 - last_time_step_mse: 0.0152 - val_loss: 0.0246 - val_last_time_step_mse: 0.0141
Epoch 6/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0239 - last_time_step_mse: 0.0129 - val_loss: 0.0227 - val_last_time_step_mse: 0.0115
Epoch 7/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0228 - last_time_step_mse: 0.0116 - val_loss: 0.0225 - val_last_time_step_mse: 0.0116
Epoch 8/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0222 - last_time_step_mse: 0.0111 - val_loss: 0.0216 - val_last_time_step_mse: 0.0105
Epoch 9/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0215 - last_time_step_mse: 0.0109 - val_loss: 0.0217 - val_last_time_step_mse: 0.0109
Epoch 10/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0216 - last_time_step_mse: 0.0107 - val_loss: 0.0210 - val_last_time_step_mse: 0.0102
Epoch 11/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0210 - last_time_step_mse: 0.0103 - val_loss: 0.0208 - val_last_time_step_mse: 0.0100
Epoch 12/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0209 - last_time_step_mse: 0.0102 - val_loss: 0.0208 - val_last_time_step_mse: 0.0102
Epoch 13/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0206 - last_time_step_mse: 0.0098 - val_loss: 0.0206 - val_last_time_step_mse: 0.0101
Epoch 14/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0205 - last_time_step_mse: 0.0100 - val_loss: 0.0204 - val_last_time_step_mse: 0.0099
Epoch 15/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0202 - last_time_step_mse: 0.0099 - val_loss: 0.0199 - val_last_time_step_mse: 0.0093
Epoch 16/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0202 - last_time_step_mse: 0.0097 - val_loss: 0.0201 - val_last_time_step_mse: 0.0095
Epoch 17/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0197 - last_time_step_mse: 0.0094 - val_loss: 0.0197 - val_last_time_step_mse: 0.0091
Epoch 18/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0195 - last_time_step_mse: 0.0090 - val_loss: 0.0192 - val_last_time_step_mse: 0.0086
Epoch 19/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0190 - last_time_step_mse: 0.0088 - val_loss: 0.0188 - val_last_time_step_mse: 0.0084
Epoch 20/20
219/219 [==============================] - 3s 13ms/step - loss: 0.0186 - last_time_step_mse: 0.0084 - val_loss: 0.0184 - val_last_time_step_mse: 0.0080
</pre></div>
</div>
</div>
</div>
</section>
<section id="wavenet">
<h2><span class="section-number">10.2. </span>WaveNet<a class="headerlink" href="#wavenet" title="Permalink to this headline">#</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">C2</span>  <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\<span class="o">.../</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\
   \  <span class="o">/</span>  \  <span class="o">/</span>  \  <span class="o">/</span>  \  <span class="o">/</span>  \  <span class="o">/</span>  \  <span class="o">/</span>  \       <span class="o">/</span>  \  <span class="o">/</span>  \  <span class="o">/</span>  \
     <span class="o">/</span>    \      <span class="o">/</span>    \      <span class="o">/</span>    \                 <span class="o">/</span>    \
<span class="n">C1</span>  <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\  <span class="o">/</span>\ <span class="o">/.../</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\ <span class="o">/</span>\
<span class="n">X</span><span class="p">:</span> <span class="mi">0</span>  <span class="mi">1</span>  <span class="mi">2</span>  <span class="mi">3</span>  <span class="mi">4</span>  <span class="mi">5</span>  <span class="mi">6</span>  <span class="mi">7</span>  <span class="mi">8</span>  <span class="mi">9</span>  <span class="mi">10</span> <span class="mi">11</span> <span class="mi">12</span> <span class="o">...</span> <span class="mi">43</span> <span class="mi">44</span> <span class="mi">45</span> <span class="mi">46</span> <span class="mi">47</span> <span class="mi">48</span> <span class="mi">49</span>
<span class="n">Y</span><span class="p">:</span> <span class="mi">1</span>  <span class="mi">2</span>  <span class="mi">3</span>  <span class="mi">4</span>  <span class="mi">5</span>  <span class="mi">6</span>  <span class="mi">7</span>  <span class="mi">8</span>  <span class="mi">9</span>  <span class="mi">10</span> <span class="mi">11</span> <span class="mi">12</span> <span class="mi">13</span> <span class="o">...</span> <span class="mi">44</span> <span class="mi">45</span> <span class="mi">46</span> <span class="mi">47</span> <span class="mi">48</span> <span class="mi">49</span> <span class="mi">50</span>
  <span class="o">/</span><span class="mi">10</span> <span class="mi">11</span> <span class="mi">12</span> <span class="mi">13</span> <span class="mi">14</span> <span class="mi">15</span> <span class="mi">16</span> <span class="mi">17</span> <span class="mi">18</span> <span class="mi">19</span> <span class="mi">20</span> <span class="mi">21</span> <span class="mi">22</span> <span class="o">...</span> <span class="mi">53</span> <span class="mi">54</span> <span class="mi">55</span> <span class="mi">56</span> <span class="mi">57</span> <span class="mi">58</span> <span class="mi">59</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential()
model.add(keras.layers.InputLayer(input_shape=[None, 1]))
for rate in (1, 2, 4, 8) * 2:
    model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding=&quot;causal&quot;,
                                  activation=&quot;relu&quot;, dilation_rate=rate))
model.add(keras.layers.Conv1D(filters=10, kernel_size=1))
model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;, metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=20,
                    validation_data=(X_valid, Y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
219/219 [==============================] - 2s 7ms/step - loss: 0.0981 - last_time_step_mse: 0.0891 - val_loss: 0.0365 - val_last_time_step_mse: 0.0231
Epoch 2/20
219/219 [==============================] - 1s 7ms/step - loss: 0.0340 - last_time_step_mse: 0.0212 - val_loss: 0.0294 - val_last_time_step_mse: 0.0166
Epoch 3/20
219/219 [==============================] - 1s 7ms/step - loss: 0.0291 - last_time_step_mse: 0.0163 - val_loss: 0.0269 - val_last_time_step_mse: 0.0145
Epoch 4/20
219/219 [==============================] - 1s 6ms/step - loss: 0.0265 - last_time_step_mse: 0.0141 - val_loss: 0.0254 - val_last_time_step_mse: 0.0130
Epoch 5/20
219/219 [==============================] - 1s 6ms/step - loss: 0.0251 - last_time_step_mse: 0.0129 - val_loss: 0.0244 - val_last_time_step_mse: 0.0122
Epoch 6/20
219/219 [==============================] - 2s 7ms/step - loss: 0.0242 - last_time_step_mse: 0.0121 - val_loss: 0.0233 - val_last_time_step_mse: 0.0108
Epoch 7/20
219/219 [==============================] - 1s 6ms/step - loss: 0.0234 - last_time_step_mse: 0.0112 - val_loss: 0.0230 - val_last_time_step_mse: 0.0109
Epoch 8/20
219/219 [==============================] - 1s 7ms/step - loss: 0.0228 - last_time_step_mse: 0.0105 - val_loss: 0.0228 - val_last_time_step_mse: 0.0105
Epoch 9/20
219/219 [==============================] - 1s 6ms/step - loss: 0.0222 - last_time_step_mse: 0.0105 - val_loss: 0.0225 - val_last_time_step_mse: 0.0107
Epoch 10/20
219/219 [==============================] - 2s 7ms/step - loss: 0.0221 - last_time_step_mse: 0.0102 - val_loss: 0.0214 - val_last_time_step_mse: 0.0092
Epoch 11/20
219/219 [==============================] - 1s 7ms/step - loss: 0.0214 - last_time_step_mse: 0.0095 - val_loss: 0.0211 - val_last_time_step_mse: 0.0091
Epoch 12/20
219/219 [==============================] - 1s 7ms/step - loss: 0.0212 - last_time_step_mse: 0.0092 - val_loss: 0.0214 - val_last_time_step_mse: 0.0099
Epoch 13/20
219/219 [==============================] - 1s 7ms/step - loss: 0.0209 - last_time_step_mse: 0.0090 - val_loss: 0.0204 - val_last_time_step_mse: 0.0084
Epoch 14/20
219/219 [==============================] - 1s 6ms/step - loss: 0.0207 - last_time_step_mse: 0.0088 - val_loss: 0.0202 - val_last_time_step_mse: 0.0084
Epoch 15/20
219/219 [==============================] - 2s 7ms/step - loss: 0.0202 - last_time_step_mse: 0.0085 - val_loss: 0.0198 - val_last_time_step_mse: 0.0079
Epoch 16/20
219/219 [==============================] - 1s 7ms/step - loss: 0.0205 - last_time_step_mse: 0.0086 - val_loss: 0.0197 - val_last_time_step_mse: 0.0080
Epoch 17/20
219/219 [==============================] - 1s 6ms/step - loss: 0.0196 - last_time_step_mse: 0.0078 - val_loss: 0.0194 - val_last_time_step_mse: 0.0077
Epoch 18/20
219/219 [==============================] - 1s 7ms/step - loss: 0.0194 - last_time_step_mse: 0.0074 - val_loss: 0.0192 - val_last_time_step_mse: 0.0076
Epoch 19/20
219/219 [==============================] - 2s 7ms/step - loss: 0.0193 - last_time_step_mse: 0.0077 - val_loss: 0.0188 - val_last_time_step_mse: 0.0072
Epoch 20/20
219/219 [==============================] - 2s 7ms/step - loss: 0.0190 - last_time_step_mse: 0.0073 - val_loss: 0.0188 - val_last_time_step_mse: 0.0072
</pre></div>
</div>
</div>
</div>
<p>Here is the original WaveNet defined in the paper: it uses Gated Activation Units instead of ReLU and parametrized skip connections, plus it pads with zeros on the left to avoid getting shorter and shorter sequences:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>class GatedActivationUnit(keras.layers.Layer):
    def __init__(self, activation=&quot;tanh&quot;, **kwargs):
        super().__init__(**kwargs)
        self.activation = keras.activations.get(activation)
    def call(self, inputs):
        n_filters = inputs.shape[-1] // 2
        linear_output = self.activation(inputs[..., :n_filters])
        gate = keras.activations.sigmoid(inputs[..., n_filters:])
        return self.activation(linear_output) * gate
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def wavenet_residual_block(inputs, n_filters, dilation_rate):
    z = keras.layers.Conv1D(2 * n_filters, kernel_size=2, padding=&quot;causal&quot;,
                            dilation_rate=dilation_rate)(inputs)
    z = GatedActivationUnit()(z)
    z = keras.layers.Conv1D(n_filters, kernel_size=1)(z)
    return keras.layers.Add()([z, inputs]), z
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

n_layers_per_block = 3 # 10 in the paper
n_blocks = 1 # 3 in the paper
n_filters = 32 # 128 in the paper
n_outputs = 10 # 256 in the paper

inputs = keras.layers.Input(shape=[None, 1])
z = keras.layers.Conv1D(n_filters, kernel_size=2, padding=&quot;causal&quot;)(inputs)
skip_to_last = []
for dilation_rate in [2**i for i in range(n_layers_per_block)] * n_blocks:
    z, skip = wavenet_residual_block(z, n_filters, dilation_rate)
    skip_to_last.append(skip)
z = keras.activations.relu(keras.layers.Add()(skip_to_last))
z = keras.layers.Conv1D(n_filters, kernel_size=1, activation=&quot;relu&quot;)(z)
Y_proba = keras.layers.Conv1D(n_outputs, kernel_size=1, activation=&quot;softmax&quot;)(z)

model = keras.models.Model(inputs=[inputs], outputs=[Y_proba])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.compile(loss=&quot;mse&quot;, optimizer=&quot;adam&quot;, metrics=[last_time_step_mse])
history = model.fit(X_train, Y_train, epochs=2,
                    validation_data=(X_valid, Y_valid))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/2
219/219 [==============================] - 3s 9ms/step - loss: 0.1387 - last_time_step_mse: 0.1347 - val_loss: 0.1229 - val_last_time_step_mse: 0.1199
Epoch 2/2
219/219 [==============================] - 2s 8ms/step - loss: 0.1222 - last_time_step_mse: 0.1161 - val_loss: 0.1217 - val_last_time_step_mse: 0.1189
</pre></div>
</div>
</div>
</div>
<p>In this chapter we explored the fundamentals of RNNs and used them to process sequences (namely, time series). In the process we also looked at other ways to process sequences, including CNNs. In the next chapter we will use RNNs for Natural Language Processing, and we will learn more about RNNs (bidirectional RNNs, stateful vs stateless RNNs, Encoder–Decoders, and Attention-augmented Encoder-Decoders). We will also look at the Transformer, an Attention-only architecture.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-solutions">
<h1><span class="section-number">11. </span>Exercise solutions<a class="headerlink" href="#exercise-solutions" title="Permalink to this headline">#</a></h1>
<section id="to-8">
<h2><span class="section-number">11.1. </span>1. to 8.<a class="headerlink" href="#to-8" title="Permalink to this headline">#</a></h2>
<p>See Appendix A.</p>
</section>
<section id="tackling-the-sketchrnn-dataset">
<h2><span class="section-number">11.2. </span>9. Tackling the SketchRNN Dataset<a class="headerlink" href="#tackling-the-sketchrnn-dataset" title="Permalink to this headline">#</a></h2>
<p><em>Exercise: Train a classification model for the SketchRNN dataset, available in TensorFlow Datasets.</em></p>
<p>The dataset is not available in TFDS yet, the <a class="reference external" href="https://github.com/tensorflow/datasets/pull/361">pull request</a> is still work in progress. Luckily, the data is conveniently available as TFRecords, so let’s download it (it might take a while, as it’s about 1 GB large, with 3,450,000 training sketches and 345,000 test sketches):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>DOWNLOAD_ROOT = &quot;http://download.tensorflow.org/data/&quot;
FILENAME = &quot;quickdraw_tutorial_dataset_v1.tar.gz&quot;
filepath = keras.utils.get_file(FILENAME,
                                DOWNLOAD_ROOT + FILENAME,
                                cache_subdir=&quot;datasets/quickdraw&quot;,
                                extract=True)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>quickdraw_dir = Path(filepath).parent
train_files = sorted([str(path) for path in quickdraw_dir.glob(&quot;training.tfrecord-*&quot;)])
eval_files = sorted([str(path) for path in quickdraw_dir.glob(&quot;eval.tfrecord-*&quot;)])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_files
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;/Users/ageron/.keras/datasets/quickdraw/training.tfrecord-00000-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/training.tfrecord-00001-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/training.tfrecord-00002-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/training.tfrecord-00003-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/training.tfrecord-00004-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/training.tfrecord-00005-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/training.tfrecord-00006-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/training.tfrecord-00007-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/training.tfrecord-00008-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/training.tfrecord-00009-of-00010&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>eval_files
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;/Users/ageron/.keras/datasets/quickdraw/eval.tfrecord-00000-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/eval.tfrecord-00001-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/eval.tfrecord-00002-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/eval.tfrecord-00003-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/eval.tfrecord-00004-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/eval.tfrecord-00005-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/eval.tfrecord-00006-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/eval.tfrecord-00007-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/eval.tfrecord-00008-of-00010&#39;,
 &#39;/Users/ageron/.keras/datasets/quickdraw/eval.tfrecord-00009-of-00010&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>with open(quickdraw_dir / &quot;eval.tfrecord.classes&quot;) as test_classes_file:
    test_classes = test_classes_file.readlines()
    
with open(quickdraw_dir / &quot;training.tfrecord.classes&quot;) as train_classes_file:
    train_classes = train_classes_file.readlines()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>assert train_classes == test_classes
class_names = [name.strip().lower() for name in train_classes]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sorted(class_names)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;aircraft carrier&#39;,
 &#39;airplane&#39;,
 &#39;alarm clock&#39;,
 &#39;ambulance&#39;,
 &#39;angel&#39;,
 &#39;animal migration&#39;,
 &#39;ant&#39;,
 &#39;anvil&#39;,
 &#39;apple&#39;,
 &#39;arm&#39;,
 &#39;asparagus&#39;,
 &#39;axe&#39;,
 &#39;backpack&#39;,
 &#39;banana&#39;,
 &#39;bandage&#39;,
 &#39;barn&#39;,
 &#39;baseball&#39;,
 &#39;baseball bat&#39;,
 &#39;basket&#39;,
 &#39;basketball&#39;,
 &#39;bat&#39;,
 &#39;bathtub&#39;,
 &#39;beach&#39;,
 &#39;bear&#39;,
 &#39;beard&#39;,
 &#39;bed&#39;,
 &#39;bee&#39;,
 &#39;belt&#39;,
 &#39;bench&#39;,
 &#39;bicycle&#39;,
 &#39;binoculars&#39;,
 &#39;bird&#39;,
 &#39;birthday cake&#39;,
 &#39;blackberry&#39;,
 &#39;blueberry&#39;,
 &#39;book&#39;,
 &#39;boomerang&#39;,
 &#39;bottlecap&#39;,
 &#39;bowtie&#39;,
 &#39;bracelet&#39;,
 &#39;brain&#39;,
 &#39;bread&#39;,
 &#39;bridge&#39;,
 &#39;broccoli&#39;,
 &#39;broom&#39;,
 &#39;bucket&#39;,
 &#39;bulldozer&#39;,
 &#39;bus&#39;,
 &#39;bush&#39;,
 &#39;butterfly&#39;,
 &#39;cactus&#39;,
 &#39;cake&#39;,
 &#39;calculator&#39;,
 &#39;calendar&#39;,
 &#39;camel&#39;,
 &#39;camera&#39;,
 &#39;camouflage&#39;,
 &#39;campfire&#39;,
 &#39;candle&#39;,
 &#39;cannon&#39;,
 &#39;canoe&#39;,
 &#39;car&#39;,
 &#39;carrot&#39;,
 &#39;castle&#39;,
 &#39;cat&#39;,
 &#39;ceiling fan&#39;,
 &#39;cell phone&#39;,
 &#39;cello&#39;,
 &#39;chair&#39;,
 &#39;chandelier&#39;,
 &#39;church&#39;,
 &#39;circle&#39;,
 &#39;clarinet&#39;,
 &#39;clock&#39;,
 &#39;cloud&#39;,
 &#39;coffee cup&#39;,
 &#39;compass&#39;,
 &#39;computer&#39;,
 &#39;cookie&#39;,
 &#39;cooler&#39;,
 &#39;couch&#39;,
 &#39;cow&#39;,
 &#39;crab&#39;,
 &#39;crayon&#39;,
 &#39;crocodile&#39;,
 &#39;crown&#39;,
 &#39;cruise ship&#39;,
 &#39;cup&#39;,
 &#39;diamond&#39;,
 &#39;dishwasher&#39;,
 &#39;diving board&#39;,
 &#39;dog&#39;,
 &#39;dolphin&#39;,
 &#39;donut&#39;,
 &#39;door&#39;,
 &#39;dragon&#39;,
 &#39;dresser&#39;,
 &#39;drill&#39;,
 &#39;drums&#39;,
 &#39;duck&#39;,
 &#39;dumbbell&#39;,
 &#39;ear&#39;,
 &#39;elbow&#39;,
 &#39;elephant&#39;,
 &#39;envelope&#39;,
 &#39;eraser&#39;,
 &#39;eye&#39;,
 &#39;eyeglasses&#39;,
 &#39;face&#39;,
 &#39;fan&#39;,
 &#39;feather&#39;,
 &#39;fence&#39;,
 &#39;finger&#39;,
 &#39;fire hydrant&#39;,
 &#39;fireplace&#39;,
 &#39;firetruck&#39;,
 &#39;fish&#39;,
 &#39;flamingo&#39;,
 &#39;flashlight&#39;,
 &#39;flip flops&#39;,
 &#39;floor lamp&#39;,
 &#39;flower&#39;,
 &#39;flying saucer&#39;,
 &#39;foot&#39;,
 &#39;fork&#39;,
 &#39;frog&#39;,
 &#39;frying pan&#39;,
 &#39;garden&#39;,
 &#39;garden hose&#39;,
 &#39;giraffe&#39;,
 &#39;goatee&#39;,
 &#39;golf club&#39;,
 &#39;grapes&#39;,
 &#39;grass&#39;,
 &#39;guitar&#39;,
 &#39;hamburger&#39;,
 &#39;hammer&#39;,
 &#39;hand&#39;,
 &#39;harp&#39;,
 &#39;hat&#39;,
 &#39;headphones&#39;,
 &#39;hedgehog&#39;,
 &#39;helicopter&#39;,
 &#39;helmet&#39;,
 &#39;hexagon&#39;,
 &#39;hockey puck&#39;,
 &#39;hockey stick&#39;,
 &#39;horse&#39;,
 &#39;hospital&#39;,
 &#39;hot air balloon&#39;,
 &#39;hot dog&#39;,
 &#39;hot tub&#39;,
 &#39;hourglass&#39;,
 &#39;house&#39;,
 &#39;house plant&#39;,
 &#39;hurricane&#39;,
 &#39;ice cream&#39;,
 &#39;jacket&#39;,
 &#39;jail&#39;,
 &#39;kangaroo&#39;,
 &#39;key&#39;,
 &#39;keyboard&#39;,
 &#39;knee&#39;,
 &#39;knife&#39;,
 &#39;ladder&#39;,
 &#39;lantern&#39;,
 &#39;laptop&#39;,
 &#39;leaf&#39;,
 &#39;leg&#39;,
 &#39;light bulb&#39;,
 &#39;lighter&#39;,
 &#39;lighthouse&#39;,
 &#39;lightning&#39;,
 &#39;line&#39;,
 &#39;lion&#39;,
 &#39;lipstick&#39;,
 &#39;lobster&#39;,
 &#39;lollipop&#39;,
 &#39;mailbox&#39;,
 &#39;map&#39;,
 &#39;marker&#39;,
 &#39;matches&#39;,
 &#39;megaphone&#39;,
 &#39;mermaid&#39;,
 &#39;microphone&#39;,
 &#39;microwave&#39;,
 &#39;monkey&#39;,
 &#39;moon&#39;,
 &#39;mosquito&#39;,
 &#39;motorbike&#39;,
 &#39;mountain&#39;,
 &#39;mouse&#39;,
 &#39;moustache&#39;,
 &#39;mouth&#39;,
 &#39;mug&#39;,
 &#39;mushroom&#39;,
 &#39;nail&#39;,
 &#39;necklace&#39;,
 &#39;nose&#39;,
 &#39;ocean&#39;,
 &#39;octagon&#39;,
 &#39;octopus&#39;,
 &#39;onion&#39;,
 &#39;oven&#39;,
 &#39;owl&#39;,
 &#39;paint can&#39;,
 &#39;paintbrush&#39;,
 &#39;palm tree&#39;,
 &#39;panda&#39;,
 &#39;pants&#39;,
 &#39;paper clip&#39;,
 &#39;parachute&#39;,
 &#39;parrot&#39;,
 &#39;passport&#39;,
 &#39;peanut&#39;,
 &#39;pear&#39;,
 &#39;peas&#39;,
 &#39;pencil&#39;,
 &#39;penguin&#39;,
 &#39;piano&#39;,
 &#39;pickup truck&#39;,
 &#39;picture frame&#39;,
 &#39;pig&#39;,
 &#39;pillow&#39;,
 &#39;pineapple&#39;,
 &#39;pizza&#39;,
 &#39;pliers&#39;,
 &#39;police car&#39;,
 &#39;pond&#39;,
 &#39;pool&#39;,
 &#39;popsicle&#39;,
 &#39;postcard&#39;,
 &#39;potato&#39;,
 &#39;power outlet&#39;,
 &#39;purse&#39;,
 &#39;rabbit&#39;,
 &#39;raccoon&#39;,
 &#39;radio&#39;,
 &#39;rain&#39;,
 &#39;rainbow&#39;,
 &#39;rake&#39;,
 &#39;remote control&#39;,
 &#39;rhinoceros&#39;,
 &#39;rifle&#39;,
 &#39;river&#39;,
 &#39;roller coaster&#39;,
 &#39;rollerskates&#39;,
 &#39;sailboat&#39;,
 &#39;sandwich&#39;,
 &#39;saw&#39;,
 &#39;saxophone&#39;,
 &#39;school bus&#39;,
 &#39;scissors&#39;,
 &#39;scorpion&#39;,
 &#39;screwdriver&#39;,
 &#39;sea turtle&#39;,
 &#39;see saw&#39;,
 &#39;shark&#39;,
 &#39;sheep&#39;,
 &#39;shoe&#39;,
 &#39;shorts&#39;,
 &#39;shovel&#39;,
 &#39;sink&#39;,
 &#39;skateboard&#39;,
 &#39;skull&#39;,
 &#39;skyscraper&#39;,
 &#39;sleeping bag&#39;,
 &#39;smiley face&#39;,
 &#39;snail&#39;,
 &#39;snake&#39;,
 &#39;snorkel&#39;,
 &#39;snowflake&#39;,
 &#39;snowman&#39;,
 &#39;soccer ball&#39;,
 &#39;sock&#39;,
 &#39;speedboat&#39;,
 &#39;spider&#39;,
 &#39;spoon&#39;,
 &#39;spreadsheet&#39;,
 &#39;square&#39;,
 &#39;squiggle&#39;,
 &#39;squirrel&#39;,
 &#39;stairs&#39;,
 &#39;star&#39;,
 &#39;steak&#39;,
 &#39;stereo&#39;,
 &#39;stethoscope&#39;,
 &#39;stitches&#39;,
 &#39;stop sign&#39;,
 &#39;stove&#39;,
 &#39;strawberry&#39;,
 &#39;streetlight&#39;,
 &#39;string bean&#39;,
 &#39;submarine&#39;,
 &#39;suitcase&#39;,
 &#39;sun&#39;,
 &#39;swan&#39;,
 &#39;sweater&#39;,
 &#39;swing set&#39;,
 &#39;sword&#39;,
 &#39;syringe&#39;,
 &#39;t-shirt&#39;,
 &#39;table&#39;,
 &#39;teapot&#39;,
 &#39;teddy-bear&#39;,
 &#39;telephone&#39;,
 &#39;television&#39;,
 &#39;tennis racquet&#39;,
 &#39;tent&#39;,
 &#39;the eiffel tower&#39;,
 &#39;the great wall of china&#39;,
 &#39;the mona lisa&#39;,
 &#39;tiger&#39;,
 &#39;toaster&#39;,
 &#39;toe&#39;,
 &#39;toilet&#39;,
 &#39;tooth&#39;,
 &#39;toothbrush&#39;,
 &#39;toothpaste&#39;,
 &#39;tornado&#39;,
 &#39;tractor&#39;,
 &#39;traffic light&#39;,
 &#39;train&#39;,
 &#39;tree&#39;,
 &#39;triangle&#39;,
 &#39;trombone&#39;,
 &#39;truck&#39;,
 &#39;trumpet&#39;,
 &#39;umbrella&#39;,
 &#39;underwear&#39;,
 &#39;van&#39;,
 &#39;vase&#39;,
 &#39;violin&#39;,
 &#39;washing machine&#39;,
 &#39;watermelon&#39;,
 &#39;waterslide&#39;,
 &#39;whale&#39;,
 &#39;wheel&#39;,
 &#39;windmill&#39;,
 &#39;wine bottle&#39;,
 &#39;wine glass&#39;,
 &#39;wristwatch&#39;,
 &#39;yoga&#39;,
 &#39;zebra&#39;,
 &#39;zigzag&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def parse(data_batch):
    feature_descriptions = {
        &quot;ink&quot;: tf.io.VarLenFeature(dtype=tf.float32),
        &quot;shape&quot;: tf.io.FixedLenFeature([2], dtype=tf.int64),
        &quot;class_index&quot;: tf.io.FixedLenFeature([1], dtype=tf.int64)
    }
    examples = tf.io.parse_example(data_batch, feature_descriptions)
    flat_sketches = tf.sparse.to_dense(examples[&quot;ink&quot;])
    sketches = tf.reshape(flat_sketches, shape=[tf.size(data_batch), -1, 3])
    lengths = examples[&quot;shape&quot;][:, 0]
    labels = examples[&quot;class_index&quot;][:, 0]
    return sketches, lengths, labels
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def quickdraw_dataset(filepaths, batch_size=32, shuffle_buffer_size=None,
                      n_parse_threads=5, n_read_threads=5, cache=False):
    dataset = tf.data.TFRecordDataset(filepaths,
                                      num_parallel_reads=n_read_threads)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(parse, num_parallel_calls=n_parse_threads)
    return dataset.prefetch(1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_set = quickdraw_dataset(train_files, shuffle_buffer_size=10000)
valid_set = quickdraw_dataset(eval_files[:5])
test_set = quickdraw_dataset(eval_files[5:])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for sketches, lengths, labels in train_set.take(1):
    print(&quot;sketches =&quot;, sketches)
    print(&quot;lengths =&quot;, lengths)
    print(&quot;labels =&quot;, labels)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>sketches = tf.Tensor(
[[[-0.07058823  0.04255319  0.        ]
  [-0.01568627  0.0425532   0.        ]
  [-0.09803921  0.03191489  0.        ]
  ...
  [ 0.          0.          0.        ]
  [ 0.          0.          0.        ]
  [ 0.          0.          0.        ]]

 [[ 0.07058824  0.27741933  0.        ]
  [-0.02745098  0.06451613  0.        ]
  [-0.02352941  0.          0.        ]
  ...
  [ 0.          0.          0.        ]
  [ 0.          0.          0.        ]
  [ 0.          0.          0.        ]]

 [[-0.17857143  0.06666667  0.        ]
  [-0.26020408  0.15294117  0.        ]
  [-0.01020408  0.01568627  0.        ]
  ...
  [ 0.          0.          0.        ]
  [ 0.          0.          0.        ]
  [ 0.          0.          0.        ]]

 ...

 [[ 0.03056769 -0.01176471  0.        ]
  [ 0.29694325  0.          0.        ]
  [ 0.38864627  0.04705882  0.        ]
  ...
  [ 0.          0.          0.        ]
  [ 0.          0.          0.        ]
  [ 0.          0.          0.        ]]

 [[ 0.34901962  0.02985072  0.        ]
  [ 0.10588235  0.07462686  0.        ]
  [ 0.01176471 -0.35820895  0.        ]
  ...
  [ 0.          0.          0.        ]
  [ 0.          0.          0.        ]
  [ 0.          0.          0.        ]]

 [[ 0.01176471  0.          0.        ]
  [ 0.00392157  0.03448276  0.        ]
  [ 0.00784314  0.21551724  0.        ]
  ...
  [ 0.          0.          0.        ]
  [ 0.          0.          0.        ]
  [ 0.          0.          0.        ]]], shape=(32, 195, 3), dtype=float32)
lengths = tf.Tensor(
[ 44  30  18  44  20  21  26  44  17  43  47  44  34  39  50  28  24  29
  37  17 195  64  78  49  45  33  28  19  17  56  12  30], shape=(32,), dtype=int64)
labels = tf.Tensor(
[ 70 247 266  10 149 170 268 252  53 121  11   5 116 209 199  50 244  32
 327 140  22  58   8 151 204 167  39 275 143 333 152  71], shape=(32,), dtype=int64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def draw_sketch(sketch, label=None):
    origin = np.array([[0., 0., 0.]])
    sketch = np.r_[origin, sketch]
    stroke_end_indices = np.argwhere(sketch[:, -1]==1.)[:, 0]
    coordinates = np.cumsum(sketch[:, :2], axis=0)
    strokes = np.split(coordinates, stroke_end_indices + 1)
    title = class_names[label.numpy()] if label is not None else &quot;Try to guess&quot;
    plt.title(title)
    plt.plot(coordinates[:, 0], -coordinates[:, 1], &quot;y:&quot;)
    for stroke in strokes:
        plt.plot(stroke[:, 0], -stroke[:, 1], &quot;.-&quot;)
    plt.axis(&quot;off&quot;)

def draw_sketches(sketches, lengths, labels):
    n_sketches = len(sketches)
    n_cols = 4
    n_rows = (n_sketches - 1) // n_cols + 1
    plt.figure(figsize=(n_cols * 3, n_rows * 3.5))
    for index, sketch, length, label in zip(range(n_sketches), sketches, lengths, labels):
        plt.subplot(n_rows, n_cols, index + 1)
        draw_sketch(sketch[:length], label)
    plt.show()

for sketches, lengths, labels in train_set.take(1):
    draw_sketches(sketches, lengths, labels)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_110_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_110_0.png" />
</div>
</div>
<p>Most sketches are composed of less than 100 points:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>lengths = np.concatenate([lengths for _, lengths, _ in train_set.take(1000)])
plt.hist(lengths, bins=150, density=True)
plt.axis([0, 200, 0, 0.03])
plt.xlabel(&quot;length&quot;)
plt.ylabel(&quot;density&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_112_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_112_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def crop_long_sketches(dataset, max_length=100):
    return dataset.map(lambda inks, lengths, labels: (inks[:, :max_length], labels))

cropped_train_set = crop_long_sketches(train_set)
cropped_valid_set = crop_long_sketches(valid_set)
cropped_test_set = crop_long_sketches(test_set)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model = keras.models.Sequential([
    keras.layers.Conv1D(32, kernel_size=5, strides=2, activation=&quot;relu&quot;),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(64, kernel_size=5, strides=2, activation=&quot;relu&quot;),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=&quot;relu&quot;),
    keras.layers.BatchNormalization(),
    keras.layers.LSTM(128, return_sequences=True),
    keras.layers.LSTM(128),
    keras.layers.Dense(len(class_names), activation=&quot;softmax&quot;)
])
optimizer = keras.optimizers.SGD(learning_rate=1e-2, clipnorm=1.)
model.compile(loss=&quot;sparse_categorical_crossentropy&quot;,
              optimizer=optimizer,
              metrics=[&quot;accuracy&quot;, &quot;sparse_top_k_categorical_accuracy&quot;])
history = model.fit(cropped_train_set, epochs=2,
                    validation_data=cropped_valid_set)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/2
107813/107813 [==============================] - 2182s 20ms/step - loss: 3.8473 - accuracy: 0.2086 - sparse_top_k_categorical_accuracy: 0.4242 - val_loss: 2.6672 - val_accuracy: 0.3872 - val_sparse_top_k_categorical_accuracy: 0.6771
Epoch 2/2
107813/107813 [==============================] - 2049s 19ms/step - loss: 2.3393 - accuracy: 0.4502 - sparse_top_k_categorical_accuracy: 0.7367 - val_loss: 2.1072 - val_accuracy: 0.4968 - val_sparse_top_k_categorical_accuracy: 0.7759
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_test = np.concatenate([labels for _, _, labels in test_set])
y_probas = model.predict(test_set)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.mean(keras.metrics.sparse_top_k_categorical_accuracy(y_test, y_probas))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6899671
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n_new = 10
Y_probas = model.predict(sketches)
top_k = tf.nn.top_k(Y_probas, k=5)
for index in range(n_new):
    plt.figure(figsize=(3, 3.5))
    draw_sketch(sketches[index])
    plt.show()
    print(&quot;Top-5 predictions:&quot;.format(index + 1))
    for k in range(5):
        class_name = class_names[top_k.indices[index, k]]
        proba = 100 * top_k.values[index, k]
        print(&quot;  {}. {} {:.3f}%&quot;.format(k + 1, class_name, proba))
    print(&quot;Answer: {}&quot;.format(class_names[labels[index].numpy()]))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_0.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-5 predictions:
  1. firetruck 46.565%
  2. police car 30.455%
  3. ambulance 3.810%
  4. car 3.695%
  5. cannon 3.371%
Answer: firetruck
</pre></div>
</div>
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_2.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_2.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-5 predictions:
  1. mouth 23.162%
  2. pond 14.151%
  3. pool 12.582%
  4. beard 11.375%
  5. goatee 9.808%
Answer: mouth
</pre></div>
</div>
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_4.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_4.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-5 predictions:
  1. jail 71.532%
  2. fence 6.519%
  3. swing set 5.708%
  4. grass 3.302%
  5. rain 3.023%
Answer: jail
</pre></div>
</div>
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_6.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_6.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-5 predictions:
  1. baseball 79.233%
  2. watermelon 7.687%
  3. basketball 5.259%
  4. clock 1.659%
  5. compass 1.101%
Answer: baseball
</pre></div>
</div>
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_8.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_8.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-5 predictions:
  1. basketball 51.888%
  2. baseball 17.328%
  3. onion 12.688%
  4. watermelon 9.989%
  5. brain 2.216%
Answer: baseball
</pre></div>
</div>
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_10.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_10.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-5 predictions:
  1. lantern 7.235%
  2. toothpaste 6.845%
  3. drill 6.254%
  4. lighthouse 4.624%
  5. crayon 3.566%
Answer: brain
</pre></div>
</div>
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_12.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_12.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-5 predictions:
  1. animal migration 8.771%
  2. blackberry 7.932%
  3. blueberry 6.413%
  4. peas 5.549%
  5. bracelet 3.623%
Answer: helicopter
</pre></div>
</div>
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_14.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_14.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-5 predictions:
  1. vase 42.793%
  2. wine glass 13.744%
  3. shovel 8.136%
  4. house plant 5.144%
  5. sailboat 4.850%
Answer: vase
</pre></div>
</div>
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_16.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_16.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-5 predictions:
  1. anvil 25.870%
  2. drill 9.670%
  3. nail 7.246%
  4. screwdriver 5.611%
  5. knee 4.355%
Answer: anvil
</pre></div>
</div>
<img alt="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_18.png" src="../../../_images/15_processing_sequences_using_rnns_and_cnns_117_18.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top-5 predictions:
  1. hurricane 34.674%
  2. tornado 16.056%
  3. blackberry 7.664%
  4. squiggle 5.489%
  5. zigzag 4.906%
Answer: pillow
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.save(&quot;my_sketchrnn&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:From /Users/ageron/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
INFO:tensorflow:Assets written to: my_sketchrnn/assets
</pre></div>
</div>
</div>
</div>
</section>
<section id="bach-chorales">
<h2><span class="section-number">11.3. </span>10. Bach Chorales<a class="headerlink" href="#bach-chorales" title="Permalink to this headline">#</a></h2>
<p><em>Exercise: Download the <a class="reference external" href="https://homl.info/bach">Bach chorales</a> dataset and unzip it. It is composed of 382 chorales composed by Johann Sebastian Bach. Each chorale is 100 to 640 time steps long, and each time step contains 4 integers, where each integer corresponds to a note’s index on a piano (except for the value 0, which means that no note is played). Train a model—recurrent, convolutional, or both—that can predict the next time step (four notes), given a sequence of time steps from a chorale. Then use this model to generate Bach-like music, one note at a time: you can do this by giving the model the start of a chorale and asking it to predict the next time step, then appending these time steps to the input sequence and asking the model for the next note, and so on. Also make sure to check out <a class="reference external" href="https://homl.info/coconet">Google’s Coconet model</a>, which was used for a nice <a class="reference external" href="https://www.google.com/doodles/celebrating-johann-sebastian-bach">Google doodle about Bach</a>.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>DOWNLOAD_ROOT = &quot;https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/&quot;
FILENAME = &quot;jsb_chorales.tgz&quot;
filepath = keras.utils.get_file(FILENAME,
                                DOWNLOAD_ROOT + FILENAME,
                                cache_subdir=&quot;datasets/jsb_chorales&quot;,
                                extract=True)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>jsb_chorales_dir = Path(filepath).parent
train_files = sorted(jsb_chorales_dir.glob(&quot;train/chorale_*.csv&quot;))
valid_files = sorted(jsb_chorales_dir.glob(&quot;valid/chorale_*.csv&quot;))
test_files = sorted(jsb_chorales_dir.glob(&quot;test/chorale_*.csv&quot;))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import pandas as pd

def load_chorales(filepaths):
    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]

train_chorales = load_chorales(train_files)
valid_chorales = load_chorales(valid_files)
test_chorales = load_chorales(test_files)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_chorales[0]
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[74, 70, 65, 58],
 [74, 70, 65, 58],
 [74, 70, 65, 58],
 [74, 70, 65, 58],
 [75, 70, 58, 55],
 [75, 70, 58, 55],
 [75, 70, 60, 55],
 [75, 70, 60, 55],
 [77, 69, 62, 50],
 [77, 69, 62, 50],
 [77, 69, 62, 50],
 [77, 69, 62, 50],
 [77, 70, 62, 55],
 [77, 70, 62, 55],
 [77, 69, 62, 55],
 [77, 69, 62, 55],
 [75, 67, 63, 48],
 [75, 67, 63, 48],
 [75, 69, 63, 48],
 [75, 69, 63, 48],
 [74, 70, 65, 46],
 [74, 70, 65, 46],
 [74, 70, 65, 46],
 [74, 70, 65, 46],
 [72, 69, 65, 53],
 [72, 69, 65, 53],
 [72, 69, 65, 53],
 [72, 69, 65, 53],
 [72, 69, 65, 53],
 [72, 69, 65, 53],
 [72, 69, 65, 53],
 [72, 69, 65, 53],
 [74, 70, 65, 46],
 [74, 70, 65, 46],
 [74, 70, 65, 46],
 [74, 70, 65, 46],
 [75, 69, 63, 48],
 [75, 69, 63, 48],
 [75, 67, 63, 48],
 [75, 67, 63, 48],
 [77, 65, 62, 50],
 [77, 65, 62, 50],
 [77, 65, 60, 50],
 [77, 65, 60, 50],
 [74, 67, 58, 55],
 [74, 67, 58, 55],
 [74, 67, 58, 53],
 [74, 67, 58, 53],
 [72, 67, 58, 51],
 [72, 67, 58, 51],
 [72, 67, 58, 51],
 [72, 67, 58, 51],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [72, 69, 65, 53],
 [72, 69, 65, 53],
 [72, 69, 65, 53],
 [72, 69, 65, 53],
 [74, 71, 53, 50],
 [74, 71, 53, 50],
 [74, 71, 53, 50],
 [74, 71, 53, 50],
 [75, 72, 55, 48],
 [75, 72, 55, 48],
 [75, 72, 55, 50],
 [75, 72, 55, 50],
 [75, 67, 60, 51],
 [75, 67, 60, 51],
 [75, 67, 60, 53],
 [75, 67, 60, 53],
 [74, 67, 60, 55],
 [74, 67, 60, 55],
 [74, 67, 57, 55],
 [74, 67, 57, 55],
 [74, 65, 59, 43],
 [74, 65, 59, 43],
 [72, 63, 59, 43],
 [72, 63, 59, 43],
 [72, 63, 55, 48],
 [72, 63, 55, 48],
 [72, 63, 55, 48],
 [72, 63, 55, 48],
 [72, 63, 55, 48],
 [72, 63, 55, 48],
 [72, 63, 55, 48],
 [72, 63, 55, 48],
 [75, 67, 60, 60],
 [75, 67, 60, 60],
 [75, 67, 60, 60],
 [75, 67, 60, 60],
 [77, 70, 62, 58],
 [77, 70, 62, 58],
 [77, 70, 62, 56],
 [77, 70, 62, 56],
 [79, 70, 62, 55],
 [79, 70, 62, 55],
 [79, 70, 62, 53],
 [79, 70, 62, 53],
 [79, 70, 63, 51],
 [79, 70, 63, 51],
 [79, 70, 63, 51],
 [79, 70, 63, 51],
 [77, 70, 63, 58],
 [77, 70, 63, 58],
 [77, 70, 60, 58],
 [77, 70, 60, 58],
 [77, 70, 62, 46],
 [77, 70, 62, 46],
 [77, 68, 62, 46],
 [75, 68, 62, 46],
 [75, 67, 58, 51],
 [75, 67, 58, 51],
 [75, 67, 58, 51],
 [75, 67, 58, 51],
 [75, 67, 58, 51],
 [75, 67, 58, 51],
 [75, 67, 58, 51],
 [75, 67, 58, 51],
 [74, 67, 58, 55],
 [74, 67, 58, 55],
 [74, 67, 58, 55],
 [74, 67, 58, 55],
 [75, 67, 58, 53],
 [75, 67, 58, 53],
 [75, 67, 58, 51],
 [75, 67, 58, 51],
 [77, 65, 58, 50],
 [77, 65, 58, 50],
 [77, 65, 56, 50],
 [77, 65, 56, 50],
 [70, 63, 55, 51],
 [70, 63, 55, 51],
 [70, 63, 55, 51],
 [70, 63, 55, 51],
 [75, 65, 60, 45],
 [75, 65, 60, 45],
 [75, 65, 60, 45],
 [75, 65, 60, 45],
 [74, 65, 58, 46],
 [74, 65, 58, 46],
 [74, 65, 58, 46],
 [74, 65, 58, 46],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [74, 65, 58, 58],
 [74, 65, 58, 58],
 [74, 65, 58, 58],
 [74, 65, 58, 58],
 [75, 67, 58, 57],
 [75, 67, 58, 57],
 [75, 67, 58, 55],
 [75, 67, 58, 55],
 [77, 65, 60, 57],
 [77, 65, 60, 57],
 [77, 65, 60, 53],
 [77, 65, 60, 53],
 [74, 65, 58, 58],
 [74, 65, 58, 58],
 [74, 65, 58, 58],
 [74, 65, 58, 58],
 [72, 67, 58, 51],
 [72, 67, 58, 51],
 [72, 67, 58, 51],
 [72, 67, 58, 51],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [72, 65, 57, 53],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [70, 65, 62, 46],
 [70, 65, 62, 46]]
</pre></div>
</div>
</div>
</div>
<p>Notes range from 36 (C1 = C on octave 1) to 81 (A5 = A on octave 5), plus 0 for silence:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>notes = set()
for chorales in (train_chorales, valid_chorales, test_chorales):
    for chorale in chorales:
        for chord in chorale:
            notes |= set(chord)

n_notes = len(notes)
min_note = min(notes - {0})
max_note = max(notes)

assert min_note == 36
assert max_note == 81
</pre></div>
</div>
</div>
</div>
<p>Let’s write a few functions to listen to these chorales (you don’t need to understand the details here, and in fact there are certainly simpler ways to do this, for example using MIDI players, but I just wanted to have a bit of fun writing a synthesizer):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from IPython.display import Audio

def notes_to_frequencies(notes):
    # Frequency doubles when you go up one octave; there are 12 semi-tones
    # per octave; Note A on octave 4 is 440 Hz, and it is note number 69.
    return 2 ** ((np.array(notes) - 69) / 12) * 440

def frequencies_to_samples(frequencies, tempo, sample_rate):
    note_duration = 60 / tempo # the tempo is measured in beats per minutes
    # To reduce click sound at every beat, we round the frequencies to try to
    # get the samples close to zero at the end of each note.
    frequencies = np.round(note_duration * frequencies) / note_duration
    n_samples = int(note_duration * sample_rate)
    time = np.linspace(0, note_duration, n_samples)
    sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)
    # Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)
    sine_waves *= (frequencies &gt; 9.).reshape(-1, 1)
    return sine_waves.reshape(-1)

def chords_to_samples(chords, tempo, sample_rate):
    freqs = notes_to_frequencies(chords)
    freqs = np.r_[freqs, freqs[-1:]] # make last note a bit longer
    merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)
                     for melody in freqs.T], axis=0)
    n_fade_out_samples = sample_rate * 60 // tempo # fade out last note
    fade_out = np.linspace(1., 0., n_fade_out_samples)**2
    merged[-n_fade_out_samples:] *= fade_out
    return merged

def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):
    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)
    if filepath:
        from scipy.io import wavfile
        samples = (2**15 * samples).astype(np.int16)
        wavfile.write(filepath, sample_rate, samples)
        return display(Audio(filepath))
    else:
        return display(Audio(samples, rate=sample_rate))
</pre></div>
</div>
</div>
</div>
<p>Now let’s listen to a few chorales:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for index in range(3):
    play_chords(train_chorales[index])
</pre></div>
</div>
</div>
</div>
<p>Divine! :)</p>
<p>In order to be able to generate new chorales, we want to train a model that can predict the next chord given all the previous chords. If we naively try to predict the next chord in one shot, predicting all 4 notes at once, we run the risk of getting notes that don’t go very well together (believe me, I tried). It’s much better and simpler to predict one note at a time. So we will need to preprocess every chorale, turning each chord into an arpegio (i.e., a sequence of notes rather than notes played simultaneuously). So each chorale will be a long sequence of notes (rather than chords), and we can just train a model that can predict the next note given all the previous notes. We will use a sequence-to-sequence approach, where we feed a window to the neural net, and it tries to predict that same window shifted one time step into the future.</p>
<p>We will also shift the values so that they range from 0 to 46, where 0 represents silence, and values 1 to 46 represent notes 36 (C1) to 81 (A5).</p>
<p>And we will train the model on windows of 128 notes (i.e., 32 chords).</p>
<p>Since the dataset fits in memory, we could preprocess the chorales in RAM using any Python code we like, but I will demonstrate here how to do all the preprocessing using tf.data (there will be more details about creating windows using tf.data in the next chapter).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def create_target(batch):
    X = batch[:, :-1]
    Y = batch[:, 1:] # predict next note in each arpegio, at each step
    return X, Y

def preprocess(window):
    window = tf.where(window == 0, window, window - min_note + 1) # shift values
    return tf.reshape(window, [-1]) # convert to arpegio

def bach_dataset(chorales, batch_size=32, shuffle_buffer_size=None,
                 window_size=32, window_shift=16, cache=True):
    def batch_window(window):
        return window.batch(window_size + 1)

    def to_windows(chorale):
        dataset = tf.data.Dataset.from_tensor_slices(chorale)
        dataset = dataset.window(window_size + 1, window_shift, drop_remainder=True)
        return dataset.flat_map(batch_window)

    chorales = tf.ragged.constant(chorales, ragged_rank=1)
    dataset = tf.data.Dataset.from_tensor_slices(chorales)
    dataset = dataset.flat_map(to_windows).map(preprocess)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(create_target)
    return dataset.prefetch(1)
</pre></div>
</div>
</div>
</div>
<p>Now let’s create the training set, the validation set and the test set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_set = bach_dataset(train_chorales, shuffle_buffer_size=1000)
valid_set = bach_dataset(valid_chorales)
test_set = bach_dataset(test_chorales)
</pre></div>
</div>
</div>
</div>
<p>Now let’s create the model:</p>
<ul class="simple">
<li><p>We could feed the note values directly to the model, as floats, but this would probably not give good results. Indeed, the relationships between notes are not that simple: for example, if you replace a C3 with a C4, the melody will still sound fine, even though these notes are 12 semi-tones apart (i.e., one octave). Conversely, if you replace a C3 with a C#3, it’s very likely that the chord will sound horrible, despite these notes being just next to each other. So we will use an <code class="docutils literal notranslate"><span class="pre">Embedding</span></code> layer to convert each note to a small vector representation (see Chapter 16 for more details on embeddings). We will use 5-dimensional embeddings, so the output of this first layer will have a shape of <code class="docutils literal notranslate"><span class="pre">[batch_size,</span> <span class="pre">window_size,</span> <span class="pre">5]</span></code>.</p></li>
<li><p>We will then feed this data to a small WaveNet-like neural network, composed of a stack of 4 <code class="docutils literal notranslate"><span class="pre">Conv1D</span></code> layers with doubling dilation rates. We will intersperse these layers with <code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code> layers for faster better convergence.</p></li>
<li><p>Then one <code class="docutils literal notranslate"><span class="pre">LSTM</span></code> layer to try to capture long-term patterns.</p></li>
<li><p>And finally a <code class="docutils literal notranslate"><span class="pre">Dense</span></code> layer to produce the final note probabilities. It will predict one probability for each chorale in the batch, for each time step, and for each possible note (including silence). So the output shape will be <code class="docutils literal notranslate"><span class="pre">[batch_size,</span> <span class="pre">window_size,</span> <span class="pre">47]</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n_embedding_dims = 5

model = keras.models.Sequential([
    keras.layers.Embedding(input_dim=n_notes, output_dim=n_embedding_dims,
                           input_shape=[None]),
    keras.layers.Conv1D(32, kernel_size=2, padding=&quot;causal&quot;, activation=&quot;relu&quot;),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(48, kernel_size=2, padding=&quot;causal&quot;, activation=&quot;relu&quot;, dilation_rate=2),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(64, kernel_size=2, padding=&quot;causal&quot;, activation=&quot;relu&quot;, dilation_rate=4),
    keras.layers.BatchNormalization(),
    keras.layers.Conv1D(96, kernel_size=2, padding=&quot;causal&quot;, activation=&quot;relu&quot;, dilation_rate=8),
    keras.layers.BatchNormalization(),
    keras.layers.LSTM(256, return_sequences=True),
    keras.layers.Dense(n_notes, activation=&quot;softmax&quot;)
])

model.summary()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 5)           235       
_________________________________________________________________
conv1d (Conv1D)              (None, None, 32)          352       
_________________________________________________________________
batch_normalization (BatchNo (None, None, 32)          128       
_________________________________________________________________
conv1d_1 (Conv1D)            (None, None, 48)          3120      
_________________________________________________________________
batch_normalization_1 (Batch (None, None, 48)          192       
_________________________________________________________________
conv1d_2 (Conv1D)            (None, None, 64)          6208      
_________________________________________________________________
batch_normalization_2 (Batch (None, None, 64)          256       
_________________________________________________________________
conv1d_3 (Conv1D)            (None, None, 96)          12384     
_________________________________________________________________
batch_normalization_3 (Batch (None, None, 96)          384       
_________________________________________________________________
lstm (LSTM)                  (None, None, 256)         361472    
_________________________________________________________________
dense (Dense)                (None, None, 47)          12079     
=================================================================
Total params: 396,810
Trainable params: 396,330
Non-trainable params: 480
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<p>Now we’re ready to compile and train the model!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>optimizer = keras.optimizers.Nadam(learning_rate=1e-3)
model.compile(loss=&quot;sparse_categorical_crossentropy&quot;, optimizer=optimizer,
              metrics=[&quot;accuracy&quot;])
model.fit(train_set, epochs=20, validation_data=valid_set)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
98/98 [==============================] - 17s 171ms/step - loss: 1.8198 - accuracy: 0.5358 - val_loss: 3.7675 - val_accuracy: 0.0428
Epoch 2/20
98/98 [==============================] - 15s 152ms/step - loss: 0.8885 - accuracy: 0.7641 - val_loss: 4.1054 - val_accuracy: 0.0470
Epoch 3/20
98/98 [==============================] - 16s 165ms/step - loss: 0.7471 - accuracy: 0.7930 - val_loss: 3.8600 - val_accuracy: 0.0368
Epoch 4/20
98/98 [==============================] - 16s 165ms/step - loss: 0.6749 - accuracy: 0.8083 - val_loss: 3.0490 - val_accuracy: 0.2196
Epoch 5/20
98/98 [==============================] - 15s 157ms/step - loss: 0.6221 - accuracy: 0.8188 - val_loss: 1.7138 - val_accuracy: 0.5153
Epoch 6/20
98/98 [==============================] - 16s 163ms/step - loss: 0.5833 - accuracy: 0.8283 - val_loss: 1.9068 - val_accuracy: 0.4570
Epoch 7/20
98/98 [==============================] - 16s 165ms/step - loss: 0.5484 - accuracy: 0.8362 - val_loss: 0.7930 - val_accuracy: 0.7678
Epoch 8/20
98/98 [==============================] - 16s 159ms/step - loss: 0.5163 - accuracy: 0.8447 - val_loss: 0.6577 - val_accuracy: 0.8091
Epoch 9/20
98/98 [==============================] - 15s 158ms/step - loss: 0.4877 - accuracy: 0.8519 - val_loss: 0.6239 - val_accuracy: 0.8180
Epoch 10/20
98/98 [==============================] - 17s 171ms/step - loss: 0.4607 - accuracy: 0.8595 - val_loss: 0.6330 - val_accuracy: 0.8151
Epoch 11/20
98/98 [==============================] - 15s 156ms/step - loss: 0.4369 - accuracy: 0.8657 - val_loss: 0.6248 - val_accuracy: 0.8179
Epoch 12/20
98/98 [==============================] - 16s 167ms/step - loss: 0.4125 - accuracy: 0.8726 - val_loss: 0.6046 - val_accuracy: 0.8248
Epoch 13/20
98/98 [==============================] - 16s 162ms/step - loss: 0.3924 - accuracy: 0.8784 - val_loss: 0.6618 - val_accuracy: 0.8096
Epoch 14/20
98/98 [==============================] - 16s 159ms/step - loss: 0.3713 - accuracy: 0.8847 - val_loss: 0.6919 - val_accuracy: 0.8067
Epoch 15/20
98/98 [==============================] - 17s 176ms/step - loss: 0.3562 - accuracy: 0.8889 - val_loss: 0.6123 - val_accuracy: 0.8236
Epoch 16/20
98/98 [==============================] - 16s 165ms/step - loss: 0.3328 - accuracy: 0.8969 - val_loss: 0.6547 - val_accuracy: 0.8133
Epoch 17/20
98/98 [==============================] - 15s 156ms/step - loss: 0.3182 - accuracy: 0.9011 - val_loss: 0.6322 - val_accuracy: 0.8202
Epoch 18/20
98/98 [==============================] - 16s 167ms/step - loss: 0.3007 - accuracy: 0.9069 - val_loss: 0.6929 - val_accuracy: 0.8037
Epoch 19/20
98/98 [==============================] - 16s 168ms/step - loss: 0.2869 - accuracy: 0.9103 - val_loss: 0.6446 - val_accuracy: 0.8220
Epoch 20/20
98/98 [==============================] - 17s 173ms/step - loss: 0.2703 - accuracy: 0.9158 - val_loss: 0.6439 - val_accuracy: 0.8189
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7fee205ff490&gt;
</pre></div>
</div>
</div>
</div>
<p>I have not done much hyperparameter search, so feel free to iterate on this model now and try to optimize it. For example, you could try removing the <code class="docutils literal notranslate"><span class="pre">LSTM</span></code> layer and replacing it with <code class="docutils literal notranslate"><span class="pre">Conv1D</span></code> layers. You could also play with the number of layers, the learning rate, the optimizer, and so on.</p>
<p>Once you’re satisfied with the performance of the model on the validation set, you can save it and evaluate it one last time on the test set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.save(&quot;my_bach_model.h5&quot;)
model.evaluate(test_set)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     34/Unknown - 2s 66ms/step - loss: 0.6557 - accuracy: 0.8164
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.6556663916391485, 0.8164004]
</pre></div>
</div>
</div>
</div>
<p><strong>Note:</strong> There’s no real need for a test set in this exercise, since we will perform the final evaluation by just listening to the music produced by the model. So if you want, you can add the test set to the train set, and train the model again, hopefully getting a slightly better model.</p>
<p>Now let’s write a function that will generate a new chorale. We will give it a few seed chords, it will convert them to arpegios (the format expected by the model), and use the model to predict the next note, then the next, and so on. In the end, it will group the notes 4 by 4 to create chords again, and return the resulting chorale.</p>
<p><strong>Warning</strong>: <code class="docutils literal notranslate"><span class="pre">model.predict_classes(X)</span></code> is deprecated. It is replaced with <code class="docutils literal notranslate"><span class="pre">np.argmax(model.predict(X),</span> <span class="pre">axis=-1)</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def generate_chorale(model, seed_chords, length):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            #next_note = model.predict_classes(arpegio)[:1, -1:]
            next_note = np.argmax(model.predict(arpegio), axis=-1)[:1, -1:]
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])
</pre></div>
</div>
</div>
</div>
<p>To test this function, we need some seed chords. Let’s use the first 8 chords of one of the test chorales (it’s actually just 2 different chords, each played 4 times):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>seed_chords = test_chorales[2][:8]
play_chords(seed_chords, amplitude=0.2)
</pre></div>
</div>
</div>
</div>
<p>Now we are ready to generate our first chorale! Let’s ask the function to generate 56 more chords, for a total of 64 chords, i.e., 16 bars (assuming 4 chords per bar, i.e., a 4/4 signature):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>new_chorale = generate_chorale(model, seed_chords, 56)
play_chords(new_chorale)
</pre></div>
</div>
</div>
</div>
<p>This approach has one major flaw: it is often too conservative. Indeed, the model will not take any risk, it will always choose the note with the highest score, and since repeating the previous note generally sounds good enough, it’s the least risky option, so the algorithm will tend to make notes last longer and longer. Pretty boring. Plus, if you run the model multiple times, it will always generate the same melody.</p>
<p>So let’s spice things up a bit! Instead of always picking the note with the highest score, we will pick the next note randomly, according to the predicted probabilities. For example, if the model predicts a C3 with 75% probability, and a G3 with a 25% probability, then we will pick one of these two notes randomly, with these probabilities. We will also add a <code class="docutils literal notranslate"><span class="pre">temperature</span></code> parameter that will control how “hot” (i.e., daring) we want the system to feel. A high temperature will bring the predicted probabilities closer together, reducing the probability of the likely notes and increasing the probability of the unlikely ones.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def generate_chorale_v2(model, seed_chords, length, temperature=1):
    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))
    arpegio = tf.reshape(arpegio, [1, -1])
    for chord in range(length):
        for note in range(4):
            next_note_probas = model.predict(arpegio)[0, -1:]
            rescaled_logits = tf.math.log(next_note_probas) / temperature
            next_note = tf.random.categorical(rescaled_logits, num_samples=1)
            arpegio = tf.concat([arpegio, next_note], axis=1)
    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)
    return tf.reshape(arpegio, shape=[-1, 4])
</pre></div>
</div>
</div>
</div>
<p>Let’s generate 3 chorales using this new function: one cold, one medium, and one hot (feel free to experiment with other seeds, lengths and temperatures). The code saves each chorale to a separate file. You can run these cells over an over again until you generate a masterpiece!</p>
<p><strong>Please share your most beautiful generated chorale with me on Twitter &#64;aureliengeron, I would really appreciate it! :))</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>new_chorale_v2_cold = generate_chorale_v2(model, seed_chords, 56, temperature=0.8)
play_chords(new_chorale_v2_cold, filepath=&quot;bach_cold.wav&quot;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>new_chorale_v2_medium = generate_chorale_v2(model, seed_chords, 56, temperature=1.0)
play_chords(new_chorale_v2_medium, filepath=&quot;bach_medium.wav&quot;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>new_chorale_v2_hot = generate_chorale_v2(model, seed_chords, 56, temperature=1.5)
play_chords(new_chorale_v2_hot, filepath=&quot;bach_hot.wav&quot;)
</pre></div>
</div>
</div>
</div>
<p>Lastly, you can try a fun social experiment: send your friends a few of your favorite generated chorales, plus the real chorale, and ask them to guess which one is the real one!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>play_chords(test_chorales[2][:64], filepath=&quot;bach_test_4.wav&quot;)
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./aiml-common/lectures/rnn"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="lstm/_index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">3. </span>The Long Short-Term Memory (LSTM) Cell Architecture</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../nlp/nlp-intro/_index.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">1. </span>Introduction to NLP</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Pantelis Monogioudis, Ph.D<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>