
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CNN Architectures &#8212; Data Mining</title>
    
  <link href="../../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://pantelis.github.io/data-mining/aiml-common/lectures/cnn/cnn-layers/_index.html" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="CNN Example Architectures" href="../cnn-example-architectures/_index.html" />
    <link rel="prev" title="Introduction to Convolutional Neural Networks" href="../cnn-intro/_index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Mining</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Syllabus
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../syllabus/_index.html">
   Syllabus
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Data Mining
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../ai-intro/course-introduction/_index.html">
   Course Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ai-intro/data-science-360/_index.html">
   Data Science 360
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ai-intro/pipelines/_index.html">
   ML Pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../uber-ml-arch-case-study/_index.html">
   A Case Study of an ML Architecture - Uber
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  The Learning Problem
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../learning-problem/_index.html">
   The Learning Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../regression/linear-regression/_index.html">
   Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../optimization/maximum-likelihood/_index.html">
   Maximum Likelihood (ML) Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../entropy/_index.html">
   Entropy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../optimization/sgd/_index.html">
   Stochastic Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/classification-intro/_index.html">
   Introduction to Classification
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Classical Learning Methods
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/logistic-regression/_index.html">
   Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../decision-trees/_index.html">
   Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../regression-trees/regression_trees.html">
   Regression tree stumps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ensemble/_index.html">
   Ensemble Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ensemble/random-forests/_index.html">
   Random Forests
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ensemble/boosting/_index.html">
   Boosting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../ensemble/boosting-workshop/_index.html">
   Boosting workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pgm/bayesian-inference/_index.html">
   Bayesian Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../pgm/bayesian-coin/_index.html">
   Bayesian Coin Flipping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/covid19-antibody-test/_index.html">
   COVID-19 Antibody Test
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deep Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../classification/perceptron/_index.html">
   The Neuron (Perceptron)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../dnn/dnn-intro/_index.html">
   Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../dnn/backprop-intro/_index.html">
   Introduction to Backpropagation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../dnn/backprop-dnn/_index.html">
   Backpropagation in Deep Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../dnn/backprop-dnn-exercises/_index.html">
   Backpropagation DNN exercises
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../optimization/regularization/_index.html">
   Regularization in Deep Neural Networks
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Convolutional Neural Networks
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../cnn-intro/_index.html">
   Introduction to Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   CNN Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cnn-example-architectures/_index.html">
   CNN Example Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cnn-example-architectures/using_convnets_with_small_datasets.html">
   Using convnets with small datasets
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Scene Understanding
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/scene-understanding-intro/_index.html">
   Introduction to Scene Understanding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/feature-extraction-resnet/_index.html">
   Feature Extraction via Residual Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/object-detection/_index.html">
   Object Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../scene-understanding/object-detection/detection-segmentation-workshop/_index.html">
   Object Detection and Semantic Segmentation Workshop
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cnn-explainers/_index.html">
   CNN Explainers
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Sequences and RNNs
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../rnn/introduction/_index.html">
   Introduction to Recurrent Neural Networks (RNN)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../rnn/simple-rnn/_index.html">
   Simple RNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../rnn/lstm/_index.html">
   The Long Short-Term Memory (LSTM) Cell Architecture
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Embeddings and NLP
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/nlp-intro/_index.html">
   Introduction to NLP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/word2vec/_index.html">
   Word2Vec Embeddings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/rnn-language-models/_index.html">
   RNN Language Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/nmt/_index.html">
   Neural Machine Translation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Non-Parametric Methods
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../unsupervised/k-means/_index.html">
   K-means Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../density-estimation/knn/_index.html">
   k-Nearest Neighbors (kNN) Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../density-estimation/knn-workshop/_index.html">
   kNN Workshop
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dimensionality Reduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../pca/_index.html">
   Principal Component Analysis (PCA)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Math Background
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../ml-math/_index.html">
   Math for ML
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-math/probability/_index.html">
     Probability Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../linear-algebra/_index.html">
     Linear Algebra for Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../ml-math/calculus/_index.html">
     Calculus
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../python/_index.html">
   Learn Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Assignments &amp; Projects
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../assignments/probability/probability-assignment-2/probability-assignment-2.html">
   Probability Assigmment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../assignments/mle/mle_exponential_linear_regression.html">
   Maximum Likelihood Parameter Estimation
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../../_sources/aiml-common/lectures/cnn/cnn-layers/_index.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://pantelis.github.io/data-mining"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://pantelis.github.io/data-mining/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/cnn/cnn-layers/_index.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolutional-layer">
   Convolutional Layer
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#zero-padding">
     Zero Padding
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-the-convolution-operation-offers">
   What the convolution / operation offers
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sparsity">
     Sparsity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameter-sharing">
     Parameter sharing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pooling">
   Pooling
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#x1-convolutional-layer">
     1x1 Convolutional layer
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#known-cnn-architectures">
   Known CNN Architectures
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>CNN Architectures</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolutional-layer">
   Convolutional Layer
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#zero-padding">
     Zero Padding
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-the-convolution-operation-offers">
   What the convolution / operation offers
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sparsity">
     Sparsity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameter-sharing">
     Parameter sharing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pooling">
   Pooling
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#x1-convolutional-layer">
     1x1 Convolutional layer
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#known-cnn-architectures">
   Known CNN Architectures
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="cnn-architectures">
<h1>CNN Architectures<a class="headerlink" href="#cnn-architectures" title="Permalink to this headline">¶</a></h1>
<div class="section" id="convolutional-layer">
<h2>Convolutional Layer<a class="headerlink" href="#convolutional-layer" title="Permalink to this headline">¶</a></h2>
<p>In the convolutional layer the first operation a 3D image with its two spatial dimensions and its third dimension due to the primary colors, typically Red Green and Blue is at the input layer, is convolved with a 3D structure called the <strong>filter</strong> shown below.</p>
<p><img alt="cnn-filter" src="../../../../_images/filter.png" />
<em>Each filter is composed of kernels - <a class="reference external" href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215">source</a></em></p>
<p>The filter slides through the picture and the amount by which it slides is referred to as the <strong>stride</strong> <span class="math notranslate nohighlight">\(s\)</span>. The stride is a hyperparameter. Increasing the stride reduces the size of your model by reducing the number of total patches each layer observes. However, this usually comes with a reduction in accuracy.</p>
<p>It’s common to have more than one filter. Different filters pick up different qualities of the receptive field. Apart from the stride, the spatial dimensions of the filter (height, width, num_kernels) the number of filters is another hyperparameter of a convolutional layer.</p>
<p>This means that typically we are dealing with <strong>volumes</strong> (3D tensors) and of course if someone adds the fact that we do processing in minibatches we are typically dealing with 4D tensors that contain input feature maps. Lets look at a single feature map visualization below of the convolution operation.</p>
<p><img alt="convolution-single-feature-map" src="../../../../_images/convolution-single-feature-map.png" />
<em>Convolutional layer with a single feature map. We can see the strides <span class="math notranslate nohighlight">\((s_h, s_w)\)</span>, the zero padding as well as the receptive field in the produced feature map.</em></p>
<p>In the figure below the authors of <a class="reference external" href="https://arxiv.org/abs/1603.07285">this</a> paper have also animated the operation.  Blue maps are inputs, and cyan maps are outputs.From left to right: (a) No padding, no strides, (b) Arbitrary padding, no strides, © Half padding, no strides, (d) Full padding, no strides.</p>
<a class="reference internal image-reference" href="../../../../_images/no_padding_no_strides.gif"><img alt="No padding, no strides" src="../../../../_images/no_padding_no_strides.gif" style="width: 200px;" /></a>
<a class="reference internal image-reference" href="../../../../_images/arbitrary_padding_no_strides.gif"><img alt="arbitrary padding, no strides" src="../../../../_images/arbitrary_padding_no_strides.gif" style="width: 200px;" /></a>
<a class="reference internal image-reference" href="../../../../_images/same_padding_no_strides.gif"><img alt="same padding, no strides" src="../../../../_images/same_padding_no_strides.gif" style="width: 200px;" /></a>
<a class="reference internal image-reference" href="../../../../_images/full_padding_no_strides.gif"><img alt="full padding, no strides" src="../../../../_images/full_padding_no_strides.gif" style="width: 200px;" /></a>
<p>Some additional annimations are shown below. From left to right: (a) No padding, with strides, (b) Padding, with strides, © Padding, with strides (odd).</p>
<a class="reference internal image-reference" href="../../../../_images/no_padding_strides.gif"><img alt="No padding, strides" src="../../../../_images/no_padding_strides.gif" style="width: 200px;" /></a>
<a class="reference internal image-reference" href="../../../../_images/padding_strides.gif"><img alt="padding, strides" src="../../../../_images/padding_strides.gif" style="width: 200px;" /></a>
<a class="reference internal image-reference" href="../../../../_images/padding_strides_odd.gif"><img alt="padding, strides odd" src="../../../../_images/padding_strides_odd.gif" style="width: 200px;" /></a>
<p>In general though in practice we are dealing with <strong>volumes</strong> due to the multiple feature maps &amp; kernels  involved. Its important to understand the figure below. Its a direct extension to the single feature map figure above. The difference is that each neuron in each feature map of layer <span class="math notranslate nohighlight">\(l\)</span> is connected to all neurons of the corresponding receptive field of layer <span class="math notranslate nohighlight">\(l-1\)</span> just as before but now these connections extend to all feature maps of layer <span class="math notranslate nohighlight">\(l-1\)</span>. <strong>In other words we connect each neuron in the feature map of layer <span class="math notranslate nohighlight">\(l\)</span> to the corresponding receptive volume (3D array) of neurons in the layer below.</strong></p>
<p>In the class we will go through the example below.</p>
<p><img alt="2d-convolution-example" src="../../../../_images/2d-convolution-example.png" /></p>
<p>There are two steps involved. Notice that the number of input feature maps is <span class="math notranslate nohighlight">\(M_{l-1} = 2\)</span>, while the number of output feature maps is <span class="math notranslate nohighlight">\(M_{l}=3\)</span>. We therefore have three filters of spatial dimension <span class="math notranslate nohighlight">\([height, width]=[3 \times 3]\)</span> and depth dimension of 2.  In the first step each of the three filters generates a correlation result for each of the 2 input feature maps.</p>
<p><span class="math notranslate nohighlight">\(z(i,j) = \sum_u^{height} \sum_v^{width} x(i+u, j+v) w(u,v)\)</span></p>
<p>In the second step we sum over the correlations for each of the three filters separately. Equivalently is like taking a volume cross correlation and extend the equation above accordingly.</p>
<p><span class="math notranslate nohighlight">\(z(i,j,k_l) = \sum_u^{height} \sum_v^{width} \sum_{k_{l-1}=1}^{M_i} x(i+u, j+v, k_{l-1}) w(u, v, k_{l-1}, k_l)\)</span></p>
<p>The figure below illustrates the input feature map to output feature map mapping directly i.e. without the intermediate step of the example above.</p>
<p><img alt="convnet-multiple-feature-maps" src="../../../../_images/convnet-feature-maps.png" />
<em>Convolutional layers with multiple feature maps. We can see the receptive field of each column of neurons of the next layer. Each column is produced by performing multiple convolutions (or cross correlation operations) between the volume below and each of the filters.</em></p>
<p>In each layer we can have in other words, as was shown in the example above, input and output feature maps of different depths.</p>
<p><img alt="2d-convolution-b" src="../../../../_images/2d-convolution-b.png" />
<em>2D convolution that produces a feature map with different depth than the input feature map</em></p>
<div class="section" id="zero-padding">
<h3>Zero Padding<a class="headerlink" href="#zero-padding" title="Permalink to this headline">¶</a></h3>
<p>Each feature map “pixel” that results from the above convolution is followed by a RELU non-linearity i.e. RELU is applied element-wise. Few words about padding. There are two types: <strong>same padding</strong> where we add zeros at the edges of the picture and <strong>valid padding</strong> where we dont. The reason we pad with zeros is to maintain the original spatial dimensions from one convolution layer to the next. If we dont, very soon we can end up with deep architectures with just a one “pixel”.</p>
<p>Lets see a complete <a class="reference external" href="http://cs231n.github.io/assets/conv-demo/index.html">animated example</a> that includes padding. You can press the toggle movement button to stop the animation and do the calculations with pencil and paper.</p>
<iframe src="http://cs231n.github.io/assets/conv-demo/index.html" width="100%" height="700px;"></iframe>
source: CS231n
<p><strong>Each output spatial dimension (height is shown here) is in general given by <span class="math notranslate nohighlight">\(⌊ \frac{height+2p-k}{s} ⌋ + 1\)</span>, where <span class="math notranslate nohighlight">\(p\)</span> is the amount of padding,  <span class="math notranslate nohighlight">\(k\)</span> is the square kernel size, <span class="math notranslate nohighlight">\(s\)</span> is the stride. In the animation above, <span class="math notranslate nohighlight">\(p=1, k=3, s = 2\)</span>.</strong>  In yet another example of sizing - output depth is a function of the number of kernels but the spatial dimensions depend as the equation above specified on stride, padding and kernel size (usually square).</p>
<p><img alt="sizing-example" src="../../../../_images/sizing-example.png" /></p>
</div>
</div>
<div class="section" id="what-the-convolution-operation-offers">
<h2>What the convolution / operation offers<a class="headerlink" href="#what-the-convolution-operation-offers" title="Permalink to this headline">¶</a></h2>
<p>There are two main consequences of the convolution operation: sparsity and parameter sharing. With the later we get as a byproduct <strong>equivariance to translation</strong>. These are explained next.</p>
<div class="section" id="sparsity">
<h3>Sparsity<a class="headerlink" href="#sparsity" title="Permalink to this headline">¶</a></h3>
<p>In DNNs, every output unit interacts with every input unit. Convolutional networks, however, typically have sparse interactions(also referred to as sparse connectivity or sparse weights). This is accomplished by making the kernel smaller than the input as shown in the figure above. For example,when processing an image, the input image might have thousands or millions of pixels, but we can detect small, meaningful features such as edges with kernels that have much smaller receptive fields.</p>
<p><img alt="cnn-sparsity" src="../../../../_images/cnn-sparsity.png" />
<em>For a specific input unit,<span class="math notranslate nohighlight">\(x_3\)</span>, we mark the output units in that are aﬀected by this unit. (Top) When is formed by convolution with a kernel of width 3, only three outputs are aﬀected by x. (Bottom)When is formed by matrix multiplication, connectivity is no longer sparse, so all the outputs are aﬀected by <span class="math notranslate nohighlight">\(x_3\)</span>.</em></p>
</div>
<div class="section" id="parameter-sharing">
<h3>Parameter sharing<a class="headerlink" href="#parameter-sharing" title="Permalink to this headline">¶</a></h3>
<p>In CNNs, each member of the kernel is used at every feasible position of the input. The parameter sharing used by the convolution operation means that rather than learning a separate set of parameters for every location, we learn only one set.</p>
<p><img alt="cnn-parameter-sharing" src="../../../../_images/cnn-parameter-sharing.png" />
<em>Parameter sharing. Black arrows indicate the connections that use a particular parameter in two diﬀerent models. (Top)The black arrows indicate uses of the central element of a 3-element kernel in a convolutional model. Because of parameter sharing, this single parameter is used at all input locations. (Bottom)The single black arrow indicates the use of the central element of the weight matrix in a fully connected model. This model has no parameter sharing, so the parameter is used only once</em>.</p>
<p>The particular form of parameter sharing causes the layer to have a property called <strong>equivariance to translation</strong>.  This means that a translation of input features results in an equivalent translation of outputs. So if your pattern 0,3,2,0,0 on the input results in 0,1,0,0 in the output, then the pattern 0,0,3,2,0 might lead to 0,0,1,0</p>
<p>As explained <a class="reference external" href="https://datascience.stackexchange.com/questions/16060/what-is-the-difference-between-equivariant-to-translation-and-invariant-to-tr">here</a> this should not be confused with <strong>invariance to translation</strong>. The later means that a translation of input features does not change the outputs at all. So if your pattern 0,3,2,0,0 on the input results in 0,1,0 in the output, then the pattern 0,0,3,2,0 would also lead to 0,1,0.</p>
<p>For feature maps in convolutional networks to be useful, they typically need both equivariance and invariance in some balance. The equivariance allows the network to generalize edge, texture, shape detection in <strong>different</strong> locations. The invariance allows precise location of the detected features to matter less. These are two complementary types of generalization for many image processing tasks.</p>
<p>In a nutshell, in images, these properties ensure that the CNN that is trained to detect an object, can do its job irrespective on where the object is located in the image.</p>
</div>
</div>
<div class="section" id="pooling">
<h2>Pooling<a class="headerlink" href="#pooling" title="Permalink to this headline">¶</a></h2>
<p>Pooling was introduced to reduce redundancy of representation and reduce the number of parameters, recognizing that precise location is not important for object detection.</p>
<p>The pooling function is a form of non-linear function that further modifies the result of the RELU result. The pooling function accepts as input pixel values surrounding (a rectangular region) a feature map location (i,j) and returns one of the following</p>
<ul class="simple">
<li><p>the maximum,</p></li>
<li><p>the average or distance weighted average,</p></li>
<li><p>the L2 norm.</p></li>
</ul>
<p>A pooling layer typically works on every input channel independently, so the output depth is the same as the input depth. You may alternatively pool over the depth dimension, in which case the image’s spatial dimensions (height and width) remain unchanged, but the number of channels is reduced.</p>
<p>Despite receiving ample treatment in Ians Goodfellows’ book, pooling has fallen out of favor. Some reasons are:</p>
<ul class="simple">
<li><p>Datasets are so big that we’re more concerned about under-fitting.</p></li>
<li><p>Dropout is a much better regularizer.</p></li>
<li><p>Pooling results in a loss of information - think about the max-pooling operation as an example shown in the figure below.</p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1412.6806.pdf">All convolutional networks</a> where the pooling is replaced by a CNN with larger stride can do better.</p></li>
</ul>
<p><img alt="pooling" src="../../../../_images/pooling.png" />
<em>Max pooling layer (2 × 2 pooling kernel, stride 2, no padding)</em></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To further understand the latest reservations against pooling in CNNs, see <a class="reference external" href="https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b">this</a> summary of Hinton’s <strong>capsules</strong> concept.</p>
</div>
<div class="section" id="x1-convolutional-layer">
<h3>1x1 Convolutional layer<a class="headerlink" href="#x1-convolutional-layer" title="Permalink to this headline">¶</a></h3>
<p>The 1x1 convolution layer is met in many network architectures (e.g. GoogleNet) and offers a number of modeling capabilities. Spatially, the 1x1 convolution is equivalent to a single number multiplication of each spatial position of the input feature map (if we ignore the non-linearity) as shown below. This means that leaves the spatial dimensions of the input feature maps unchanged unlike the pooling layer.</p>
<p><img alt="1x1-convolution" src="../../../../_images/1x1-convolution.gif" />
<em>1x1 convolution of a single feature map is just scaling - the 1x1 convolution is justified only when we have multiple feature maps at the input</em>.</p>
<p>The most straightforward way to look at this layer is as a <em>cross feature map pooling layer</em>. When we have multiple input feature maps <span class="math notranslate nohighlight">\(M_{l-1}\)</span> and 1x1 filters 1x1x<span class="math notranslate nohighlight">\(M_{l-1}\)</span> (note the depth of the filter must match the number of the input feature maps) then we form a dot product between the feature maps at the spatial location <span class="math notranslate nohighlight">\((i,j)\)</span>  of the 1x1 filter followed by a non-linearity (ReLU). This operation is in other words the same operation of a fully connected single layer neural network whose neurons are those spanned by the single column at the <span class="math notranslate nohighlight">\((i,j)\)</span> coordinate.  This layer will produce a single output at each visited <span class="math notranslate nohighlight">\((i,j)\)</span> coordinate.</p>
<p>This idea can be expanded to multiple layers as described in <a class="reference external" href="https://arxiv.org/pdf/1312.4400v3.pdf">this</a> paper.</p>
<p><img alt="1x1-convolution-b" src="../../../../_images/1x1-convolution-b.png" /></p>
<p>When we have <strong>multiple</strong> <span class="math notranslate nohighlight">\(M_l\)</span> layers of size 1 x 1 x <span class="math notranslate nohighlight">\(M_{l-1}\)</span> then, effectively, we produce multiple feature maps one for each 1x1 layer and this is a good way to reduce the number of feature maps at the output of this layer, with benefits in computational complexity of the deep network as a whole.</p>
</div>
</div>
<div class="section" id="known-cnn-architectures">
<h2>Known CNN Architectures<a class="headerlink" href="#known-cnn-architectures" title="Permalink to this headline">¶</a></h2>
<p>A summary of well known CNN networks are <a class="reference external" href="https://towardsdatascience.com/neural-network-architectures-156e5bad51ba">here</a> article with <a class="reference external" href="https://medium.com/&#64;culurciello/analysis-of-deep-neural-networks-dcf398e71aae">this</a> update as a reference. This summary will be important to you as a starting point to develop your own understanding of very well known CNNs. After you read the corresponding papers in arxiv you will be able to recall key design patterns and why those patterns came to be.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./aiml-common/lectures/cnn/cnn-layers"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../cnn-intro/_index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introduction to Convolutional Neural Networks</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../cnn-example-architectures/_index.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">CNN Example Architectures</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Pantelis Monogioudis, Ph.D<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>