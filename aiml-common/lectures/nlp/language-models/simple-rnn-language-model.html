

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Simple RNN Language Model &#8212; Data Mining</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'aiml-common/lectures/nlp/language-models/simple-rnn-language-model';</script>
    <link rel="canonical" href="https://pantelis.github.io/data-mining/aiml-common/lectures/nlp/language-models/simple-rnn-language-model.html" />
    <link rel="shortcut icon" href="../../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="CNN Language Model" href="cnn-language-model.html" />
    <link rel="prev" title="RNN Language Models" href="_index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../intro.html">
                    Data Mining
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Syllabus</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../syllabus/_index.html">Syllabus</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to Data Mining</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/course-introduction/_index.html">Course Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/data-science-360/_index.html">Data Science 360</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../ai-intro/pipelines/_index.html">Pipelines</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../uber-ml-arch-case-study/_index.html">A Case Study of an ML Architecture - Uber</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../ai-intro/pipelines/02_end_to_end_machine_learning_project.html">Setup</a></li>







</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">The Learning Problem</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../learning-problem/_index.html">The Learning Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../regression/linear-regression/linear_regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../regression/linear-regression/regression-notebooks.html">Regression Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/maximum-likelihood/marginal_maximum_likelihood.html">Maximum Likelihood Estimation of a marginal model</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../optimization/maximum-likelihood/conditional_maximum_likelihood.html">Maximum Likelihood (ML) Estimation of conditional models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../entropy/_index.html">Entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/sgd/_index.html">Stochastic Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../classification/classification-intro/_index.html">Introduction to Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../classification/logistic-regression/_index.html">Logistic Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../classification/perceptron/_index.html">The Neuron (Perceptron)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/dnn-intro/_index.html">Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/backprop-intro/_index.html">Introduction to Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/backprop-dnn/_index.html">Backpropagation in Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/backprop-dnn-exercises/_index.html">Backpropagation DNN exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/fashion-mnist-case-study.html">Fashion MNIST Case Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/regularization/_index.html">Regularization in Deep Neural Networks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Convolutional Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-intro/_index.html">Introduction to Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-layers/_index.html">CNN Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/_index.html">CNN Example Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">Using convnets with small datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../scene-understanding/feature-extraction-resnet/index.html">Feature Extraction via Residual Networks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Transfer Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../transfer-learning/transfer-learning-introduction.html">Introduction to Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../transfer-learning/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Scene Understanding</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../scene-understanding/scene-understanding-intro/index.html">Introduction to Scene Understanding</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../scene-understanding/object-detection/object-detection-intro/index.html">Object Detection</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/object-detection/detection-metrics/index.html">Object Detection and Semantic Segmentation Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/object-detection/rcnn-object-detection/index.html">Region-CNN (RCNN) Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/object-detection/faster-rcnn-object-detection/index.html">Fast and Faster RCNN Object Detection</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Sequences and RNNs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../rnn/introduction/_index.html">Introduction to Recurrent Neural Networks (RNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/simple-rnn/_index.html">Simple RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/lstm/_index.html">The Long Short-Term Memory (LSTM) Cell Architecture</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Embeddings and NLP</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../nlp-intro/_index.html">Introduction to NLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../word2vec/_index.html">Word2Vec Embeddings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../word2vec/word2vec-workshop.html">Word2Vec Workshop</a></li>
<li class="toctree-l1"><a class="reference internal" href="_index.html">RNN Language Models</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Simple RNN Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="cnn-language-model.html">CNN Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nmt/_index.html">Neural Machine Translation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Classical Learning Methods</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../decision-trees/_index.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../regression-trees/regression_trees.html">Regression tree stumps</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../ensemble/_index.html">Ensemble Methods </a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ensemble/random-forests/_index.html">Random Forests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ensemble/adaboost/index.html">Adaptive Boosting (AdaBoost)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ensemble/gradient-boosting/index.html">Gradient Boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ensemble/boosting-workshop/_index.html">Boosting workshop</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bayesian Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../pgm/bayesian-inference/_index.html">Bayesian Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pgm/bayesian-inference/bayesian_regression.html">Bayesian Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pgm/bayesian-coin/bayesian_update_coin_flip.html">Posterior updates in a coin flipping experiment</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Non-Parametric Methods</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../unsupervised/k-means/_index.html">K-means Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../density-estimation/knn/_index.html">k-Nearest Neighbors (kNN) Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../density-estimation/knn-workshop/_index.html">kNN Workshop</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Dimensionality Reduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../pca/_index.html">Principal Component Analysis (PCA)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Math Background</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/index.html">Math for ML Textbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/probability/index.html">Probability Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/linear-algebra/index.html">Linear Algebra for Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/calculus/index.html">Calculus</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/index.html">Your Programming Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/assignment-submission.html">Submitting Your Assignment / Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python/index.html">Learn Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/notebook-status.html">Notebook execution status</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/probability/probability-assignment-5/index.html">Probability Assignment</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../assignments/mle/poisson-regression-1/index.html">Bike Rides and the Poisson Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/cnn-face-similarity/index.html">CNN Featurizers and Similarity Search</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project (CS482)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/nlp/finetuning-language-models-tweets/index.html">Finetuning Language Models - Toxic Tweets</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project (CS634)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/nlp/finetuning-language-models-patents/index.html">Finetuning Language Models - Can I Patent This?</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/pantelis/data-mining/master?urlpath=tree/data_mining/aiml-common/lectures/nlp/language-models/simple-rnn-language-model.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/pantelis/data-mining/blob/master/data_mining/aiml-common/lectures/nlp/language-models/simple-rnn-language-model.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pantelis/data-mining" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pantelis/data-mining/edit/master/data_mining/aiml-common/lectures/nlp/language-models/simple-rnn-language-model.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pantelis/data-mining/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/nlp/language-models/simple-rnn-language-model.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/aiml-common/lectures/nlp/language-models/simple-rnn-language-model.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Simple RNN Language Model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a class="reference external" href="https://colab.research.google.com/github/pantelis-nlp/tutorial-nlp-notebooks/blob/main/rnn_language_model.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="simple-rnn-language-model">
<h1>Simple RNN Language Model<a class="headerlink" href="#simple-rnn-language-model" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="s1">&#39;Chios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, with a ridge of mountains running the length of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), are situated in the north of the island. The center of the island is divided between east and west by a range of smaller peaks, known as Provatas.&#39;</span>
<span class="c1"># data I/O</span>
<span class="c1"># data = open(&#39;input.txt&#39;, &#39;r&#39;).read() # should be simple plain text file - you can use any (small) file in txt format from the web or type your own. </span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># creating a vocabulary of unique characters</span>
<span class="n">chars</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>                                                   
<span class="n">data_size</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;data has </span><span class="si">%d</span><span class="s1"> characters, </span><span class="si">%d</span><span class="s1"> unique.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">data_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>data has 508 characters, 43 unique.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data pre-processing</span>
<span class="c1"># creating a dictionary, mapping characters to index and index to characters</span>
<span class="n">char_to_ix</span> <span class="o">=</span> <span class="p">{</span> <span class="n">ch</span><span class="p">:</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span> <span class="p">}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">char_to_ix</span><span class="p">)</span>
<span class="n">ix_to_char</span> <span class="o">=</span> <span class="p">{</span> <span class="n">i</span><span class="p">:</span><span class="n">ch</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span> <span class="p">}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ix_to_char</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;9&#39;: 0, &#39;d&#39;: 1, &#39;s&#39;: 2, &#39;0&#39;: 3, &#39;c&#39;: 4, &#39;7&#39;: 5, &#39;a&#39;: 6, &#39;u&#39;: 7, &#39;P&#39;: 8, &#39;b&#39;: 9, &#39;n&#39;: 10, &#39;)&#39;: 11, &#39;k&#39;: 12, &#39;g&#39;: 13, &#39;o&#39;: 14, &#39;r&#39;: 15, &#39;l&#39;: 16, &#39;.&#39;: 17, &#39;p&#39;: 18, &#39;2&#39;: 19, &#39;1&#39;: 20, &#39;[&#39;: 21, &#39;5&#39;: 22, &#39;i&#39;: 23, &#39;w&#39;: 24, &#39;q&#39;: 25, &#39;m&#39;: 26, &#39;(&#39;: 27, &#39;t&#39;: 28, &#39;3&#39;: 29, &#39;4&#39;: 30, &#39;]&#39;: 31, &#39;v&#39;: 32, &#39;,&#39;: 33, &#39;C&#39;: 34, &#39;y&#39;: 35, &#39;8&#39;: 36, &#39;h&#39;: 37, &#39;T&#39;: 38, &#39;f&#39;: 39, &#39;E&#39;: 40, &#39;e&#39;: 41, &#39; &#39;: 42}
{0: &#39;9&#39;, 1: &#39;d&#39;, 2: &#39;s&#39;, 3: &#39;0&#39;, 4: &#39;c&#39;, 5: &#39;7&#39;, 6: &#39;a&#39;, 7: &#39;u&#39;, 8: &#39;P&#39;, 9: &#39;b&#39;, 10: &#39;n&#39;, 11: &#39;)&#39;, 12: &#39;k&#39;, 13: &#39;g&#39;, 14: &#39;o&#39;, 15: &#39;r&#39;, 16: &#39;l&#39;, 17: &#39;.&#39;, 18: &#39;p&#39;, 19: &#39;2&#39;, 20: &#39;1&#39;, 21: &#39;[&#39;, 22: &#39;5&#39;, 23: &#39;i&#39;, 24: &#39;w&#39;, 25: &#39;q&#39;, 26: &#39;m&#39;, 27: &#39;(&#39;, 28: &#39;t&#39;, 29: &#39;3&#39;, 30: &#39;4&#39;, 31: &#39;]&#39;, 32: &#39;v&#39;, 33: &#39;,&#39;, 34: &#39;C&#39;, 35: &#39;y&#39;, 36: &#39;8&#39;, 37: &#39;h&#39;, 38: &#39;T&#39;, 39: &#39;f&#39;, 40: &#39;E&#39;, 41: &#39;e&#39;, 42: &#39; &#39;}
</pre></div>
</div>
</div>
</div>
<p>Our aim is to predict the next character given a set of previous characters from our data string.</p>
<p>For our RNN  implementation, we would take a sequence of length 25 characters as inputs to predict the next character.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># see here for notation http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture10.pdf</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Minimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)</span>
<span class="sd">BSD License</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;\nMinimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)\nBSD License\n&#39;
</pre></div>
</div>
</div>
</div>
<a class="reference internal image-reference" href="https://drive.google.com/uc?id=12ha59vACcd8eCEPAQdbZ4-axPGPKnn7F"><img alt="https://drive.google.com/uc?id=12ha59vACcd8eCEPAQdbZ4-axPGPKnn7F" src="https://drive.google.com/uc?id=12ha59vACcd8eCEPAQdbZ4-axPGPKnn7F" style="width: 700px;" /></a>
<p><strong>Inputs to RNN</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_1\)</span> to <span class="math notranslate nohighlight">\(x_{25}\)</span> is the input sequence of 25 characters, one character given as input to RNN at each time step</p></li>
</ul>
<p><strong>Hidden state of RNN</strong></p>
<ul class="simple">
<li><p>The state consists of a single ‘hidden’ vector h</p></li>
<li><p>At every time step, a recurrence function <span class="math notranslate nohighlight">\(f_W\)</span> with parameters <span class="math notranslate nohighlight">\(W_{xh}\)</span>, <span class="math notranslate nohighlight">\(W_{hh}\)</span> and <span class="math notranslate nohighlight">\(b_h\)</span> is applied to the input <span class="math notranslate nohighlight">\(x_t\)</span> and the output from the previous hidden state <span class="math notranslate nohighlight">\(h_{t-1}\)</span>, to generate <span class="math notranslate nohighlight">\(h_t\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad h_t = f_W (h_{t-1},x_t)\)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \; \; \; \; = tanh (W_{hh}h_{t-1} + W_{xh}x_t + b_h)\)</span></p>
<p><strong>Outputs of the RNN</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y_T\)</span> is the character that our network would predict after <span class="math notranslate nohighlight">\(T=25\)</span> time steps</p></li>
<li><p>At each time step, a <span class="math notranslate nohighlight">\(y_t\)</span> is calculated as</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad y_t = W_{hy}h_t + b_y\)</span></p>
<ul class="simple">
<li><p>The softmax of <span class="math notranslate nohighlight">\(y_t\)</span> is the set of probabilities of occurance of each unique character in the input data</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad softmax(y_t)\)</span></p>
<ul class="simple">
<li><p>At each time step, from <span class="math notranslate nohighlight">\(t=1\)</span> to <span class="math notranslate nohighlight">\(25\)</span>, loss is calculated from the set of predicted probabilities.</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad L_t = Cross\;Entropy(softmax(y_t), target_t)\)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> where the <span class="math notranslate nohighlight">\(target\)</span> is the next character to the input sequence in the data string</p>
<ul class="simple">
<li><p>The total loss is the sum of all the losses from the previously unrolled steps</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad L = ∑_{t=0}^{24}L_t\)</span></p>
<p>All the weights <span class="math notranslate nohighlight">\(W_{xh}\)</span>, <span class="math notranslate nohighlight">\(W_{hh}\)</span>, <span class="math notranslate nohighlight">\(b_h\)</span>, <span class="math notranslate nohighlight">\(W_{hy}\)</span> and <span class="math notranslate nohighlight">\(b_y\)</span> are reused at each time step.</p>
<p><strong>Hyperparameters</strong></p>
<ul class="simple">
<li><p>the size of hidden state of neurons</p></li>
<li><p>the sequence length or the time steps to unroll, which is 25 in our case</p></li>
<li><p>optimizer we use here is Adagrad</p></li>
<li><p>the learning rate for Adagrad optimizer</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># hyperparameters</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">100</span>           <span class="c1"># size of hidden layer of neurons</span>
<span class="n">seq_length</span> <span class="o">=</span> <span class="mi">25</span>             <span class="c1"># number of time steps to unroll the RNN for, taking 25 previous characters to predict the next</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-1</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Dimensions of tensors</strong></p>
<p>Input:</p>
<ul class="simple">
<li><p>Each character from the data string is pre-processed before being fed then into the RNN</p></li>
<li><p>From each sequence of 25 characters (for 25 time-steps) from the data string, we create an ‘inputs’ list of tokenized integer values</p></li>
<li><p>Each character is converted to an integer token index using ‘char_to_ix’ function, which maps each character to a number between 0 and 42 (as there are 43 unique characters in our data)</p></li>
<li><p>The integer tokens from the ‘inputs’ list are then one-hot encoded in 1-of-k representations, ie, into vectors of size 43 (k=43 unique characters in our data), which are fed as inputs to the RNN</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of input <span class="math notranslate nohighlight">\(x_t =\)</span> (43,1)</p>
<p>Targets:</p>
<ul class="simple">
<li><p>For each input in the ‘inputs’ list, we create a ‘target’ list consisting of the subsequent character’s integer token</p></li>
<li><p>Our ‘targets’ list, which is used during the cross-entropy loss calculation, is of length 25</p></li>
</ul>
<p>Predicted output:</p>
<ul class="simple">
<li><p>The predicted outputs are the probabilities of the next characters</p></li>
<li><p>Since k=43 unique characters, the unnormalized log probabilities for next chars is given by <span class="math notranslate nohighlight">\(y_t =\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of output <span class="math notranslate nohighlight">\(y_t =\)</span> (43,1)</p>
<ul class="simple">
<li><p>The <span class="math notranslate nohighlight">\(softmax(y_t)\)</span> gives the class probabilities for next characters</p></li>
<li><p>The probabilities are then converted into one-hot encoded vectors using argmax</p></li>
<li><p>The one-hot encoded vectors are converted into integer tokens and then to a single character using ‘ix_to_char’ function</p></li>
</ul>
<p>Hidden layers:</p>
<ul class="simple">
<li><p>Since we have chosen 100 neurons in the hidden layer,</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of hidden state <span class="math notranslate nohighlight">\(h_t =\)</span> (100,1)</p>
<p>Model parameters:</p>
<ul class="simple">
<li><p>Given the hidden_size=100,  input x dimension=(43,1) and output y dimension=(43,1):</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of <span class="math notranslate nohighlight">\(W_{xh} =\)</span> (100,43),</p>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of <span class="math notranslate nohighlight">\(W_{hh} =\)</span> (100,100),</p>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of <span class="math notranslate nohighlight">\(b_{h} =\)</span> (100,1),</p>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of <span class="math notranslate nohighlight">\(W_{hy} =\)</span> (43,100),</p>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of <span class="math notranslate nohighlight">\(b_{y} =\)</span> (43,1)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># model parameters</span>
<span class="c1"># we set the initial values of the weights randomly from a normal distribution and set all the bias to zero</span>

<span class="n">Wxh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>   <span class="c1"># input to hidden, shape = (hidden_size, vocab_size) = (100,43)</span>
<span class="n">Whh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>  <span class="c1"># hidden to hidden, shape = (hidden_size, hidden_size) = (100,100)</span>
<span class="n">Why</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>   <span class="c1"># hidden to output, shape = (vocab_size, hidden_size) = (43,100)</span>
<span class="n">bh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>                       <span class="c1"># hidden bias, shape  = (hidden_size, 1) = (100,1)</span>
<span class="n">by</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>                        <span class="c1"># output bias, shape  = (vocab_size, 1) = (43,1)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Forward Pass</strong></p>
<ul class="simple">
<li><p>Forward through entire sequence <span class="math notranslate nohighlight">\(x_1\)</span> to <span class="math notranslate nohighlight">\(x_{25}\)</span> to compute loss</p></li>
<li><p>Calculate hidden states at each time step</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad h_t = tanh (W_{hh}h_{t-1} + W_{xh}x_t + b_h)\)</span></p>
<ul class="simple">
<li><p>Calculate output <span class="math notranslate nohighlight">\(y_t\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad y_t = W_{hy}h_t + b_y\)</span></p>
<ul class="simple">
<li><p>The softmax of <span class="math notranslate nohighlight">\(y_t\)</span> is the set of probabilities of occurance of each unique character in the input data</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad p_t = softmax(y_t)\)</span></p>
<ul class="simple">
<li><p>Calculate loss at each time step</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad L_t = Cross\;Entropy(p_t, target_t)\)</span></p>
<ul class="simple">
<li><p>Calculate the total loss, which is the negative log likelihood of our model</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad L = ∑_{t=0}^{24}L_t\)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \; \; \; \; = - ∑_t log \; p_{model} (y_t | x_1,...,x_t)\)</span></p>
<p><strong>Backpropogation Through Time</strong></p>
<ul class="simple">
<li><p>Backward through entire sequence to compute gradient</p></li>
<li><p>The nodes include parameters <span class="math notranslate nohighlight">\(W_{xh}\)</span>, <span class="math notranslate nohighlight">\(W_{hh}\)</span>, <span class="math notranslate nohighlight">\(b_h\)</span>, <span class="math notranslate nohighlight">\(W_{hy}\)</span> and <span class="math notranslate nohighlight">\(b_y\)</span></p></li>
<li><p>The inputs and outputs of nodes are <span class="math notranslate nohighlight">\(x_t\)</span>, <span class="math notranslate nohighlight">\(h_t\)</span>, <span class="math notranslate nohighlight">\(y_t\)</span>, <span class="math notranslate nohighlight">\(p_t\)</span> and <span class="math notranslate nohighlight">\(L_t\)</span> at time-step <span class="math notranslate nohighlight">\(t\)</span></p></li>
<li><p>We’ll use the suffix <span class="math notranslate nohighlight">\((i)\)</span> to indicate the <span class="math notranslate nohighlight">\(i^{th}\)</span> sample</p></li>
</ul>
<p><em>Gradients on the internal nodes:</em></p>
<ul class="simple">
<li><p>We’ll be computing the gradients recursively starting with the nodes immediately preceding the final loss</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial L_t}  = 1 \)</span></p>
<ul class="simple">
<li><p>The gradient with respect to the softmax layer would be:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial y_{(i)t}}  = p_{(i)t} -1 \)</span></p>
<ul class="simple">
<li><p>At t=25, the gradient with respect to the hidden layer would be:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial h_{t=25}}  = {W_{hy}}^T \frac{\partial L}{\partial y_{t=25}} \)</span></p>
<ul class="simple">
<li><p>We can now iterate backwards from t=24 down to t=1:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial h_{t}}  =  \bigg(\frac{\partial h_{t+1}}{\partial h_{t}}\bigg)^T \frac{\partial L}{\partial h_{t+1}} + \bigg(\frac{\partial y_{t}}{\partial h_{t}}\bigg)^T \frac{\partial L}{\partial y_{t}}  \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \qquad = (W_{hh})^T \; diag\bigg(1-(h_{t+1})^2\bigg) \frac{\partial L}{\partial h_{t+1}}  + (W_{hy})^T \frac{\partial L}{\partial y_{t}} \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \)</span> where <span class="math notranslate nohighlight">\(diag\bigg(1-(h_{t+1})^2\bigg)\)</span> indicates the diagonal matrix containing the elements <span class="math notranslate nohighlight">\(1-(h_{(i)t+1})^2\)</span></p>
<p><em>Gradients on the parameter nodes:</em></p>
<ul class="simple">
<li><p>Gradients with respect to <span class="math notranslate nohighlight">\(W_{hy}\)</span>:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial W_{hy}} = \sum_t  \sum_i \frac{\partial L}{\partial y_{(i)t}} \frac{\partial y_{(i)t}}{\partial W_{hy}} \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad  \qquad = \sum_t  \frac{\partial L}{\partial y_t} (h_t)^T\)</span></p>
<ul class="simple">
<li><p>Gradients with respect to <span class="math notranslate nohighlight">\(b_y\)</span>:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial b_{y}} = \sum_t \bigg(\frac{\partial y_t}{\partial b_{y}}\bigg)^T \frac{\partial L}{\partial y_{t}} \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad  \qquad = \sum_t \frac{\partial L}{\partial y_{t}} \)</span></p>
<ul class="simple">
<li><p>Gradients with respect to <span class="math notranslate nohighlight">\(W_{hh}\)</span>:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial W_{hh}} = \sum_t  \sum_i \frac{\partial L}{\partial h_{(i)t}} \frac{\partial h_{(i)t}}{\partial W_{hh}} \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad  \qquad = \sum_t diag\bigg(1-(h_{t})^2\bigg)  \frac{\partial L}{\partial h_t} (h_{t-1})^T\)</span></p>
<ul class="simple">
<li><p>Gradients with respect to <span class="math notranslate nohighlight">\(b_h\)</span>:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial b_{h}} = \sum_t \bigg(\frac{\partial h_t}{\partial b_{h}}\bigg)^T \frac{\partial L}{\partial h_{t}} \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad  \qquad = \sum_t diag\bigg(1-(h_{t})^2\bigg)  \frac{\partial L}{\partial h_{t}} \)</span></p>
<ul class="simple">
<li><p>Gradients with respect to <span class="math notranslate nohighlight">\(W_{xh}\)</span>:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial W_{xh}} = \sum_t  \sum_i \frac{\partial L}{\partial h_{(i)t}} \frac{\partial h_{(i)t}}{\partial W_{xh}} \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad  \qquad = \sum_t diag\bigg(1-(h_{t})^2\bigg)  \frac{\partial L}{\partial h_t} (x_t)^T\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">lossFun</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">hprev</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  inputs,targets are both list of integers.</span>
<span class="sd">  hprev is Hx1 array of initial hidden state</span>
<span class="sd">  perform forward and backward pass</span>
<span class="sd">  returns the loss, gradients on model parameters, and last hidden state</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="n">xs</span><span class="p">,</span> <span class="n">hs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">ps</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{},</span> <span class="p">{},</span> <span class="p">{}</span>
  <span class="n">hs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hprev</span><span class="p">)</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="c1"># forward pass: compute loss going forward</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>                                         <span class="c1"># looping for t timesteps, which is the size of the length of inputs</span>
    <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>                                   <span class="c1"># xs = one-hot encode in 1-of-k representation</span>
    <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="n">inputs</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Wxh</span><span class="p">,</span> <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Whh</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="n">bh</span><span class="p">)</span>    <span class="c1"># hs_t = tanh(W_hh.hs_t-1 + W_xh.xs_t + b_h) -&gt; hidden state</span>
    <span class="n">ys</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Why</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">+</span> <span class="n">by</span>                                    <span class="c1"># ys = W_hy.hs_t + b_y -&gt; unnormalized log probabilities for next chars</span>
    <span class="n">ps</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">ys</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">ys</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span>                      <span class="c1"># ps = softmax(ys) -&gt; probabilities for next chars</span>
    <span class="n">loss</span> <span class="o">+=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ps</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="n">targets</span><span class="p">[</span><span class="n">t</span><span class="p">],</span><span class="mi">0</span><span class="p">])</span>                               <span class="c1"># cross-entropy loss</span>

  <span class="c1"># backward pass: compute gradients going backwards</span>
  <span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Wxh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Whh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Why</span><span class="p">)</span>      <span class="c1"># create numpy arrays for right size for the weights</span>
  <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">bh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>                                    <span class="c1"># create numpy arrays for right size for the biasses</span>
  <span class="n">dhnext</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">hs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>                                                      <span class="c1"># h_t-1 for the first iteration is set to all zeros</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))):</span>
    <span class="n">dy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">ps</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>
    <span class="n">dy</span><span class="p">[</span><span class="n">targets</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">-=</span> <span class="mi">1</span>                      <span class="c1"># backprop into y by taking gradient for softmax (http://cs231n.github.io/neural-networks-case-study/#grad)</span>
    <span class="n">dWhy</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>              <span class="c1"># gradient for Why</span>
    <span class="n">dby</span> <span class="o">+=</span> <span class="n">dy</span>                                <span class="c1"># gradient for by</span>
    <span class="n">dh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Why</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span> <span class="o">+</span> <span class="n">dhnext</span>          <span class="c1"># backprop into h</span>
    <span class="n">dhraw</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">*</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">*</span> <span class="n">dh</span>         <span class="c1"># backprop through tanh nonlinearity</span>
    <span class="n">dbh</span> <span class="o">+=</span> <span class="n">dhraw</span>                             <span class="c1"># gradient for bh</span>
    <span class="n">dWxh</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dhraw</span><span class="p">,</span> <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>           <span class="c1"># gradient for Wxh</span>
    <span class="n">dWhh</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dhraw</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>         <span class="c1"># gradient for Whh</span>
    <span class="n">dhnext</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Whh</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dhraw</span><span class="p">)</span>            <span class="c1"># calculate h_t-1 for the next iteration</span>
  <span class="k">for</span> <span class="n">dparam</span> <span class="ow">in</span> <span class="p">[</span><span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span><span class="p">,</span> <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span><span class="p">]:</span>
    <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">dparam</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">dparam</span><span class="p">)</span>                              <span class="c1"># clip gradients to mitigate exploding gradients</span>
  <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span><span class="p">,</span> <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">seed_ix</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot; </span>
<span class="sd">  sample a sequence of integers from the model </span>
<span class="sd">  h is memory state, seed_ix is seed letter for first time step</span>
<span class="sd">  predicts probabilities for each character </span>
<span class="sd">  returns the set of predicted indices with the highest probabilities</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># at test-time sample characters one at a time, feed back to model for next character prediction</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="n">x</span><span class="p">[</span><span class="n">seed_ix</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>                                              <span class="c1"># x = one-hot encode the input for seed_ix letter in 1-of-k representation</span>
  <span class="n">ixes</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># predicting the next character</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Wxh</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Whh</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="n">bh</span><span class="p">)</span>         <span class="c1"># h_t = tanh(W_hh.h_t-1 + W_xh.x_t + b_h) -&gt; hidden state                    </span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Why</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="n">by</span>                                   <span class="c1"># y = W_hy.h_t + b_y -&gt; unnormalized log probabilities for next chars</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>                         <span class="c1"># p = softmax(y) -&gt; probabilities for next chars</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>     <span class="c1"># p.ravel gives the probabilities of each entry, with the maximum ix at argmax</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  
    <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>                                                 <span class="c1"># convert probabilities to one-hot encoded vectors in 1-of-k representation</span>
    <span class="n">ixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ix</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">ixes</span>                                                 <span class="c1"># return all the indices to convert them into characters and print the predictions</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># p-data pointer, n-iteration counter</span>
<span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>                        <span class="c1"># setting both to zero in the beginning</span>

<span class="c1"># memory variables for Adagrad, initialized to all zeros</span>
<span class="n">mWxh</span><span class="p">,</span> <span class="n">mWhh</span><span class="p">,</span> <span class="n">mWhy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Wxh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Whh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Why</span><span class="p">)</span>    
<span class="n">mbh</span><span class="p">,</span> <span class="n">mby</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">bh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">by</span><span class="p">)</span> 

<span class="c1"># loss at time instance 0</span>
<span class="n">smooth_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">vocab_size</span><span class="p">)</span><span class="o">*</span><span class="n">seq_length</span> 

<span class="c1"># while True:</span>
<span class="c1"># running for 80000 epochs</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">8000</span><span class="p">):</span>

  <span class="c1"># Data pre-processing to prepare inputs and targets</span>
  <span class="k">if</span> <span class="n">p</span><span class="o">+</span><span class="n">seq_length</span><span class="o">+</span><span class="mi">1</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="ow">or</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>                        <span class="c1"># sweeping from left to right in steps seq_length=25 long</span>
    <span class="n">hprev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">hidden_size</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>                              <span class="c1"># reset RNN memory</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span>                                                          <span class="c1"># go from start of data</span>
  <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">char_to_ix</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="n">p</span><span class="p">:</span><span class="n">p</span><span class="o">+</span><span class="n">seq_length</span><span class="p">]]</span>         <span class="c1"># inputs are tokens each of length seq_length=25</span>
  <span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">char_to_ix</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">p</span><span class="o">+</span><span class="n">seq_length</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span>    <span class="c1"># targets are the tokens of the subsequent characters for each input sequence</span>

  <span class="c1"># Model testing</span>
  <span class="k">if</span> <span class="n">n</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">sample_ix</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">hprev</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">200</span><span class="p">)</span>                   <span class="c1"># sample from the model and predict characters every 1000 iterations</span>
    <span class="n">txt</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ix_to_char</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="k">for</span> <span class="n">ix</span> <span class="ow">in</span> <span class="n">sample_ix</span><span class="p">)</span>           <span class="c1"># convert tokens into characters and add it to the list of previous predictions</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----</span><span class="se">\n</span><span class="s1"> </span><span class="si">%s</span><span class="s1"> </span><span class="se">\n</span><span class="s1">----&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">txt</span><span class="p">,</span> <span class="p">))</span>                         <span class="c1"># print model predictions</span>

  <span class="c1"># Model training</span>
  <span class="n">loss</span><span class="p">,</span> <span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span><span class="p">,</span> <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span><span class="p">,</span> <span class="n">hprev</span> <span class="o">=</span> <span class="n">lossFun</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">hprev</span><span class="p">)</span>   <span class="c1"># forward seq_length characters through the net and fetch gradient</span>
  <span class="n">smooth_loss</span> <span class="o">=</span> <span class="n">smooth_loss</span> <span class="o">*</span> <span class="mf">0.999</span> <span class="o">+</span> <span class="n">loss</span> <span class="o">*</span> <span class="mf">0.001</span>                            <span class="c1"># RNN adds all the losses from the previously unrolled steps</span>
  <span class="k">if</span> <span class="n">n</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;iter </span><span class="si">%d</span><span class="s1">, loss: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">smooth_loss</span><span class="p">))</span>             <span class="c1"># print progress</span>
  
  <span class="c1"># parameter update with Adagrad</span>
  <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">dparam</span><span class="p">,</span> <span class="n">mem</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">Wxh</span><span class="p">,</span> <span class="n">Whh</span><span class="p">,</span> <span class="n">Why</span><span class="p">,</span> <span class="n">bh</span><span class="p">,</span> <span class="n">by</span><span class="p">],</span> 
                                <span class="p">[</span><span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span><span class="p">,</span> <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span><span class="p">],</span> 
                                <span class="p">[</span><span class="n">mWxh</span><span class="p">,</span> <span class="n">mWhh</span><span class="p">,</span> <span class="n">mWhy</span><span class="p">,</span> <span class="n">mbh</span><span class="p">,</span> <span class="n">mby</span><span class="p">]):</span>
    <span class="n">mem</span> <span class="o">+=</span> <span class="n">dparam</span> <span class="o">*</span> <span class="n">dparam</span>
    <span class="n">param</span> <span class="o">+=</span> <span class="o">-</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dparam</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mem</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>              <span class="c1"># adagrad parameter update</span>

  <span class="n">p</span> <span class="o">+=</span> <span class="n">seq_length</span>                                                       <span class="c1"># move data pointer</span>
  <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>                                                                <span class="c1"># iteration counter </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>----
 oq7wTvb.bksek.CTolkw]dl31[esuqwsww4gq2Ctd,)7P,fi00is3,Thi]2oEhtvoP.4Cybf83go90pa3y0PEs1req]v]khaeggivCf[8P5Cqpb[E5smtq)([gT0C5ns)sa4hTekk42yd]wqndTlk8u9m41bs,f078ew]7T1(2]T(,wp]P9)2flyybb.8hTPuukkb4]. 
----
iter 0, loss: 94.030000
----
 hiosh inseinoe o) s, kmt)e)algeidf  iolialsarrand. (h8 b39 kthe oris knoPires sa naf ates s47 f mitwf (4T2 a ndind awretf of th th2 i) apesotwed mt)  sniundemees thib  the ind is9inos1. Ped and t)ed i 
----
iter 1000, loss: 72.848263
----
 liss (Pi) ind lrst.[210 wnountaind we gestwt, islan a ge nten longet, is lanler t aid indwrmownwind islate in the nseanded ast)) kn5 s (31 mountast ipnd and islant orerineinescencer, aateain afntereth 
----
iter 2000, loss: 41.491765
----
 heos inge of these mountwre teon (1, Th the a st)), [1 and west bed west 4,188 ft)), an isis and Epos (1,255 ak iountanenty mowntan (1,297 m (4,18, st.[2] The the island. The center in the of the isla 
----
iter 3000, loss: 21.440355
----
 hios island is aped, 508 mounn(31 mi) long from north of the island. The tso lares pos arent or klent isdd)e covering an area of 842.289 km2 (325.210 s.2.[89 km2 ((25.210 sq mit.[2] 29 km (18 mi) at i 
----
iter 4000, loss: 10.351897
----
 hioss,898 mounthe n ens The two lared enoes, kidan of 842.289 kmi).[2] The tonsof these misland or kids, mithe n erak ith west Epos (1,18 m (18 kn (3,898 ft)),89 m97 m (3,255 ft)), ares of the islanes 
----
iter 5000, loss: 9.279704
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long fro, south, and 29 km mland. The center of the eridge of mountains running the length of the island. The center of the island is divided bi 
----
iter 6000, loss: 4.833243
----
 hios island is aped, 51t1 a ridge of mountains runeing the land Epom (1,188 i)) widest, covering an area of 842.[2] The terthe ous, widod be Prin, wit of these mountains, Pelineen ingth of the island. 
----
iter 7000, loss: 2.589996
----
 hios island is (4,255 ft)) and Epos (1,188 m (3,898 ft)), are situst, saaped, 5orunning tud in the north of the island. The center of the island is divids wideor kteom smt nt.[2] The terrain is mounta 
----
iter 8000, loss: 1.566884
----
 hios island is (4,255 ft)), are kiteated in the north of the island. The center twnt areat islan(1,29, area o  Prd an area of the island. The center of the island ish weakino ith wed arid, with in the 
----
iter 9000, loss: 1.073685
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq 5q mi).[2] The terrain is mountainous ind 
----
iter 10000, loss: 0.815450
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering and. The two largest of these mountains, Pelineon (1,297 m (42255 and.210 sq 
----
iter 11000, loss: 0.666259
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 k12 (325.21m (31 mi) long from north to south, and 29 km (18 mi)..210 Pelineon (1,297 m (4,255 ft)) and Epos (1 
----
iter 12000, loss: 0.571068
----
 hios island is crest, covering an area of 842.289 km2 (325.210 sq mi).[2] The mous and arid, kitwn arid, kitm a  sland, Pr( and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq 
----
iter 13000, loss: 0.504284
----
 hios island is crescent or kidney shaped, 50 km (3,898 ft)), are situated in the north of the island. The two largest of thes of 842.289 km2 (325.210 sq mi).[2] The ternor9 kintwn ast and west by a ra 
----
iter 14000, loss: 0.454044
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842..210 sq mi).[2] The terrain is mountainous and arid, with a r 
----
iter 15000, loss: 0.414568
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its wideaits mountainous and arid, with a ridge of mountains running the length of the island. Th 
----
iter 16000, loss: 0.382602
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering and west by a range of smaller peaks, known as Prid, with a ridge of mountai 
----
iter 17000, loss: 0.356144
----
 hios island is crescent or kidney shaped, 50 km (31 5,8328 km (18 m (18 5.,898 ft)), ak island. The center of the island is divided between east and west by a range nf the Epos (1,188 m (3,898 ft)), a 
----
iter 18000, loss: 0.333839
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 llrges arid, with i9 mof th tfe oun an ind rren er of the 
----
iter 19000, loss: 0.314753
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 25.2189 mi)) and Epos (1,188 m (3,898 ft)), are situated in the north of the island. The center of the island is d 
----
iter 20000, loss: 0.298233
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 s, kntwn asd ilsn arid, with  mit. th the islast and west by a range of smaller peaks, known as Prgth to 
----
iter 21000, loss: 0.283769
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north tt north tf to south, and 29 km (18 mi) ak it) larges aretce tuono of these mountains, Pelineon (1,297 m (4,255 ft)) and Epos (9 
----
iter 22000, loss: 0.271125
----
 hios island is crescent or kidney shaped, 50 km (3,898 ft)), are situated in the north of the island. The two largest of these mountains, Pelineorid in and arid, with a ridge of mountains running the  
----
iter 23000, loss: 0.260058
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 24000, loss: 0.251042
----
 hios island is Pridge oron brthe north tt south, ares Ped ar s,297 m (4idg 89 knt blong the land by anes ares (188 moung fnthe island. The thes crid, with weaknit anea ois am coveris aig are kist its  
----
iter 25000, loss: 11.138854
----
 hios uned an aivideeeislaltnous Emd am (1,297 m (4,255 ft)) and Epos (1id peat are tisllange north tt kof th sh.)w nth[21 8 and. The two laristhese mountains, Prange mowneastwits widest, covering an a 
----
iter 26000, loss: 6.324848
----
 hios island or the island. The thestam of the t, ftth of sm mi)53210 aid are ta) (325.210 sq mi).[2] The terrain is mountarea of 842.289 km2 (325.29 kmd as Pelineon (1,297 m (4,255 ft)) and Ewos Pridg 
----
iter 27000, loss: 3.588278
----
 hios island is crescerange ise s,831 mi) aid is (1,297 m (4,255 ft)) and are t by a range of sm lartrge aareon (1,131 mi) awn ispest by a rans8 mid bis ind betweeof smaller peaks, known as Pridde of t 
----
iter 28000, loss: 2.098169
----
 hios island is crescent or kidney shaped, with wedent of the island. The two largestnorof wits wist an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and aret, with a ridge of moun 
----
iter 29000, loss: 1.531017
----
 hios arant, 50 Th  f,842.289 km2 (325.210 sq mi).[2] The terrain is mountainous mof the island. The ben the kitnd between east and west by a range of smaller peaks, and Epos (1,188 m (3,898 ft)), are  
----
iter 30000, loss: 1.004267
----
 hios island is crescented lwnd by area of 842.289 km2 (325.210 sq mi).[2] The tainous and arescenter of the island is divided between east and west by a range of smaller peaks, known as Pridge of moun 
----
iter 31000, loss: 0.742361
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to sout4,898 ft)), are situated in the north of the island. The center of the islangest of these mountains, Pelineon (1,297 m (4 
----
iter 32000, loss: 0.597886
----
 hios island is crescent or kidney shaped, 50 km (31 mountbit ane 29 km (18 mi) at its widest, covering an aneas atnous and is crescent or kidney shaped, 50 km (3, and west by a range of smaller peaks, 
----
iter 33000, loss: 0.509623
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) an ar mountains, Pelineon (1,297 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), are situated in the no 
----
iter 34000, loss: 0.450951
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 the n east and west by a rant in ismand between east and wealing an area of 842.289 km2 (325.210 sq mi).[2] The 
----
iter 35000, loss: 0.409344
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long Epnd between east ann wedera n erange noud in the north of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) an 
----
iter 36000, loss: 0.376838
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to sten iransis divided between east and west by a range of smaller peaks, known as Prand rog an are titps ind is crescent or ki 
----
iter 37000, loss: 0.350307
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 38000, loss: 0.327764
----
 hios island is crescent or km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrawe erannis and west by a range of smaller  
----
iter 39000, loss: 0.308869
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering and west by a ranta o. The center of the island is divided between east and  
----
iter 40000, loss: 0.292480
----
 hios island is crescent or kidney shaped, Pelineon (1,297 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), are situated in the north of the island. The center of the islandnif divided between east and wes 
----
iter 41000, loss: 0.278175
----
 hios island is crescent or kid)ey d argese the length of the island. The center of the island is divided between east and west by . The center of the island is divided between east and wes brthe nnt p 
----
iter 42000, loss: 0.265652
----
 hios island is cred, with a ridge of mountains running the length of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), ane s9ithe is crescent 
----
iter 43000, loss: 0.254642
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain irand, 50 km (3, mou) 
----
iter 44000, loss: 0.245017
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 45000, loss: 0.236550
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325m210 sq mi).[2] The terrain is mountainous and ar 
----
iter 46000, loss: 0.228955
----
 hios island is crescent or kins widest, coveyi lergth of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), are situated in the north of the i 
----
iter 47000, loss: 0.221976
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 48000, loss: 0.215698
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 49000, loss: 0.209889
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 50000, loss: 0.204583
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 51000, loss: 0.199602
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 52000, loss: 0.194990
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 25 2. km (of terrain is mount, 84, 55 foundaind west by a range of smaller peaks, known as Prand re norranneer pea 
----
iter 53000, loss: 0.190968
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, alea tert, s lrngth of the ouscand is crescent or kidney shaped, 50 km (31 mi) long f 
----
iter 54000, loss: 0.186888
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (31 mi) long from north to south, and 29 km (18 mi) a 
----
iter 55000, loss: 0.183269
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, ay  peaks, known as Prand is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at i 
----
iter 56000, loss: 0.179754
----
 hios island is crescent or kidney shaped, 50 km (31.289 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, with a ridge of mountains running the length of the island. The center of the islan 
----
iter 57000, loss: 0.176605
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to torth of the island. The land between east an area of 842.289 km2 (325.210 sq mi).[8898 m (3,898 ft)), are siof thes of Pof t 
----
iter 58000, loss: 5.376437
----
 hios island is crest, covering the length of the island. The center of the island are situated in the south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The te 
----
iter 59000, loss: 2.290689
----
 hios island is crest, covering the length of the island. The two largest covided between east and west by a range of she ithe island are the norvm ind is atea oi asta) crescent or kidney shaped, 50 km 
----
iter 60000, loss: 1.053711
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from northes and arid, with a ridge of mountains, known as Pridge of mountains running the length of the island. The two largest of these m 
----
iter 61000, loss: 0.565654
----
 hios island is crescen ind The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) and Epos (3,898 ft)), are situated in the north of the island. The two largest of these mountains, Pelineon 
----
iter 62000, loss: 0.369324
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 63000, loss: 0.285917
----
 hios island is crescent or kidnere kituthe sland is divided between east and west by a range of smaller peaks, known as Prane islasd by a range of smaller peaks, known as Prand between east and west b 
----
iter 64000, loss: 0.247174
----
 hios island ind Ey ftea of 842.289 km2 (325.210 sq mi).[2] The tainous and arid, with a ridge of m2und ar mo) amd ast and west by a range of smaller peaks, known as Pridge of mountains running the len 
----
iter 65000, loss: 0.226341
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, coveritg shape the inout a ridge of mountains running the length of the island. The t 
----
iter 66000, loss: 0.213156
----
 hios island is crescent or kidney sh[88 ft)) and Epos (1,188 m (3,898 ft)), are situated in the north of the island. The center of the island is divided between east and west by a range of smaller pea 
----
iter 67000, loss: 0.203560
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 68000, loss: 0.195921
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] km2 (3,898 ft)), are situated in  
----
iter 69000, loss: 0.189520
----
 hios island is arede north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, with a ridge of mountains running the len 
----
iter 70000, loss: 0.183996
----
 hios island is crest, covering the leng from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, with a ridge of m 
----
iter 71000, loss: 0.179140
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 72000, loss: 0.174820
----
 hios island is crescent or kidney  runn areanof 842.289 km2 (325.210 sq mi).[2] The terrane the n eranney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an a 
----
iter 73000, loss: 0.170937
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an are s fithe island. The center of the island is divided between east and  
----
iter 74000, loss: 0.167423
----
 hios island r runnis cridse otrans running the length of the island. The two largese of mountains running the length of the island. The center of the island is divided between east and west by a range 
----
iter 75000, loss: 0.164220
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to torth of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), are sit 
----
iter 76000, loss: 0.161288
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at iss, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an areag a 
----
iter 77000, loss: 0.158590
----
 hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 78000, loss: 0.156101
----
 hios island is crescent or kidney shaped, 50 km (31 mi) langth of the island. The center of the island is divided between east and west by a range of smaller peaks, known as Pra ain in the north of th 
----
iter 79000, loss: 0.153797
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "pantelis/data-mining",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./aiml-common/lectures/nlp/language-models"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="_index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">RNN Language Models</p>
      </div>
    </a>
    <a class="right-next"
       href="cnn-language-model.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">CNN Language Model</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pantelis Monogioudis, Ph.D
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>