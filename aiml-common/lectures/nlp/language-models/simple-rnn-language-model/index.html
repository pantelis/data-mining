

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Simple RNN Language Model &#8212; Data Mining</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
    <script src="../../../../../_static/jquery.js"></script>
    <script src="../../../../../_static/underscore.js"></script>
    <script src="../../../../../_static/doctools.js"></script>
    <script src="../../../../../_static/clipboard.min.js"></script>
    <script src="../../../../../_static/copybutton.js"></script>
    <script src="../../../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'aiml-common/lectures/nlp/language-models/simple-rnn-language-model/index';</script>
    <link rel="canonical" href="https://pantelis.github.io/data-mining/aiml-common/lectures/nlp/language-models/simple-rnn-language-model/index.html" />
    <link rel="shortcut icon" href="../../../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
    <link rel="next" title="LSTM Language Model from scratch" href="../lstm-language-model/index.html" />
    <link rel="prev" title="CNN Language Model" href="../cnn-language-model/index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../../../intro.html">
                    Data Mining
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Syllabus</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../../syllabus/_index.html">Syllabus</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to Data Mining</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../ai-intro/course-introduction/_index.html">Course Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ai-intro/data-science-360/_index.html">Data Science 360</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../ai-intro/pipelines/_index.html">Pipelines</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../uber-ml-arch-case-study/_index.html">A Case Study of an ML Architecture - Uber</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../ai-intro/pipelines/02_end_to_end_machine_learning_project.html">Setup</a></li>







</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">The Learning Problem</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../learning-problem/_index.html">The Learning Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../regression/linear-regression/linear_regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../regression/linear-regression/regression-notebooks.html">Regression Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optimization/maximum-likelihood/marginal_maximum_likelihood.html">Maximum Likelihood Estimation of a marginal model</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../optimization/maximum-likelihood/conditional_maximum_likelihood.html">Maximum Likelihood (ML) Estimation of conditional models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../entropy/_index.html">Entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optimization/sgd/_index.html">Stochastic Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../classification/classification-intro/_index.html">Introduction to Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../classification/logistic-regression/_index.html">Logistic Regression</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../classification/perceptron/_index.html">The Neuron (Perceptron)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dnn/dnn-intro/_index.html">Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dnn/backprop-intro/_index.html">Introduction to Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dnn/backprop-dnn/_index.html">Backpropagation in Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dnn/backprop-dnn-exercises/_index.html">Backpropagation DNN exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dnn/fashion-mnist-case-study.html">Fashion MNIST Case Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optimization/regularization/_index.html">Regularization in Deep Neural Networks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Convolutional Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../cnn/cnn-intro/_index.html">Introduction to Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cnn/cnn-layers/_index.html">CNN Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cnn/cnn-example-architectures/_index.html">CNN Example Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">Using convnets with small datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../scene-understanding/feature-extraction-resnet/index.html">Feature Extraction via Residual Networks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Transfer Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../transfer-learning/transfer-learning-introduction.html">Introduction to Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../transfer-learning/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Scene Understanding</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../scene-understanding/scene-understanding-intro/index.html">Introduction to Scene Understanding</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../scene-understanding/object-detection/object-detection-intro/index.html">Object Detection</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../scene-understanding/object-detection/detection-metrics/index.html">Object Detection and Semantic Segmentation Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scene-understanding/object-detection/rcnn-object-detection/index.html">Region-CNN (RCNN) Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scene-understanding/object-detection/faster-rcnn-object-detection/index.html">Fast and Faster RCNN Object Detection</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Sequences and RNNs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../rnn/introduction/_index.html">Introduction to Recurrent Neural Networks (RNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rnn/simple-rnn/_index.html">Simple RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rnn/lstm/_index.html">The Long Short-Term Memory (LSTM) Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rnn/time_series_using_simple_rnn_lstm.html">Time Series Prediction using RNNs</a></li>





</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Natural Language Processing</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../_index.html">Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlp-introduction/nlp-pipelines/_index.html">Introduction to NLP Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlp-introduction/tokenization/index.html">Tokenization</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp-introduction/word2vec/_index.html">Embeddings</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nlp-introduction/word2vec/word2vec_from_scratch.html">Word2Vec from scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp-introduction/word2vec/word2vec_tensorflow_tutorial.html">Word2Vec Tensorflow Tutorial</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../_index.html">Language Models</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../cnn-language-model/index.html">CNN Language Model</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Simple RNN Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lstm-language-model/index.html">LSTM Language Model from scratch</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nmt/nmt-intro/index.html">Neural Machine Translation</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nmt/nmt-metrics/index.html">NMT Metrics  - BLEU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nmt/lstm_seq2seq.html">Character-level recurrent sequence-to-sequence model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../nmt/rnn-nmt-attention/index.html">Attention in RNN-based NMT</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../transformers/transformers-intro.html">Transformers</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../transformers/annotated_transformer.html">The Annotated Transformer</a></li>











</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Structured Data Methods</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../decision-trees/_index.html">Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../regression-trees/regression_trees.html">Regression tree stumps</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../ensemble/_index.html">Ensemble Methods </a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ensemble/random-forests/_index.html">Random Forests</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ensemble/adaboost/index.html">Adaptive Boosting (AdaBoost)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ensemble/gradient-boosting/index.html">Gradient Boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ensemble/boosting-workshop/_index.html">Boosting workshop</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Non-Parametric Methods</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../unsupervised/k-means/_index.html">K-means Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../density-estimation/knn/_index.html">k-Nearest Neighbors (kNN) Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../density-estimation/knn-workshop/_index.html">kNN Workshop</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Dimensionality Reduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../pca/_index.html">Principal Component Analysis (PCA)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Math Background</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../ml-math/index.html">Math for ML Textbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ml-math/probability/index.html">Probability Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ml-math/linear-algebra/index.html">Linear Algebra for Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ml-math/calculus/index.html">Calculus</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../resources/environment/index.html">Your Programming Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../resources/environment/assignment-submission.html">Submitting Your Assignment / Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python/index.html">Learn Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../resources/environment/notebook-status.html">Notebook execution status</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../assignments/probability/probability-assignment-5/index.html">Probability Assignment</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../../assignments/mle/poisson-regression-1/index.html">Bike Rides and the Poisson Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../assignments/cnn-face-similarity/index.html">CNN Featurizers and Similarity Search</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project (CS482)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../projects/nlp/finetuning-language-models-tweets/index.html">Finetuning Language Models - Toxic Tweets</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project (CS634)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../projects/nlp/finetuning-language-models-patents/index.html">Finetuning Language Models - Can I Patent This?</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/pantelis/data-mining/master?urlpath=tree/data_mining/aiml-common/lectures/nlp/language-models/simple-rnn-language-model/index.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/pantelis/data-mining/blob/master/data_mining/aiml-common/lectures/nlp/language-models/simple-rnn-language-model/index.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pantelis/data-mining" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pantelis/data-mining/edit/master/data_mining/aiml-common/lectures/nlp/language-models/simple-rnn-language-model/index.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pantelis/data-mining/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/nlp/language-models/simple-rnn-language-model/index.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../../_sources/aiml-common/lectures/nlp/language-models/simple-rnn-language-model/index.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Simple RNN Language Model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><a class="reference external" href="https://colab.research.google.com/github/pantelis-nlp/tutorial-nlp-notebooks/blob/main/rnn_language_model.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="simple-rnn-language-model">
<h1>Simple RNN Language Model<a class="headerlink" href="#simple-rnn-language-model" title="Permalink to this headline">#</a></h1>
<p>Our aim is to predict the next character given a set of previous characters from our data string. For our RNN  implementation, we would take a sequence of length 25 characters as inputs to predict the next character.</p>
<p>The notation used here was introduced first <a class="reference external" href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture10.pdf">here</a>. This minimal character-level Vanilla RNN model was first written by Andrej Karpathy (&#64;karpathy) and was decorated with the forward and backprop equations by students of the CS-GY-6613 course as part of an asignment.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="s1">&#39;Chiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, with a ridge of mountains running the length of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), are situated in the north of the island. The center of the island is divided between east and west by a range of smaller peaks, known as Provatas.&#39;</span>
<span class="c1"># data I/O</span>
<span class="c1"># data = open(&#39;input.txt&#39;, &#39;r&#39;).read() # should be simple plain text file - you can use any (small) file in txt format from the web or type your own. </span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># creating a vocabulary of unique characters</span>
<span class="n">chars</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>                                                   
<span class="n">data_size</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;data has </span><span class="si">%d</span><span class="s1"> characters, </span><span class="si">%d</span><span class="s1"> unique.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">data_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>data has 508 characters, 43 unique.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data pre-processing</span>
<span class="c1"># creating a dictionary, mapping characters to index and index to characters</span>
<span class="n">char_to_ix</span> <span class="o">=</span> <span class="p">{</span> <span class="n">ch</span><span class="p">:</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span> <span class="p">}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">char_to_ix</span><span class="p">)</span>
<span class="n">ix_to_char</span> <span class="o">=</span> <span class="p">{</span> <span class="n">i</span><span class="p">:</span><span class="n">ch</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span> <span class="p">}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ix_to_char</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;4&#39;: 0, &#39;m&#39;: 1, &#39;l&#39;: 2, &#39;y&#39;: 3, &#39;,&#39;: 4, &#39;w&#39;: 5, &#39;r&#39;: 6, &#39;8&#39;: 7, &#39;.&#39;: 8, &#39;g&#39;: 9, &#39;o&#39;: 10, &#39;d&#39;: 11, &#39;]&#39;: 12, &#39;1&#39;: 13, &#39;P&#39;: 14, &#39;n&#39;: 15, &#39;(&#39;: 16, &#39;a&#39;: 17, &#39;0&#39;: 18, &#39;2&#39;: 19, &#39;f&#39;: 20, &#39;7&#39;: 21, &#39;9&#39;: 22, &#39;p&#39;: 23, &#39; &#39;: 24, &#39;e&#39;: 25, &#39;C&#39;: 26, &#39;c&#39;: 27, &#39;)&#39;: 28, &#39;[&#39;: 29, &#39;s&#39;: 30, &#39;T&#39;: 31, &#39;q&#39;: 32, &#39;h&#39;: 33, &#39;i&#39;: 34, &#39;3&#39;: 35, &#39;E&#39;: 36, &#39;5&#39;: 37, &#39;b&#39;: 38, &#39;u&#39;: 39, &#39;v&#39;: 40, &#39;k&#39;: 41, &#39;t&#39;: 42}
{0: &#39;4&#39;, 1: &#39;m&#39;, 2: &#39;l&#39;, 3: &#39;y&#39;, 4: &#39;,&#39;, 5: &#39;w&#39;, 6: &#39;r&#39;, 7: &#39;8&#39;, 8: &#39;.&#39;, 9: &#39;g&#39;, 10: &#39;o&#39;, 11: &#39;d&#39;, 12: &#39;]&#39;, 13: &#39;1&#39;, 14: &#39;P&#39;, 15: &#39;n&#39;, 16: &#39;(&#39;, 17: &#39;a&#39;, 18: &#39;0&#39;, 19: &#39;2&#39;, 20: &#39;f&#39;, 21: &#39;7&#39;, 22: &#39;9&#39;, 23: &#39;p&#39;, 24: &#39; &#39;, 25: &#39;e&#39;, 26: &#39;C&#39;, 27: &#39;c&#39;, 28: &#39;)&#39;, 29: &#39;[&#39;, 30: &#39;s&#39;, 31: &#39;T&#39;, 32: &#39;q&#39;, 33: &#39;h&#39;, 34: &#39;i&#39;, 35: &#39;3&#39;, 36: &#39;E&#39;, 37: &#39;5&#39;, 38: &#39;b&#39;, 39: &#39;u&#39;, 40: &#39;v&#39;, 41: &#39;k&#39;, 42: &#39;t&#39;}
</pre></div>
</div>
</div>
</div>
<a class="reference internal image-reference" href="https://drive.google.com/uc?id=12ha59vACcd8eCEPAQdbZ4-axPGPKnn7F"><img alt="https://drive.google.com/uc?id=12ha59vACcd8eCEPAQdbZ4-axPGPKnn7F" src="https://drive.google.com/uc?id=12ha59vACcd8eCEPAQdbZ4-axPGPKnn7F" style="width: 700px;" /></a>
<p><strong>Inputs to RNN</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_1\)</span> to <span class="math notranslate nohighlight">\(x_{25}\)</span> is the input sequence of 25 characters, one character given as input to RNN at each time step</p></li>
</ul>
<p><strong>Hidden state of RNN</strong></p>
<ul class="simple">
<li><p>The state consists of a single ‘hidden’ vector h</p></li>
<li><p>At every time step, a recurrence function <span class="math notranslate nohighlight">\(f_W\)</span> with parameters <span class="math notranslate nohighlight">\(W_{xh}\)</span>, <span class="math notranslate nohighlight">\(W_{hh}\)</span> and <span class="math notranslate nohighlight">\(b_h\)</span> is applied to the input <span class="math notranslate nohighlight">\(x_t\)</span> and the output from the previous hidden state <span class="math notranslate nohighlight">\(h_{t-1}\)</span>, to generate <span class="math notranslate nohighlight">\(h_t\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad h_t = f_W (h_{t-1},x_t)\)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \; \; \; \; = \tanh (W_{hh}h_{t-1} + W_{xh}x_t + b_h)\)</span></p>
<p><strong>Outputs of the RNN</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat y_T\)</span> is the character that our network would predict after <span class="math notranslate nohighlight">\(T=25\)</span> time steps</p></li>
<li><p>At each time step, a <span class="math notranslate nohighlight">\(o_t\)</span> is calculated as</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad o_t = W_{hy}h_t + b_y\)</span></p>
<ul class="simple">
<li><p>The softmax of <span class="math notranslate nohighlight">\(o_t\)</span> is the set of probabilities of occurance of each unique character in the input data</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \hat y_t  = \mathtt{softmax}(o_t)\)</span></p>
<ul class="simple">
<li><p>At each time step, from <span class="math notranslate nohighlight">\(t=1\)</span> to <span class="math notranslate nohighlight">\(25\)</span>, loss is calculated from the set of predicted probabilities.</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad L_t = \mathtt{CE}(\hat y_t, y_t)\)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> where the <span class="math notranslate nohighlight">\(y_t\)</span> is the next character to the input sequence in the data string</p>
<ul class="simple">
<li><p>The total loss is the sum of all the losses from the previously unrolled steps</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad L = ∑_{t=0}^{24}L_t\)</span></p>
<p>All the weights <span class="math notranslate nohighlight">\(W_{xh}\)</span>, <span class="math notranslate nohighlight">\(W_{hh}\)</span>, <span class="math notranslate nohighlight">\(b_h\)</span>, <span class="math notranslate nohighlight">\(W_{hy}\)</span> and <span class="math notranslate nohighlight">\(b_y\)</span> are reused at each time step.</p>
<p><strong>Hyperparameters</strong></p>
<ul class="simple">
<li><p>the size of hidden state of neurons</p></li>
<li><p>the sequence length or the time steps to unroll, which is 25 in our case</p></li>
<li><p>optimizer we use here is Adagrad</p></li>
<li><p>the learning rate for Adagrad optimizer</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># hyperparameters</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">100</span>           <span class="c1"># size of hidden state (number of RNN simple neurons)</span>
<span class="n">seq_length</span> <span class="o">=</span> <span class="mi">25</span>               <span class="c1"># number of time steps to unroll the RNN for, taking 25 previous characters to predict the next</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-1</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Dimensions of tensors</strong></p>
<p>Input:</p>
<ul class="simple">
<li><p>Each character from the data string is pre-processed before being fed then into the RNN</p></li>
<li><p>From each sequence of 25 characters (for 25 time-steps) from the data string, we create an ‘inputs’ list of tokenized integer values</p></li>
<li><p>Each character is converted to an integer token index using ‘char_to_ix’ function, which maps each character to a number between 0 and 42 (as there are 43 unique characters in our data)</p></li>
<li><p>The integer tokens from the ‘inputs’ list are then one-hot encoded in 1-of-k representations, ie, into vectors of size 43 (k=43 unique characters in our data), which are fed as inputs to the RNN</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of input <span class="math notranslate nohighlight">\(x_t =\)</span> (43,1)</p>
<p>Targets (<span class="math notranslate nohighlight">\(y_t\)</span>):</p>
<ul class="simple">
<li><p>For each input in the ‘inputs’ list, we create a ‘target’ list consisting of the subsequent character’s integer token</p></li>
<li><p>Our targets list, which is used during the cross-entropy loss calculation, is of length 25</p></li>
</ul>
<p>Predicted output:</p>
<ul class="simple">
<li><p>The predicted outputs are the probabilities of the next characters</p></li>
<li><p>Since k=43 unique characters, the unnormalized logits for next chars is</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of output <span class="math notranslate nohighlight">\(o_t =\)</span> (43,1)</p>
<ul class="simple">
<li><p>The <span class="math notranslate nohighlight">\(softmax(o_t)\)</span> gives the class probabilities for next characters</p></li>
<li><p>The probabilities are then converted into one-hot encoded vectors using <span class="math notranslate nohighlight">\(\argmax\)</span></p></li>
<li><p>The one-hot encoded vectors are converted into integer tokens and then to a single character using ‘ix_to_char’ function</p></li>
</ul>
<p>Hidden layers:</p>
<ul class="simple">
<li><p>Since we have chosen 100 neurons in the hidden layer,</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of hidden state <span class="math notranslate nohighlight">\(h_t =\)</span> (100,1)</p>
<p>Model parameters:</p>
<ul class="simple">
<li><p>Given the hidden_size=100,  input x dimension=(43,1) and output y dimension=(43,1):</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of <span class="math notranslate nohighlight">\(W_{xh} =\)</span> (100,43),</p>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of <span class="math notranslate nohighlight">\(W_{hh} =\)</span> (100,100),</p>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of <span class="math notranslate nohighlight">\(b_{h} =\)</span> (100,1),</p>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of <span class="math notranslate nohighlight">\(W_{hy} =\)</span> (43,100),</p>
<p><span class="math notranslate nohighlight">\( \qquad \)</span> =&gt; dimension of <span class="math notranslate nohighlight">\(b_{y} =\)</span> (43,1)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># model parameters</span>
<span class="c1"># we set the initial values of the weights randomly from a normal distribution and set all the bias to zero</span>

<span class="n">Wxh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>   <span class="c1"># input to hidden, shape = (hidden_size, vocab_size) = (100,43)</span>
<span class="n">Whh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>  <span class="c1"># hidden to hidden, shape = (hidden_size, hidden_size) = (100,100)</span>
<span class="n">Why</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>   <span class="c1"># hidden to output, shape = (vocab_size, hidden_size) = (43,100)</span>
<span class="n">bh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>       <span class="c1"># hidden bias, shape  = (hidden_size, 1) = (100,1)</span>
<span class="n">by</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>         <span class="c1"># output bias, shape  = (vocab_size, 1) = (43,1)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Forward Pass</strong></p>
<ul class="simple">
<li><p>Forward through entire sequence <span class="math notranslate nohighlight">\(x_1\)</span> to <span class="math notranslate nohighlight">\(x_{25}\)</span> to compute loss</p></li>
<li><p>Calculate hidden states at each time step</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad h_t = tanh (W_{hh}h_{t-1} + W_{xh}x_t + b_h)\)</span></p>
<ul class="simple">
<li><p>Calculate output <span class="math notranslate nohighlight">\(y_t\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad o_t = W_{hy}h_t + b_y\)</span></p>
<ul class="simple">
<li><p>The softmax of <span class="math notranslate nohighlight">\(o_t\)</span> is the set of probabilities of occurance of each unique character in the input data</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \hat y_t = softmax(o_t)\)</span></p>
<ul class="simple">
<li><p>Calculate loss at each time step</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad L_t = Cross\;Entropy(\hat y_t, y_t)\)</span></p>
<ul class="simple">
<li><p>Calculate the total loss, which is the negative log likelihood of our model</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad L = ∑_{t=0}^{24}L_t\)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \; \; \; \; = - ∑_t log \; p_{model} (y_t | x_1,...,x_t)\)</span></p>
<p><strong>Backpropogation Through Time</strong></p>
<ul class="simple">
<li><p>Backward through entire sequence to compute gradient</p></li>
<li><p>The nodes include parameters <span class="math notranslate nohighlight">\(W_{xh}\)</span>, <span class="math notranslate nohighlight">\(W_{hh}\)</span>, <span class="math notranslate nohighlight">\(b_h\)</span>, <span class="math notranslate nohighlight">\(W_{hy}\)</span> and <span class="math notranslate nohighlight">\(b_y\)</span></p></li>
<li><p>The inputs and outputs of nodes are <span class="math notranslate nohighlight">\(x_t\)</span>, <span class="math notranslate nohighlight">\(h_t\)</span>, <span class="math notranslate nohighlight">\(y_t\)</span>, <span class="math notranslate nohighlight">\(p_t\)</span> and <span class="math notranslate nohighlight">\(L_t\)</span> at time-step <span class="math notranslate nohighlight">\(t\)</span></p></li>
<li><p>We’ll use the suffix <span class="math notranslate nohighlight">\((i)\)</span> to indicate the <span class="math notranslate nohighlight">\(i^{th}\)</span> sample</p></li>
</ul>
<p><em>Gradients on the internal nodes:</em></p>
<ul class="simple">
<li><p>We’ll be computing the gradients recursively starting with the nodes immediately preceding the final loss</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial L_t}  = 1 \)</span></p>
<ul class="simple">
<li><p>The gradient with respect to the softmax layer would be:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial y_{(i)t}}  = p_{(i)t} -1 \)</span></p>
<ul class="simple">
<li><p>At t=25, the gradient with respect to the hidden layer would be:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial h_{t=25}}  = {W_{hy}}^T \frac{\partial L}{\partial y_{t=25}} \)</span></p>
<ul class="simple">
<li><p>We can now iterate backwards from t=24 down to t=1:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial h_{t}}  =  \bigg(\frac{\partial h_{t+1}}{\partial h_{t}}\bigg)^T \frac{\partial L}{\partial h_{t+1}} + \bigg(\frac{\partial y_{t}}{\partial h_{t}}\bigg)^T \frac{\partial L}{\partial y_{t}}  \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \qquad = (W_{hh})^T \; diag\bigg(1-(h_{t+1})^2\bigg) \frac{\partial L}{\partial h_{t+1}}  + (W_{hy})^T \frac{\partial L}{\partial y_{t}} \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \)</span> where <span class="math notranslate nohighlight">\(diag\bigg(1-(h_{t+1})^2\bigg)\)</span> indicates the diagonal matrix containing the elements <span class="math notranslate nohighlight">\(1-(h_{(i)t+1})^2\)</span></p>
<p><em>Gradients on the parameter nodes:</em></p>
<ul class="simple">
<li><p>Gradients with respect to <span class="math notranslate nohighlight">\(W_{hy}\)</span>:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial W_{hy}} = \sum_t  \sum_i \frac{\partial L}{\partial y_{(i)t}} \frac{\partial y_{(i)t}}{\partial W_{hy}} \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad  \qquad = \sum_t  \frac{\partial L}{\partial y_t} (h_t)^T\)</span></p>
<ul class="simple">
<li><p>Gradients with respect to <span class="math notranslate nohighlight">\(b_y\)</span>:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial b_{y}} = \sum_t \bigg(\frac{\partial y_t}{\partial b_{y}}\bigg)^T \frac{\partial L}{\partial y_{t}} \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad  \qquad = \sum_t \frac{\partial L}{\partial y_{t}} \)</span></p>
<ul class="simple">
<li><p>Gradients with respect to <span class="math notranslate nohighlight">\(W_{hh}\)</span>:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial W_{hh}} = \sum_t  \sum_i \frac{\partial L}{\partial h_{(i)t}} \frac{\partial h_{(i)t}}{\partial W_{hh}} \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad  \qquad = \sum_t diag\bigg(1-(h_{t})^2\bigg)  \frac{\partial L}{\partial h_t} (h_{t-1})^T\)</span></p>
<ul class="simple">
<li><p>Gradients with respect to <span class="math notranslate nohighlight">\(b_h\)</span>:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial b_{h}} = \sum_t \bigg(\frac{\partial h_t}{\partial b_{h}}\bigg)^T \frac{\partial L}{\partial h_{t}} \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad  \qquad = \sum_t diag\bigg(1-(h_{t})^2\bigg)  \frac{\partial L}{\partial h_{t}} \)</span></p>
<ul class="simple">
<li><p>Gradients with respect to <span class="math notranslate nohighlight">\(W_{xh}\)</span>:</p></li>
</ul>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad \frac{\partial L}{\partial W_{xh}} = \sum_t  \sum_i \frac{\partial L}{\partial h_{(i)t}} \frac{\partial h_{(i)t}}{\partial W_{xh}} \)</span></p>
<p><span class="math notranslate nohighlight">\( \qquad \qquad \qquad \qquad  \qquad = \sum_t diag\bigg(1-(h_{t})^2\bigg)  \frac{\partial L}{\partial h_t} (x_t)^T\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">lossFun</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">hprev</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  inputs,targets are both list of integers.</span>
<span class="sd">  hprev is Hx1 array of initial hidden state</span>
<span class="sd">  perform forward and backward pass</span>
<span class="sd">  returns the loss, gradients on model parameters, and last hidden state</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="n">xs</span><span class="p">,</span> <span class="n">hs</span><span class="p">,</span> <span class="n">os</span><span class="p">,</span> <span class="n">ps</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{},</span> <span class="p">{},</span> <span class="p">{}</span>
  <span class="n">hs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">hprev</span><span class="p">)</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="c1"># forward pass: compute loss going forward</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>                                         <span class="c1"># looping for t timesteps, which is the size of the length of inputs</span>
    <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>                                   <span class="c1"># xs = one-hot encode in 1-of-k representation</span>
    <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="n">inputs</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Wxh</span><span class="p">,</span> <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Whh</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="n">bh</span><span class="p">)</span>    <span class="c1"># hs_t = tanh(W_hh.hs_t-1 + W_xh.xs_t + b_h) -&gt; hidden state</span>
    <span class="n">os</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Why</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">+</span> <span class="n">by</span>                                    <span class="c1"># os = W_hy.hs_t + b_y -&gt; unnormalized log probabilities for next chars</span>
    <span class="n">ps</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">os</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">os</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span>                      <span class="c1"># ps = softmax(os) -&gt; probabilities for next chars</span>
    <span class="n">loss</span> <span class="o">+=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ps</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="n">targets</span><span class="p">[</span><span class="n">t</span><span class="p">],</span><span class="mi">0</span><span class="p">])</span>                               <span class="c1"># cross-entropy loss</span>

  <span class="c1"># backward pass: compute gradients going backwards</span>
  <span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Wxh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Whh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Why</span><span class="p">)</span>      <span class="c1"># create numpy arrays for right size for the weights</span>
  <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">bh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">by</span><span class="p">)</span>                                    <span class="c1"># create numpy arrays for right size for the biasses</span>
  <span class="n">dhnext</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">hs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>                                                      <span class="c1"># h_{t-1} for the first iteration is set to all zeros</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))):</span>
    <span class="n">dy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">ps</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>
    <span class="n">dy</span><span class="p">[</span><span class="n">targets</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">-=</span> <span class="mi">1</span>                      <span class="c1"># backprop into y by taking gradient for softmax (http://cs231n.github.io/neural-networks-case-study/#grad)</span>
    <span class="n">dWhy</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>              <span class="c1"># gradient for Why</span>
    <span class="n">dby</span> <span class="o">+=</span> <span class="n">dy</span>                                <span class="c1"># gradient for by</span>
    <span class="n">dh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Why</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dy</span><span class="p">)</span> <span class="o">+</span> <span class="n">dhnext</span>          <span class="c1"># backprop into h</span>
    <span class="n">dhraw</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">*</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">*</span> <span class="n">dh</span>         <span class="c1"># backprop through tanh nonlinearity</span>
    <span class="n">dbh</span> <span class="o">+=</span> <span class="n">dhraw</span>                             <span class="c1"># gradient for bh</span>
    <span class="n">dWxh</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dhraw</span><span class="p">,</span> <span class="n">xs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>           <span class="c1"># gradient for Wxh</span>
    <span class="n">dWhh</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dhraw</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>         <span class="c1"># gradient for Whh</span>
    <span class="n">dhnext</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Whh</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dhraw</span><span class="p">)</span>            <span class="c1"># calculate h_t-1 for the next iteration</span>
  <span class="k">for</span> <span class="n">dparam</span> <span class="ow">in</span> <span class="p">[</span><span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span><span class="p">,</span> <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span><span class="p">]:</span>
    <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">dparam</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">dparam</span><span class="p">)</span>                              <span class="c1"># clip gradients to mitigate exploding gradients</span>
  <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span><span class="p">,</span> <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span><span class="p">,</span> <span class="n">hs</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">seed_ix</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot; </span>
<span class="sd">  sample a sequence of integers from the model </span>
<span class="sd">  h is memory state, seed_ix is seed letter for first time step</span>
<span class="sd">  predicts probabilities for each character </span>
<span class="sd">  returns the set of predicted indices with the highest probabilities</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># at test-time sample characters one at a time, feed back to model for next character prediction</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
  <span class="n">x</span><span class="p">[</span><span class="n">seed_ix</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>                                              <span class="c1"># x = one-hot encode the input for seed_ix letter in 1-of-k representation</span>
  <span class="n">ixes</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="c1"># predicting the next character</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Wxh</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Whh</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="n">bh</span><span class="p">)</span>         <span class="c1"># h_t = tanh(W_hh.h_t-1 + W_xh.x_t + b_h) -&gt; hidden state                    </span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Why</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="n">by</span>                                   <span class="c1"># y = W_hy.h_t + b_y -&gt; unnormalized log probabilities for next chars</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>                         <span class="c1"># p = softmax(y) -&gt; probabilities for next chars</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>     <span class="c1"># p.ravel gives the probabilities of each entry, with the maximum ix at argmax</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  
    <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>                                                 <span class="c1"># convert probabilities to one-hot encoded vectors in 1-of-k representation</span>
    <span class="n">ixes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ix</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">ixes</span>                                                 <span class="c1"># return all the indices to convert them into characters and print the predictions</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># p-data pointer, n-iteration counter</span>
<span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>                        <span class="c1"># setting both to zero in the beginning</span>

<span class="c1"># memory variables for Adagrad, initialized to all zeros</span>
<span class="n">mWxh</span><span class="p">,</span> <span class="n">mWhh</span><span class="p">,</span> <span class="n">mWhy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Wxh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Whh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">Why</span><span class="p">)</span>    
<span class="n">mbh</span><span class="p">,</span> <span class="n">mby</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">bh</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">by</span><span class="p">)</span> 

<span class="c1"># loss at time instance 0</span>
<span class="n">smooth_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="n">vocab_size</span><span class="p">)</span><span class="o">*</span><span class="n">seq_length</span> 

<span class="c1"># while True:</span>
<span class="c1"># running for 80000 epochs</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">80000</span><span class="p">):</span>

  <span class="c1"># Data pre-processing to prepare inputs and targets</span>
  <span class="k">if</span> <span class="n">p</span><span class="o">+</span><span class="n">seq_length</span><span class="o">+</span><span class="mi">1</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="ow">or</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>                        <span class="c1"># sweeping from left to right in steps seq_length=25 long</span>
    <span class="n">hprev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">hidden_size</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>                              <span class="c1"># reset RNN memory</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span>                                                          <span class="c1"># go from start of data</span>
  <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">char_to_ix</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="n">p</span><span class="p">:</span><span class="n">p</span><span class="o">+</span><span class="n">seq_length</span><span class="p">]]</span>         <span class="c1"># inputs are tokens each of length seq_length=25</span>
  <span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">char_to_ix</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="n">p</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">p</span><span class="o">+</span><span class="n">seq_length</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span>    <span class="c1"># targets are the tokens of the subsequent characters for each input sequence</span>

  <span class="c1"># Model testing</span>
  <span class="k">if</span> <span class="n">n</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">sample_ix</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">hprev</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">200</span><span class="p">)</span>                   <span class="c1"># sample from the model and predict characters every 1000 iterations</span>
    <span class="n">txt</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ix_to_char</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="k">for</span> <span class="n">ix</span> <span class="ow">in</span> <span class="n">sample_ix</span><span class="p">)</span>           <span class="c1"># convert tokens into characters and add it to the list of previous predictions</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;----</span><span class="se">\n</span><span class="s1"> </span><span class="si">%s</span><span class="s1"> </span><span class="se">\n</span><span class="s1">----&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">txt</span><span class="p">,</span> <span class="p">))</span>                         <span class="c1"># print model predictions</span>

  <span class="c1"># Model training</span>
  <span class="n">loss</span><span class="p">,</span> <span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span><span class="p">,</span> <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span><span class="p">,</span> <span class="n">hprev</span> <span class="o">=</span> <span class="n">lossFun</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">hprev</span><span class="p">)</span>   <span class="c1"># forward seq_length characters through the net and fetch gradient</span>
  <span class="n">smooth_loss</span> <span class="o">=</span> <span class="n">smooth_loss</span> <span class="o">*</span> <span class="mf">0.999</span> <span class="o">+</span> <span class="n">loss</span> <span class="o">*</span> <span class="mf">0.001</span>                            <span class="c1"># RNN adds all the losses from the previously unrolled steps</span>
  <span class="k">if</span> <span class="n">n</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;iter </span><span class="si">%d</span><span class="s1">, loss: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">smooth_loss</span><span class="p">))</span>             <span class="c1"># print progress</span>
  
  <span class="c1"># parameter update with Adagrad</span>
  <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">dparam</span><span class="p">,</span> <span class="n">mem</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">Wxh</span><span class="p">,</span> <span class="n">Whh</span><span class="p">,</span> <span class="n">Why</span><span class="p">,</span> <span class="n">bh</span><span class="p">,</span> <span class="n">by</span><span class="p">],</span> 
                                <span class="p">[</span><span class="n">dWxh</span><span class="p">,</span> <span class="n">dWhh</span><span class="p">,</span> <span class="n">dWhy</span><span class="p">,</span> <span class="n">dbh</span><span class="p">,</span> <span class="n">dby</span><span class="p">],</span> 
                                <span class="p">[</span><span class="n">mWxh</span><span class="p">,</span> <span class="n">mWhh</span><span class="p">,</span> <span class="n">mWhy</span><span class="p">,</span> <span class="n">mbh</span><span class="p">,</span> <span class="n">mby</span><span class="p">]):</span>
    <span class="n">mem</span> <span class="o">+=</span> <span class="n">dparam</span> <span class="o">*</span> <span class="n">dparam</span>
    <span class="n">param</span> <span class="o">+=</span> <span class="o">-</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dparam</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mem</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>              <span class="c1"># adagrad parameter update</span>

  <span class="n">p</span> <span class="o">+=</span> <span class="n">seq_length</span>                                                       <span class="c1"># move data pointer</span>
  <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>                                                                <span class="c1"># iteration counter </span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>----
 hiys island. The center of the islandt to south, and 29 km (18 mi) at covering an area of 842.289 km2)wid and  roun is mountainor ridn250 north to south, and 29 km (18 mi) at arrarrer of the island. T 
----
iter 0, loss: 93.937900
----
 hiys m ft)), um898 ite kiot th fi) kmorrori),18 vi210 of (3t)d veripesd Pr (1,284 5owslang ri(shestheeslasge ma,d shee th theain cor ited ineast is m (3,255 fped Pr oo th of shevislahd, isP twe pea ba 
----
iter 1000, loss: 57.382420
----
 hiys ) (18m wo) two lari) co ofrthg (8, (5.289 kaslant is dwest Th cen of the isease f )) anthg 59 known as Pr cov afv f a range of smalles and th,d. The celand. The isnain the 10 no kiring an atd wes 
----
iter 2000, loss: 26.734174
----
 hiys island is kithe north of the island. The two large peaks, known ast anta bednt Pr co The two largest of thed ar mouth, and 29 km (18 mi) at ilonges (1, kmome isuntung a ohe is atea sq m0 Pesn wid 
----
iter 3000, loss: 12.473084
----
 hiys island arginnrain of the island is din is we peand mountainant a Epos (1,188 m (3,898 ft)), are sitves Pelineos (1,188 m (3,898 ft)), are situated in the north of the island0 Pelineang an area of 
----
iter 4000, loss: 6.580357
----
 hiys island sh of the island. The center ountains running the length of the cr thesw are the terrind west by a range of smaller peaks, known as Pr kid.[2] The terrain situated in, wnd Eiscoves a2898 f 
----
iter 5000, loss: 3.257143
----
 hiys island is ast isn aitlandise nt insand 29 norid, 5erterri south, and verei)eco between east and west by a of the island. The minteano rped ant the length of the island. The center of the island i 
----
iter 6000, loss: 1.823397
----
 hiys island is crescent or kidney shaped, 50 km (3,898 ft)), are situated in the north of the island. The twe id, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an a 
----
iter 7000, loss: 1.167439
----
 hiys island is cresces wi langth of the island. The center of the islan between east and west bela range of smaller peaks, known as Pr kreeiy d or (1,297 m (4,255 ft)) ast the length of the island. Th 
----
iter 8000, loss: 3.007568
----
 hiyn i5, known as Pr kme)ta m (3,898 ft)), are situated in, is crescent or kidney shaped, 50 km (31 mi) longes (1,188 m (3,255 ft)) and Epos (1,188 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), are sit 
----
iter 9000, loss: 1.598038
----
 hiys island is crescent or kidney shaped, 50 km (31 mountains running the length of the island. The center aidest, cre por (1,188 m (3,898 ft)), are situated in the north of the island. The center of  
----
iter 10000, loss: 0.966774
----
 hiyst and,d and Eit er situated in the north of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), are situated in the north of the island. Th 
----
iter 11000, loss: 0.730126
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north norran are situated in the north of the island. The center ountains running the length of the island. The center of the island i 
----
iter 12000, loss: 0.554884
----
 hiyst and Epos (1,1(1 m (3,898 ft)), are situated in the north of the island. The center of the island is divided between east and west by a range of smaller peaks, known as Prid, with a ridge of moun 
----
iter 13000, loss: 0.456565
----
 hiys island is crescest or kidner th covering an area of 842.289 km2 (325.210 sq 8425 29 Ped arees (1,188 m (3,8me)d ountainous and arid, with a ridge of mountaiksq mouth of the island. The two larges 
----
iter 14000, loss: 0.397573
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The tount(ountain is mountainous  
----
iter 15000, loss: 0.358886
----
 hiys island is crescent or kidney shaped, 50 km (3f mountains running the length of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) and Eh f om (31 mi)dlong from north to 
----
iter 16000, loss: 0.331059
----
 hiys island is crescent o4 cekscents mountains, Pelineon (1,297 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), are situated in the north of the island. The center of the island is divided between east a 
----
iter 17000, loss: 0.309466
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north The island. The center of the island is divided between east and west by a range of smaller peaks, known as Pr kne from north to 
----
iter 18000, loss: 0.292409
----
 hiys island is crescent of 842.889 km2 (325.210 sq mi).[2] The terrain is mountaithe redge sount its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, wi 
----
iter 19000, loss: 0.277755
----
 hiys island is crescent or kidney shang anosg an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, with a ridge of mountains running the length of the island. The two larges 
----
iter 20000, loss: 0.264833
----
 hiys island sh of th  ries (1,188 m (3,898 ft)), are situated in the north of the island. The center of the island is divided between east and west by a range of smaller peaks, known as Pr cor cove sq 
----
iter 21000, loss: 0.253981
----
 hiys island is crescent or kidneind arid, with a ridge of mountains running the length of the island. The center of the island is divided between east and west by a range of smaller peaks, known as Pr 
----
iter 22000, loss: 0.244011
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north tu north of the island. The two largespength of smaller peaks, known as Pr (1,5.210 mi) at its widest, covering an area of 842.2 
----
iter 23000, loss: 0.235539
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq ma Peline fr me fm mi) as e nountains, Pe 
----
iter 24000, loss: 0.227563
----
 hiys island is kid.289 km (10 (3,898 ft)), are situated in the north of the island. The two largest of these mountains, Pelineo2eand asn widest or kidney shaped, 50 km (31 mi) long from north to south 
----
iter 25000, loss: 0.220807
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainouth of th 
----
iter 26000, loss: 0.214157
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 27000, loss: 0.207951
----
 hiys island is crescent or kidney shaped, 50 km (3,898 ft)), are situated in the north of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) and Epos (1,188(3,.289 km2 (325. 
----
iter 28000, loss: 0.203003
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] km2 (325.210 sq mi).[2] The terra 
----
iter 29000, loss: 0.197475
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 30000, loss: 0.192071
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 31000, loss: 0.187713
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 32000, loss: 0.184434
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 33000, loss: 0.180032
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sound ihe island. The center of the island i 
----
iter 34000, loss: 0.175579
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 35000, loss: 0.171835
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainouth of th 
----
iter 36000, loss: 0.168542
----
 hiys island is creing the length of the island. The center of the island is divided th of the island. The center of the island is divided between east and west by a range of smaller peaks, known as Pr 
----
iter 37000, loss: 6.387221
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 38000, loss: 2.814015
----
 hiys island is crescovidis (1,188 m (3,898 ft)), are situated in the north of the island. The center of the island is divided between east and west by a range of smaller peaks, known as Pr kidney shap 
----
iter 39000, loss: 1.325806
----
 hiys island is crescent or kidney shant ithe north of the island. The center of the island is divided between east and west by a range of smaller peaks, knofnt(1,10210 sq mi).[2] The terrain is mounta 
----
iter 40000, loss: 0.717604
----
 hiys island is crescent or kidney shaped, 50 teendest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, with a rid, arg tw  rainistated in the north of the isla 
----
iter 41000, loss: 0.460328
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 42000, loss: 0.346036
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from norof smaller peaks, known as Pr kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an a 
----
iter 43000, loss: 0.490187
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, ces wi lend is divided between east ist an east and west by a range of smaller peaks, 
----
iter 44000, loss: 0.345052
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 45000, loss: 0.274964
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from wilondas ce the island. The center of the island is divided between east annand 29 km (18 mi) at its widest, covering an area of 842.2 
----
iter 46000, loss: 0.240069
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 47000, loss: 0.220421
----
 hiys island is crescent of 842.289 km2 (325.210 sq mi).[2] The terrain is, mi).[2] The south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mounta 
----
iter 48000, loss: 0.207621
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 84knq mi).[2] The terrain is mountainous and arid, with a ridge o 
----
iter 49000, loss: 0.198178
----
 hiys island in (1,297 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), are situated in the north of the island. The center of the island is divided between east and west by a range of smaller peaks, known 
----
iter 50000, loss: 0.190609
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 51000, loss: 0.184245
----
 hiys island is crescent or kidney shaped, 50 km arid, with a ridge of mountains running the length of the island. The center of the island is divided between eang from north to south, and 29 km (18 mi 
----
iter 52000, loss: 0.178749
----
 hiys island is ine from sq mi).[2] The terrain is mountainous and arid, with a ridge of mountains running the length of the island. The center of the island is divided between east and west by a range 
----
iter 53000, loss: 0.173909
----
 hiys islan e ma d and Epos (1,188 m (3,898 ft)), are situated in the north of the84te2araes, known as Pr kidea oange of smaller peaks, known as Pr kne ridge of mountains running the length of the isla 
----
iter 54000, loss: 0.169596
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering a or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi 
----
iter 55000, loss: 0.165723
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (3253284, rreng indd or kidney shaped, 50 km (31 mi)  
----
iter 56000, loss: 0.162224
----
 hiys island is cresceno sor ais and arid, with a ridge of mountains running the length of the island. The center of the island is divided between east and west by a range of smaller peaks, known as Pr 
----
iter 57000, loss: 0.159060
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 58000, loss: 0.156217
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.218 mot of these mountains, Pelineon as Pr (1,,9 
----
iter 59000, loss: 0.153774
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) ans m9 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, with a ridge of mountains runnin 
----
iter 60000, loss: 0.151875
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) divided between east and west by a range of smaller peaks, known as Pr kmed in the north of the isla 
----
iter 61000, loss: 0.150220
----
 hiys islandes and is crescent ope center of the island is divided between east and west by a range of smaller peaks, known as Pr (1,g[2onnis as Pr kid.[2] The terrain is mountainous and arid, with a r 
----
iter 62000, loss: 0.148586
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km ) mountains running the lengeaid, 50 km (31 mi) long moege are situated in the north of the island. The cent 
----
iter 63000, loss: 0.596505
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to souteathescent arid, with a ridge of mountains t)) arid, with a ridge of mountains running the length of the island. The cent 
----
iter 64000, loss: 0.345530
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 65000, loss: 0.231475
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 66000, loss: 0.182829
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 kmid deing the length of the island. The two largest of t 
----
iter 67000, loss: 0.161038
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 68000, loss: 0.150198
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 69000, loss: 0.144052
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, ces widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mounta 
----
iter 70000, loss: 0.140060
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 71000, loss: 0.137140
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 72000, loss: 0.134810
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 73000, loss: 0.132852
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 kmith wiey shaped, with a ridge of mountains running the  
----
iter 74000, loss: 0.131156
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 75000, loss: 0.129685
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to of scrn ni i) km2 (3,188 m (3,898 ft)), are situage asd in end is crescent or kidney shaped, 50 km (31 mi) long from north to 
----
iter 76000, loss: 0.128520
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 77000, loss: 0.127387
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar 
----
iter 78000, loss: 0.126192
----
 hiys island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sm lorth of the island. The center of the is 
----
iter 79000, loss: 0.124999
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "pantelis/data-mining",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./aiml-common/lectures/nlp/language-models/simple-rnn-language-model"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../cnn-language-model/index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">CNN Language Model</p>
      </div>
    </a>
    <a class="right-next"
       href="../lstm-language-model/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">LSTM Language Model from scratch</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pantelis Monogioudis, Ph.D
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>